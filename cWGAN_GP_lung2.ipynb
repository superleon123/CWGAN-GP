{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ScXZj2zsT-T"
      },
      "source": [
        "# Some preprocessing to implement tanh in generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iL-TUJstHLR",
        "outputId": "79b9cf93-ff39-4c32-f21b-e70377b0cfc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "gdrive\tsample_data\n",
            "/content/gdrive/My Drive/GANs_for_Tabular_data-master/cWGAN_GP\n",
            " cWGAN_GP.ipynb\t\t\t'lung cancer-name.csv'\n",
            " cWGAN_GP-lung2.ipynb\t\t'pancreatic2020 data.csv'\n",
            " cWGAN_GP-lung.ipynb\t\t'Parkinsson disease.csv'\n",
            " cWGAN_GP-pancreatic.ipynb\t Prostate_Cancer.csv\n",
            " cWGAN_GP-parkinson.ipynb\t'survey lung cancer.csv'\n",
            " cWGAN_GP-prostateCancer.ipynb\t train.csv\n",
            "'lung cancer2.csv'\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive', force_remount=True)\n",
        "drive.mount('/content/gdrive')\n",
        "!ls\n",
        "%cd gdrive/My\\ Drive/GANs_for_Tabular_data-master/cWGAN_GP/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip list\n",
        "#!pip install lightgbm==3.3.4 --upgrade \n",
        "#!pip install xgboost --upgrade\n",
        "!pip install xgboost==1.6.2 --upgrade"
      ],
      "metadata": {
        "id": "WQrXhpjmeVAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb11763c-d030-427a-cc39-1215007fe59a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xgboost==1.6.2\n",
            "  Downloading xgboost-1.6.2-py3-none-manylinux2014_x86_64.whl (255.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.9/255.9 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from xgboost==1.6.2) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from xgboost==1.6.2) (1.7.3)\n",
            "Installing collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed xgboost-1.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M5bplf9DsT-Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from imblearn.metrics import classification_report_imbalanced\n",
        "from sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# normalized_df=(df-df.mean())/df.std()\n",
        "# df = pd.read_csv('lung cancer-name.csv')\n",
        "# df.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add data preprocessing"
      ],
      "metadata": {
        "id": "50-wuWr8ORdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV, cross_validate\n",
        "\n",
        "'''Load the data'''\n",
        "df_all = pd.read_csv('survey lung cancer.csv')\n",
        "df_all.info()\n",
        "df_all.value_counts(df_all['LUNG_CANCER'])\n",
        "\n",
        "df_all[\"LUNG_CANCER\"] = df_all.LUNG_CANCER.map({\"YES\": 1, \"NO\": 0})\n",
        "cols = df_all.columns\n",
        "df = pd.get_dummies(df_all[cols])\n",
        "\n",
        "\n",
        "\n",
        "# #df_NoScaled = df[['AGE']]\n",
        "# #df.drop(['AGE'],axis=1,inplace=True)\n",
        "# #leon\n",
        "# df_target= df[\"LUNG_CANCER\"]\n",
        "\n",
        "# df.drop(['LUNG_CANCER'],axis=1,inplace=True)\n",
        "\n",
        "# #####\n",
        "# df.info()\n",
        "# df.head()\n"
      ],
      "metadata": {
        "id": "8N3gcHWTOPV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67db1fc9-2a9f-4eb0-e698-2a9b703366d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 309 entries, 0 to 308\n",
            "Data columns (total 16 columns):\n",
            " #   Column                 Non-Null Count  Dtype \n",
            "---  ------                 --------------  ----- \n",
            " 0   GENDER                 309 non-null    object\n",
            " 1   AGE                    309 non-null    int64 \n",
            " 2   SMOKING                309 non-null    int64 \n",
            " 3   YELLOW_FINGERS         309 non-null    int64 \n",
            " 4   ANXIETY                309 non-null    int64 \n",
            " 5   PEER_PRESSURE          309 non-null    int64 \n",
            " 6   CHRONIC DISEASE        309 non-null    int64 \n",
            " 7   FATIGUE                309 non-null    int64 \n",
            " 8   ALLERGY                309 non-null    int64 \n",
            " 9   WHEEZING               309 non-null    int64 \n",
            " 10  ALCOHOL CONSUMING      309 non-null    int64 \n",
            " 11  COUGHING               309 non-null    int64 \n",
            " 12  SHORTNESS OF BREATH    309 non-null    int64 \n",
            " 13  SWALLOWING DIFFICULTY  309 non-null    int64 \n",
            " 14  CHEST PAIN             309 non-null    int64 \n",
            " 15  LUNG_CANCER            309 non-null    object\n",
            "dtypes: int64(14), object(2)\n",
            "memory usage: 38.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sc = MinMaxScaler(feature_range=(0, 1))\n",
        "# #sc = StandardScaler()\n",
        "# #df_scaled = sc.fit_transform(df)\n",
        "# standard_scaler = sc.fit(df)\n",
        "# df_scaled = standard_scaler.transform(df)\n",
        "\n",
        "\n",
        "# #df_scaled.head(2)\n",
        "# df2 = pd.DataFrame(df_scaled)\n",
        "# print(df2.head())\n",
        "# #df3 = df2[cols]\n",
        "# df_target.head()\n",
        "\n",
        "# print(df.columns)"
      ],
      "metadata": {
        "id": "pvwMAsl7ZRd1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #X_train, X_test, y_train, y_test = train_test_split(model_df, df_lung_cancer, test_size=0.20, shuffle=True)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(df2, df_target, test_size=0.20, shuffle=True)\n",
        "# print(f\"X_train shape: {X_train.shape}\")\n",
        "# print(f\"X_test shape: {X_test.shape}\")\n",
        "# print(f\"y_train shape: {y_train.shape}\")\n",
        "# print(f\"y_test shape: {y_test.shape}\")\n",
        "# print(f\"Number of classes {len(np.unique(y_train))}\")\n",
        "# #print(X_test.shape)\n",
        "# #print(y_test.shape)\n",
        "# #print(pd.DataFrame(y_test).value_counts())\n",
        "# #print(X_train.value_counts())\n",
        "# print(y_train.value_counts())"
      ],
      "metadata": {
        "id": "kQ8HnyrkUtak"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN3lWrUVsT-b"
      },
      "source": [
        "# Importing the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_hbMxupesT-c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV, cross_validate\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score,\\\n",
        "                            accuracy_score, balanced_accuracy_score,classification_report,\\\n",
        "                            plot_confusion_matrix, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tcCCOkOsT-d"
      },
      "source": [
        "# Creating pytorch dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2HLGLcx6sT-d"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "X2dbz12xq44R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de1343f5-1c64-41c9-998f-b4f974560195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   AGE  SMOKING  YELLOW_FINGERS  ANXIETY  PEER_PRESSURE  CHRONIC DISEASE  \\\n",
            "0   69        1               2        2              1                1   \n",
            "1   74        2               1        1              1                2   \n",
            "2   59        1               1        1              2                1   \n",
            "3   63        2               2        2              1                1   \n",
            "4   63        1               2        1              1                1   \n",
            "\n",
            "   FATIGUE   ALLERGY   WHEEZING  ALCOHOL CONSUMING  COUGHING  \\\n",
            "0         2         1         2                  2         2   \n",
            "1         2         2         1                  1         1   \n",
            "2         2         1         2                  1         2   \n",
            "3         1         1         1                  2         1   \n",
            "4         1         1         2                  1         2   \n",
            "\n",
            "   SHORTNESS OF BREATH  SWALLOWING DIFFICULTY  CHEST PAIN  GENDER_F  GENDER_M  \n",
            "0                    2                      2           2         0         1  \n",
            "1                    2                      2           2         0         1  \n",
            "2                    2                      1           2         1         0  \n",
            "3                    1                      2           2         0         1  \n",
            "4                    2                      1           1         1         0  \n",
            "0    1\n",
            "1    1\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: LUNG_CANCER, dtype: int64\n",
            "         0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
            "0  0.727273  0.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0   \n",
            "1  0.803030  1.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  1.0   \n",
            "2  0.575758  0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  1.0   \n",
            "3  0.636364  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0   \n",
            "4  0.636364  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0   \n",
            "\n",
            "    14   15  \n",
            "0  0.0  1.0  \n",
            "1  0.0  1.0  \n",
            "2  1.0  0.0  \n",
            "3  0.0  1.0  \n",
            "4  1.0  0.0  \n",
            "y value_count:\n",
            " 1    270\n",
            "0     39\n",
            "Name: LUNG_CANCER, dtype: int64\n",
            "X_train shape: (247, 16)\n",
            "X_test shape: (62, 16)\n",
            "y_train shape: (247,)\n",
            "y_test shape: (62,)\n",
            "Number of classes 2\n"
          ]
        }
      ],
      "source": [
        "#df = pd.read_csv('lung cancer-name.csv')\n",
        "#df.info()\n",
        "\n",
        "#x = df.iloc[:, 0:7].values\n",
        "#y = df.iloc[:, -1].values\n",
        "\n",
        "y = df[\"LUNG_CANCER\"]\n",
        "x = df.drop([\"LUNG_CANCER\"], axis=1)\n",
        "print(x.head())\n",
        "print(y.head())\n",
        "\n",
        "mc = MinMaxScaler(feature_range=(0, 1))\n",
        "standard_scaler = mc.fit(x)\n",
        "x_scaled = standard_scaler.transform(x)\n",
        "x_scaled = pd.DataFrame(x_scaled)\n",
        "\n",
        "print(x_scaled.head())\n",
        "print(f\"y value_count:\\n {y.value_counts()}\")\n",
        "#x_scaled = x_scaled.values\n",
        "#y = y.values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, shuffle=True)   # 8:2\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "print(f\"Number of classes {len(np.unique(y_train))}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5ijViHPUt5OA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "93448d61-8f72-4971-8a2d-63e688418ed1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport xgboost as xgb\\nxgb = xgb.XGBClassifier()\\nxgb.fit(X_train,y_train)\\n\\ny_pred = xgb.predict(X_test)\\n\\nprint(classification_report(y_test, y_pred))\\nplot_confusion_matrix(xgb, X_test, y_test)\\nplt.show()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#leon\n",
        "\"\"\"\n",
        "import xgboost as xgb\n",
        "xgb = xgb.XGBClassifier()\n",
        "xgb.fit(X_train,y_train)\n",
        "\n",
        "y_pred = xgb.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "plot_confusion_matrix(xgb, X_test, y_test)\n",
        "plt.show()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "parameter = {\n",
        "    'max_depth':range(3,10,2), \n",
        "    'min_child_weight':range(1,5,2)\n",
        "    }\n",
        "\n",
        "p_grid_search = GridSearchCV(estimator = xgb.XGBClassifier(eval_metric='mlogloss'), param_grid = parameter, \n",
        "                             scoring='accuracy', n_jobs=-1, cv=2)\n",
        "\n",
        "p_grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "GridSearchCV(cv=2,\n",
        "             estimator=xgb.XGBClassifier(base_score=None, booster=None,   #leon  add xgb before xgbclassifier\n",
        "                                     callbacks=None, colsample_bylevel=None,\n",
        "                                     colsample_bynode=None,\n",
        "                                     colsample_bytree=None,\n",
        "                                     early_stopping_rounds=None,\n",
        "                                     enable_categorical=False,\n",
        "                                     eval_metric='mlogloss', gamma=None,\n",
        "                                     gpu_id=None, grow_policy=None,\n",
        "                                     importance_type=None,\n",
        "                                     interaction_constraints=None,\n",
        "                                     learning_rate=None, max_bin=None,\n",
        "                                     max_cat_to_onehot=None,\n",
        "                                     max_delta_step=None, max_depth=None,\n",
        "                                     max_leaves=None, min_child_weight=None,\n",
        "                                     missing=None, monotone_constraints=None,\n",
        "                                     n_estimators=100, n_jobs=None,\n",
        "                                     num_parallel_tree=None, predictor=None,\n",
        "                                     random_state=None, reg_alpha=None,\n",
        "                                     reg_lambda=None),\n",
        "             n_jobs=-1,\n",
        "             param_grid={'max_depth': range(3, 10, 2),\n",
        "                         'min_child_weight': range(1, 5, 2)},\n",
        "             scoring='accuracy')\n",
        "\n",
        "p_grid_search.best_params_, p_grid_search.best_score_"
      ],
      "metadata": {
        "id": "_Xn5r8nRhDEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946969e7-ac4d-4c26-e86c-9907607b3f21"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'max_depth': 3, 'min_child_weight': 3}, 0.8866706005769736)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "refined_xgb_model = xgb.XGBClassifier(eval_metric='logloss', max_depth=list(p_grid_search.best_params_.values())[0]-1, \n",
        "                                      min_child_weight=list(p_grid_search.best_params_.values())[-1]+4)\n",
        "refined_xgb_model.fit(X_train, y_train)\n",
        "#print(f'Accuracy of XGB classifier on training set: {refined_xgb_model.score(X_train, y_train)}')\n",
        "#print(f'Accuracy of XGB classifier on test set: {refined_xgb_model.score(X_test[X_train.columns], y_test)}')"
      ],
      "metadata": {
        "id": "UW54crUDhJne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413f94b6-d87e-40f9-970a-f618bee33bf2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
              "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric='logloss', gamma=0, gpu_id=-1,\n",
              "              grow_policy='depthwise', importance_type=None,\n",
              "              interaction_constraints='', learning_rate=0.300000012,\n",
              "              max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=2,\n",
              "              max_leaves=0, min_child_weight=7, missing=nan,\n",
              "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
              "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, ...)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.metrics import classification_report_imbalanced\n",
        "ref_xgb_pred_y = refined_xgb_model.predict(X_test)\n",
        "def plot_confusion_matrix(y_test, y_pred, color):\n",
        "    \n",
        "    plt.rcParams['figure.figsize'] = (16, 9)\n",
        "   \n",
        "    data = {'y_Actual': y_test, 'y_Predicted': y_pred}\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "    conf_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], \n",
        "                              rownames=['Actual'], \n",
        "                              colnames=['Predicted'])\n",
        "    \n",
        "    sns.heatmap(conf_matrix, annot=True, fmt = \"d\", cmap=color)\n",
        "    plt.show()\n",
        "    \n",
        "plot_confusion_matrix(np.array(y_test), ref_xgb_pred_y, 'crest')\n",
        "print(classification_report(y_test, ref_xgb_pred_y))\n",
        "print(classification_report_imbalanced(y_test, ref_xgb_pred_y))  #, digits=4"
      ],
      "metadata": {
        "id": "hfplxcLehN2V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828
        },
        "outputId": "60e678f2-908c-4576-f218-1bce369d7373"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.67      0.80         6\n",
            "           1       0.97      1.00      0.98        56\n",
            "\n",
            "    accuracy                           0.97        62\n",
            "   macro avg       0.98      0.83      0.89        62\n",
            "weighted avg       0.97      0.97      0.96        62\n",
            "\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       1.00      0.67      1.00      0.80      0.82      0.64         6\n",
            "          1       0.97      1.00      0.67      0.98      0.82      0.69        56\n",
            "\n",
            "avg / total       0.97      0.97      0.70      0.96      0.82      0.68        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=300, n_jobs=-1)\n",
        "rf.fit(X_train,y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "plot_confusion_matrix(rf, X_test, y_test)\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9rL8Zmh5CFuH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8d6560ed-682d-46c7-a2cb-ab75a2e8afad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.ensemble import RandomForestClassifier\\nrf = RandomForestClassifier(n_estimators=300, n_jobs=-1)\\nrf.fit(X_train,y_train)\\ny_pred = rf.predict(X_test)\\n\\nprint(classification_report(y_test, y_pred))\\nplot_confusion_matrix(rf, X_test, y_test)\\nplt.show()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "lgb_model= lgb.LGBMClassifier()\n",
        "lgb_model.fit(X_train,y_train)\n",
        "\n",
        "#from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "predictions= lgb_model.predict(X_train)\n",
        "percentage=lgb_model.score(X_train,y_train)\n",
        "res=confusion_matrix(y_train,predictions)\n",
        "print(\"Training confusion matrix\")\n",
        "print(res)\n",
        "predictions= lgb_model.predict(X_test)\n",
        "train_percentage=lgb_model.score(X_train,y_train)\n",
        "test_percentage=lgb_model.score(X_test,y_test)\n",
        "res = confusion_matrix(y_test,predictions)\n",
        "print(\"Testing confusion matrix\")\n",
        "print(res)\n",
        "\n",
        "# check the accuracy on the training set\n",
        "print(lgb_model.score(X_train, y_train))\n",
        "print(lgb_model.score(X_test, y_test))\n",
        "print(f\"Train set:{len(X_train)}\")\n",
        "print(f\"Train Accuracy={train_percentage*100}%\")\n",
        "print(f\"Test set:{len(X_test)}\")\n",
        "print(f\"Test Accuracy={test_percentage*100}%\")\n",
        "\n",
        "print(classification_report(y_test, predictions))\n",
        "print(classification_report_imbalanced(y_test, predictions)) \n",
        "\"\"\"\n",
        "plot_confusion_matrix(lgb_model, X_test, y_test)\n",
        "plt.show()\n",
        "\"\"\"\n",
        "cm = confusion_matrix(y_test, predictions, labels=lgb_model.classes_)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lgb_model.classes_)\n",
        "disp.plot()\n",
        "_ = disp.ax_.set_title(\"LGBM Classifier\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0sZbhKdzaLPl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b8773b9-9752-4bf1-b6a8-49beadbc8089"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training confusion matrix\n",
            "[[ 33   0]\n",
            " [  2 212]]\n",
            "Testing confusion matrix\n",
            "[[ 3  3]\n",
            " [ 2 54]]\n",
            "0.9919028340080972\n",
            "0.9193548387096774\n",
            "Train set:247\n",
            "Train Accuracy=99.19028340080972%\n",
            "Test set:62\n",
            "Test Accuracy=91.93548387096774%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.50      0.55         6\n",
            "           1       0.95      0.96      0.96        56\n",
            "\n",
            "    accuracy                           0.92        62\n",
            "   macro avg       0.77      0.73      0.75        62\n",
            "weighted avg       0.91      0.92      0.92        62\n",
            "\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.60      0.50      0.96      0.55      0.69      0.46         6\n",
            "          1       0.95      0.96      0.50      0.96      0.69      0.50        56\n",
            "\n",
            "avg / total       0.91      0.92      0.54      0.92      0.69      0.50        62\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report,\\\n",
        "                            plot_confusion_matrix, confusion_matrix\n",
        "xgb=xgb.XGBClassifier()\n",
        "\n",
        "xgb.fit(X_train,y_train)\n",
        "\n",
        "y_pred = xgb.predict(X_test)\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#change y value to 0..2\n",
        "#le2 = LabelEncoder()\n",
        "#y_test = le2.fit_transform(y_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(classification_report_imbalanced(y_test, y_pred))\n",
        "plot_confusion_matrix(xgb, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UbzR5G7wJBF2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        },
        "outputId": "5321ab5a-ec8b-481e-e2aa-9ea0e1a1c5eb"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.50      0.60         6\n",
            "           1       0.95      0.98      0.96        56\n",
            "\n",
            "    accuracy                           0.94        62\n",
            "   macro avg       0.85      0.74      0.78        62\n",
            "weighted avg       0.93      0.94      0.93        62\n",
            "\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.75      0.50      0.98      0.60      0.70      0.47         6\n",
            "          1       0.95      0.98      0.50      0.96      0.70      0.51        56\n",
            "\n",
            "avg / total       0.93      0.94      0.55      0.93      0.70      0.51        62\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RjxpSfwUsT-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a294f5c-35d2-4e3f-e093-7a80709525df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8636, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
            "         0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n",
            "        [0.8485, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
            "         1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
            "        [0.5303, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
            "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000],\n",
            "        [0.5152, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
            "        [0.5758, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
            "         0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
            "tensor([1, 1, 1, 0, 0], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "class MyDataset(Dataset):\n",
        " \n",
        "  def __init__(self ,x, y):\n",
        "    \"\"\"\n",
        "    df = pd.read_csv('train.csv')\n",
        "    df[\"label\"] = df.Survived\n",
        "#     df = df[df['label'] == 1].reset_index(drop = True)\n",
        "    df = df.drop([\"PassengerId\", \"Survived\", \"Name\", \"Ticket\", \"Cabin\"], axis=1)\n",
        "    median_age = df.Age.median()\n",
        "    mode_embarked = df.Embarked.mode()[0]\n",
        "    df = df.fillna({\"Age\": median_age, \"Embarked\": mode_embarked})\n",
        "    df.Sex = df.Sex.replace({'male':0,'female':1})\n",
        "    df.Embarked = df.Embarked.replace({'S':0,'C':1,'Q':2})\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    mc = MinMaxScaler(feature_range=(0, 1))\n",
        "    standard_scaler = mc.fit(x)\n",
        "    x_scaled = standard_scaler.transform(x)\n",
        "\n",
        "    x_scaled = pd.DataFrame(x_scaled)\n",
        "    print(x_scaled.head())\n",
        "    print(f\"y value_count:\\n {y.value_counts()}\")\n",
        "    x_scaled = x_scaled.values\n",
        "    y = y.values\n",
        "    \"\"\"\n",
        "    x = x.values\n",
        "    y = y.values\n",
        "\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.20, shuffle=True)\n",
        "    \n",
        "    #x = x.values\n",
        "    #y = y.values\n",
        "    #X_train = X_train.values\n",
        "    #y_train = y_train.values\n",
        "    #self.x_train=torch.tensor(x_scaled,dtype=torch.float32)\n",
        "    self.x_train=torch.tensor(x,dtype=torch.float32)\n",
        "    self.y_train=torch.tensor(y,dtype=torch.int)\n",
        "\n",
        "    print(self.x_train[0:5])\n",
        "    print(self.y_train[0:5])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y_train)\n",
        "   \n",
        "  def __getitem__(self,idx):\n",
        "    return self.x_train[idx],self.y_train[idx]\n",
        "\n",
        "train_ds = MyDataset(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oVR5e841oB6x"
      },
      "outputs": [],
      "source": [
        "#train_ds.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LO3r744evfUf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_r9-2iV4sT-g"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=0, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7JN4e6k3sT-g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fdedcd7-47f9-4da9-d568-0ff25ba13a52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0smG5AcwsT-i"
      },
      "outputs": [],
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "i0kACszmsT-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2abba10-88d5-4e2b-e6ca-09a7af87099b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "train_dl.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPhzFTqNsT-k"
      },
      "source": [
        "# Creating generator and discriminator models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVKk_MXMsT-k"
      },
      "source": [
        "<b> Generator Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ZNnZFnl2sT-l"
      },
      "outputs": [],
      "source": [
        "latent_size = 16 # origin is 7\n",
        "n_features = 16  # equal to columns\n",
        "num_classes = 2\n",
        "embed_size = 2  # classes number?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "w5eIj140sT-l"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, embed_size = 2):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(n_features + embed_size, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 32),\n",
        "            nn.ReLU(),\n",
        "            #nn.Linear(32, 7),\n",
        "            nn.Linear(32, 16)   # the last number is equal to columns\n",
        "            \n",
        "#             nn.Linear(latent_size, 1024),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(1024, 512),\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             nn.Dropout2d(0.2),\n",
        "            \n",
        "#             nn.Linear(512, 256),\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             nn.Dropout2d(0.2),\n",
        "            \n",
        "#             nn.Linear(256, 128),\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             nn.Dropout2d(0.2),\n",
        "            \n",
        "#             nn.Linear(128, 64),\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             nn.Dropout2d(0.2),\n",
        "            \n",
        "#             nn.Linear(64, 32),\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             nn.Dropout2d(0.2),\n",
        "            \n",
        "#             nn.Linear(32, 16),\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             nn.Dropout2d(0.2),\n",
        "            \n",
        "#             nn.Linear(16, 7),\n",
        "        )\n",
        "        self.embed = nn.Embedding(num_classes, embed_size)\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        embed = self.embed(labels)#.reshape(labels.shape[0], 1)\n",
        "        x = torch.cat([x, embed], dim = 1)\n",
        "        output = self.model(x)\n",
        "        return output\n",
        "    \n",
        "\n",
        "generator = to_device(Generator(), device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxbCeOwKsT-m"
      },
      "source": [
        "<b> Discriminator Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "DPTTf3ErsT-m"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, embed_size = 2):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(n_features + embed_size, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid(),\n",
        "#             nn.Linear(n_features, 1024),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(1024, 512),\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             nn.Dropout2d(0.2),\n",
        "            \n",
        "#             nn.Linear(512, 256),\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             nn.Dropout2d(0.2),\n",
        "            \n",
        "#             nn.Linear(256, 128),\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             nn.Dropout2d(0.2),\n",
        "            \n",
        "#             nn.Linear(128, 64),\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             nn.Dropout2d(0.2),\n",
        "            \n",
        "#             nn.Linear(64, 32),\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             nn.Dropout2d(0.2),\n",
        "            \n",
        "#             nn.Linear(32, 16),\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             nn.Dropout2d(0.2),\n",
        "            \n",
        "#             nn.Linear(16, 1),\n",
        "#             nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        self.embed = nn.Embedding(num_classes, embed_size)\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        embed = self.embed(labels) #.reshape(labels.shape[0], 1)\n",
        "        x = torch.cat([x, embed], dim = 1)\n",
        "        output = self.model(x)\n",
        "        return output\n",
        "    \n",
        "discriminator = to_device(Discriminator(), device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QsDnr0xvsT-n"
      },
      "outputs": [],
      "source": [
        "# for arr, labels in train_dl:\n",
        "#     break\n",
        "# # nn.Embedding(2, 2).to('cuda')(labels)#.reshape(labels.shape[0], 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfMI9xJNsT-n"
      },
      "source": [
        "# Generator and discriminator training methodology"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "S6oHYHU-sT-n"
      },
      "outputs": [],
      "source": [
        "CRITIC_ITERATIONS = 5\n",
        "# WEIGHT_CLIP = 0.01\n",
        "LAMBDA_GP = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "T9mJ8dEjsT-o"
      },
      "outputs": [],
      "source": [
        "def gradient_penalty(real_data, generated_data, real_labels,device = device):\n",
        "    BATCH_SIZE, features_count = real_data.shape\n",
        "    epsilon = torch.rand((BATCH_SIZE, features_count)).to(device)\n",
        "    epsilon = epsilon.to(device)\n",
        "\n",
        "    interpolated_data = real_data * epsilon + generated_data * (1 - epsilon)\n",
        "\n",
        "\n",
        "    # lets calculate critics score\n",
        "    mixed_scores = discriminator(interpolated_data, real_labels)\n",
        "\n",
        "    # Computes and returns the sum of gradients of outputs with respect to the inputs.\n",
        "    # https://pytorch.org/docs/stable/generated/torch.ones_like.html\n",
        "    # l2 norm : https://www.analyticsvidhya.com/blog/2021/03/must-known-vector-norms-in-machine-learning/\n",
        "    gradient = torch.autograd.grad(\n",
        "      inputs = interpolated_data,\n",
        "      outputs = mixed_scores,\n",
        "      grad_outputs = torch.ones_like(mixed_scores)\n",
        "    )[0]\n",
        "\n",
        "    gradient = gradient.view(gradient.shape[0], -1)\n",
        "    gradient_norm = gradient.norm(2, dim = 1)\n",
        "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
        "    return gradient_penalty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xO_HlyiLsT-o"
      },
      "outputs": [],
      "source": [
        "def reset_grad():\n",
        "    d_optimizer.zero_grad()\n",
        "    g_optimizer.zero_grad()\n",
        "\n",
        "def train_discriminator(real_data, opt_d, cur_batch_size, real_labels):\n",
        "    # Reset gradients\n",
        "    opt_d.zero_grad()\n",
        "    \n",
        "    real_labels = real_labels.to(device)\n",
        "    real_preds = discriminator(real_data, real_labels).reshape(-1)\n",
        "\n",
        "    # random noise from uniform distribution\n",
        "    latent_space_samples = torch.randn((cur_batch_size, latent_size),  device = device)\n",
        "    \n",
        "    generated_data = generator(latent_space_samples, real_labels)  # fake data generated by generator\n",
        "    fake_preds = discriminator(generated_data, real_labels).reshape(-1)\n",
        "    \n",
        "    # calculating gradient penalty\n",
        "    gp = gradient_penalty(real_data, generated_data, real_labels,device = device)\n",
        "    \n",
        "    loss = -(torch.mean(real_preds) - torch.mean(fake_preds)) + LAMBDA_GP * gp\n",
        "\n",
        "    # Compute gradients\n",
        "    loss.backward()\n",
        "    # Adjust the parameters using backprop\n",
        "    opt_d.step()\n",
        "        \n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7IGQFubMsT-p"
      },
      "outputs": [],
      "source": [
        "def train_generator(opt_g, cur_batch_size, real_labels):\n",
        "    # Clear generator gradients\n",
        "    opt_g.zero_grad()\n",
        "     \n",
        "    # random noise from uniform distribution\n",
        "    latent_space_samples = torch.randn((cur_batch_size, latent_size),  device = device)\n",
        "    generated_data = generator(latent_space_samples, real_labels)  # fake data generated by generator\n",
        "    fake_preds = discriminator(generated_data, real_labels.to(device)).reshape(-1)\n",
        "    g_loss = -torch.mean(fake_preds)\n",
        "\n",
        "    g_loss.backward()\n",
        "    opt_g.step()\n",
        "    return g_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHZpqIecsT-p"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vCPTDJ2YjPQd"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "epochs = 1000  #leon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ltdcF4MgjRkf"
      },
      "outputs": [],
      "source": [
        "opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas = (0.5, 0.9))\n",
        "opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas = (0.5, 0.9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_A41fxuXsT-q"
      },
      "outputs": [],
      "source": [
        "def fit(epochs, lr, opt_d, opt_g):\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Losses & scores\n",
        "    losses_g = []\n",
        "    losses_d = []\n",
        "\n",
        "    \n",
        "    # Create optimizers\n",
        "#     opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "#     opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    total_step = len(train_dl)\n",
        "    for epoch in range(epochs):\n",
        "        for i, (real_data, real_labels) in enumerate(train_dl):\n",
        "            cur_batch_size = real_data.shape[0]\n",
        "            \n",
        "            for _ in range(CRITIC_ITERATIONS):            \n",
        "                # Train the discriminator and generator\n",
        "                d_loss = train_discriminator(real_data, opt_d, cur_batch_size, real_labels)            \n",
        "                \n",
        "            g_loss = train_generator(opt_g, cur_batch_size, real_labels)\n",
        "            \n",
        "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}'\n",
        "                  .format(epoch, epochs, i+1, total_step, d_loss.item(), g_loss.item()))\n",
        "        # Loss of last batch\n",
        "        losses_d.append(d_loss.item())\n",
        "        losses_g.append(g_loss.item())\n",
        "    return losses_g, losses_d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "q0GSa1hzsT-r",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ed3703-5c5d-4502-8ff2-058028786596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "Epoch [375/1000], Step [3/8], d_loss: 31.8434, g_loss: -0.0000\n",
            "Epoch [375/1000], Step [4/8], d_loss: 73.0262, g_loss: -0.0000\n",
            "Epoch [375/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0028\n",
            "Epoch [375/1000], Step [6/8], d_loss: 8.8711, g_loss: -0.0000\n",
            "Epoch [375/1000], Step [7/8], d_loss: 8.9929, g_loss: -0.0000\n",
            "Epoch [375/1000], Step [8/8], d_loss: 9.0429, g_loss: -0.0000\n",
            "Epoch [376/1000], Step [1/8], d_loss: 9.0311, g_loss: -0.0000\n",
            "Epoch [376/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [376/1000], Step [3/8], d_loss: 8.3752, g_loss: -0.0000\n",
            "Epoch [376/1000], Step [4/8], d_loss: 297.0372, g_loss: -0.0001\n",
            "Epoch [376/1000], Step [5/8], d_loss: 9107.2754, g_loss: -0.0000\n",
            "Epoch [376/1000], Step [6/8], d_loss: 8.5212, g_loss: -0.0401\n",
            "Epoch [376/1000], Step [7/8], d_loss: 21.6993, g_loss: -0.0000\n",
            "Epoch [376/1000], Step [8/8], d_loss: 9.4256, g_loss: -0.0000\n",
            "Epoch [377/1000], Step [1/8], d_loss: 221.3895, g_loss: -0.0033\n",
            "Epoch [377/1000], Step [2/8], d_loss: 22.5449, g_loss: -0.0004\n",
            "Epoch [377/1000], Step [3/8], d_loss: 1125.1788, g_loss: -0.0000\n",
            "Epoch [377/1000], Step [4/8], d_loss: 1044.3489, g_loss: -0.0000\n",
            "Epoch [377/1000], Step [5/8], d_loss: 9.0014, g_loss: -0.0000\n",
            "Epoch [377/1000], Step [6/8], d_loss: 1319.7684, g_loss: -0.0000\n",
            "Epoch [377/1000], Step [7/8], d_loss: 1537.2646, g_loss: -0.0000\n",
            "Epoch [377/1000], Step [8/8], d_loss: 8.9846, g_loss: -0.0000\n",
            "Epoch [378/1000], Step [1/8], d_loss: 16.4317, g_loss: -0.0391\n",
            "Epoch [378/1000], Step [2/8], d_loss: 34.5393, g_loss: -0.0216\n",
            "Epoch [378/1000], Step [3/8], d_loss: 907.1671, g_loss: -0.0000\n",
            "Epoch [378/1000], Step [4/8], d_loss: 8.9692, g_loss: -0.0000\n",
            "Epoch [378/1000], Step [5/8], d_loss: 29.2316, g_loss: -0.0093\n",
            "Epoch [378/1000], Step [6/8], d_loss: 9.4280, g_loss: -0.0245\n",
            "Epoch [378/1000], Step [7/8], d_loss: 1193.9464, g_loss: -0.0005\n",
            "Epoch [378/1000], Step [8/8], d_loss: 18.4535, g_loss: -0.0000\n",
            "Epoch [379/1000], Step [1/8], d_loss: 9.6473, g_loss: -0.0000\n",
            "Epoch [379/1000], Step [2/8], d_loss: 376.4892, g_loss: -0.0046\n",
            "Epoch [379/1000], Step [3/8], d_loss: 8.9266, g_loss: -0.0078\n",
            "Epoch [379/1000], Step [4/8], d_loss: 11.7686, g_loss: -0.0000\n",
            "Epoch [379/1000], Step [5/8], d_loss: 775.3476, g_loss: -0.0000\n",
            "Epoch [379/1000], Step [6/8], d_loss: 978.5911, g_loss: -0.0009\n",
            "Epoch [379/1000], Step [7/8], d_loss: 1715.7273, g_loss: -0.0000\n",
            "Epoch [379/1000], Step [8/8], d_loss: 18.9019, g_loss: -0.0001\n",
            "Epoch [380/1000], Step [1/8], d_loss: 1790.4138, g_loss: -0.0183\n",
            "Epoch [380/1000], Step [2/8], d_loss: 8.7831, g_loss: -0.0000\n",
            "Epoch [380/1000], Step [3/8], d_loss: 2747.7188, g_loss: -0.0000\n",
            "Epoch [380/1000], Step [4/8], d_loss: 4381.2578, g_loss: -0.0000\n",
            "Epoch [380/1000], Step [5/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [380/1000], Step [6/8], d_loss: 8.9885, g_loss: -0.0000\n",
            "Epoch [380/1000], Step [7/8], d_loss: 8.9097, g_loss: -0.0002\n",
            "Epoch [380/1000], Step [8/8], d_loss: 27.6538, g_loss: -0.0000\n",
            "Epoch [381/1000], Step [1/8], d_loss: 8.9952, g_loss: -0.0000\n",
            "Epoch [381/1000], Step [2/8], d_loss: 943.1049, g_loss: -0.0000\n",
            "Epoch [381/1000], Step [3/8], d_loss: 8.8889, g_loss: -0.0000\n",
            "Epoch [381/1000], Step [4/8], d_loss: 180.7651, g_loss: -0.0000\n",
            "Epoch [381/1000], Step [5/8], d_loss: 8.9814, g_loss: -0.0000\n",
            "Epoch [381/1000], Step [6/8], d_loss: 4770.5713, g_loss: -0.0000\n",
            "Epoch [381/1000], Step [7/8], d_loss: 16.8868, g_loss: -0.0000\n",
            "Epoch [381/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [382/1000], Step [1/8], d_loss: 8.6583, g_loss: -0.0000\n",
            "Epoch [382/1000], Step [2/8], d_loss: 1041.9768, g_loss: -0.0000\n",
            "Epoch [382/1000], Step [3/8], d_loss: 9.0310, g_loss: -0.0000\n",
            "Epoch [382/1000], Step [4/8], d_loss: 2827.6992, g_loss: -0.0000\n",
            "Epoch [382/1000], Step [5/8], d_loss: 28.6522, g_loss: -0.0081\n",
            "Epoch [382/1000], Step [6/8], d_loss: 8.8152, g_loss: -0.0000\n",
            "Epoch [382/1000], Step [7/8], d_loss: 242.5519, g_loss: -0.0000\n",
            "Epoch [382/1000], Step [8/8], d_loss: 544.5311, g_loss: -0.0000\n",
            "Epoch [383/1000], Step [1/8], d_loss: 8.7726, g_loss: -0.0000\n",
            "Epoch [383/1000], Step [2/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [383/1000], Step [3/8], d_loss: 9.0298, g_loss: -0.0000\n",
            "Epoch [383/1000], Step [4/8], d_loss: 1844.6699, g_loss: -0.0000\n",
            "Epoch [383/1000], Step [5/8], d_loss: 311.2733, g_loss: -0.0000\n",
            "Epoch [383/1000], Step [6/8], d_loss: 8.9615, g_loss: -0.0000\n",
            "Epoch [383/1000], Step [7/8], d_loss: 566.9108, g_loss: -0.0000\n",
            "Epoch [383/1000], Step [8/8], d_loss: 145.3566, g_loss: -0.0435\n",
            "Epoch [384/1000], Step [1/8], d_loss: 16.9163, g_loss: -0.0000\n",
            "Epoch [384/1000], Step [2/8], d_loss: 3958.5005, g_loss: -0.0001\n",
            "Epoch [384/1000], Step [3/8], d_loss: 5178.7485, g_loss: -0.0000\n",
            "Epoch [384/1000], Step [4/8], d_loss: 109.4678, g_loss: -0.0000\n",
            "Epoch [384/1000], Step [5/8], d_loss: 178.3218, g_loss: -0.0243\n",
            "Epoch [384/1000], Step [6/8], d_loss: 8.8385, g_loss: -0.0000\n",
            "Epoch [384/1000], Step [7/8], d_loss: 3383.1799, g_loss: -0.0000\n",
            "Epoch [384/1000], Step [8/8], d_loss: 261.8183, g_loss: -0.0000\n",
            "Epoch [385/1000], Step [1/8], d_loss: 14.2157, g_loss: -0.0000\n",
            "Epoch [385/1000], Step [2/8], d_loss: 9.0076, g_loss: -0.0000\n",
            "Epoch [385/1000], Step [3/8], d_loss: 1733.1411, g_loss: -0.0000\n",
            "Epoch [385/1000], Step [4/8], d_loss: 9.0138, g_loss: -0.0184\n",
            "Epoch [385/1000], Step [5/8], d_loss: 56.3937, g_loss: -0.0000\n",
            "Epoch [385/1000], Step [6/8], d_loss: 7479.3540, g_loss: -0.0000\n",
            "Epoch [385/1000], Step [7/8], d_loss: 8.9604, g_loss: -0.0000\n",
            "Epoch [385/1000], Step [8/8], d_loss: 8.6444, g_loss: -0.0000\n",
            "Epoch [386/1000], Step [1/8], d_loss: 9.0982, g_loss: -0.0000\n",
            "Epoch [386/1000], Step [2/8], d_loss: 669.9939, g_loss: -0.0003\n",
            "Epoch [386/1000], Step [3/8], d_loss: 701.1857, g_loss: -0.0000\n",
            "Epoch [386/1000], Step [4/8], d_loss: 882.3060, g_loss: -0.0000\n",
            "Epoch [386/1000], Step [5/8], d_loss: 9.0372, g_loss: -0.0000\n",
            "Epoch [386/1000], Step [6/8], d_loss: 8.9972, g_loss: -0.0023\n",
            "Epoch [386/1000], Step [7/8], d_loss: 3902.4885, g_loss: -0.0000\n",
            "Epoch [386/1000], Step [8/8], d_loss: 2154.7002, g_loss: -0.0000\n",
            "Epoch [387/1000], Step [1/8], d_loss: 8.6155, g_loss: -0.0313\n",
            "Epoch [387/1000], Step [2/8], d_loss: 795.7769, g_loss: -0.0000\n",
            "Epoch [387/1000], Step [3/8], d_loss: 8.6706, g_loss: -0.0000\n",
            "Epoch [387/1000], Step [4/8], d_loss: 3824.2495, g_loss: -0.0000\n",
            "Epoch [387/1000], Step [5/8], d_loss: 9.7220, g_loss: -0.0001\n",
            "Epoch [387/1000], Step [6/8], d_loss: 8.9804, g_loss: -0.0001\n",
            "Epoch [387/1000], Step [7/8], d_loss: 115.1552, g_loss: -0.0313\n",
            "Epoch [387/1000], Step [8/8], d_loss: 8.9970, g_loss: -0.0000\n",
            "Epoch [388/1000], Step [1/8], d_loss: 9.0092, g_loss: -0.0313\n",
            "Epoch [388/1000], Step [2/8], d_loss: 11.3334, g_loss: -0.0000\n",
            "Epoch [388/1000], Step [3/8], d_loss: 9.0288, g_loss: -0.0313\n",
            "Epoch [388/1000], Step [4/8], d_loss: 2081.9131, g_loss: -0.0000\n",
            "Epoch [388/1000], Step [5/8], d_loss: 13.6792, g_loss: -0.0000\n",
            "Epoch [388/1000], Step [6/8], d_loss: 377.2943, g_loss: -0.0012\n",
            "Epoch [388/1000], Step [7/8], d_loss: 1564.6062, g_loss: -0.0003\n",
            "Epoch [388/1000], Step [8/8], d_loss: 36.7977, g_loss: -0.0000\n",
            "Epoch [389/1000], Step [1/8], d_loss: 9.0247, g_loss: -0.0000\n",
            "Epoch [389/1000], Step [2/8], d_loss: 27.8985, g_loss: -0.0000\n",
            "Epoch [389/1000], Step [3/8], d_loss: 2667.6626, g_loss: -0.0000\n",
            "Epoch [389/1000], Step [4/8], d_loss: 9.0623, g_loss: -0.0000\n",
            "Epoch [389/1000], Step [5/8], d_loss: 17.3781, g_loss: -0.0000\n",
            "Epoch [389/1000], Step [6/8], d_loss: 133.2713, g_loss: -0.0593\n",
            "Epoch [389/1000], Step [7/8], d_loss: 41.6914, g_loss: -0.0000\n",
            "Epoch [389/1000], Step [8/8], d_loss: 8.9845, g_loss: -0.0000\n",
            "Epoch [390/1000], Step [1/8], d_loss: 581.3541, g_loss: -0.0000\n",
            "Epoch [390/1000], Step [2/8], d_loss: 22.2476, g_loss: -0.0000\n",
            "Epoch [390/1000], Step [3/8], d_loss: 2768.1482, g_loss: -0.0000\n",
            "Epoch [390/1000], Step [4/8], d_loss: 13.0082, g_loss: -0.0429\n",
            "Epoch [390/1000], Step [5/8], d_loss: 105.6404, g_loss: -0.0000\n",
            "Epoch [390/1000], Step [6/8], d_loss: 8.5746, g_loss: -0.0017\n",
            "Epoch [390/1000], Step [7/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [390/1000], Step [8/8], d_loss: 2397.2358, g_loss: -0.0008\n",
            "Epoch [391/1000], Step [1/8], d_loss: 140.0646, g_loss: -0.0003\n",
            "Epoch [391/1000], Step [2/8], d_loss: 3065.8689, g_loss: -0.0001\n",
            "Epoch [391/1000], Step [3/8], d_loss: 58.9101, g_loss: -0.0003\n",
            "Epoch [391/1000], Step [4/8], d_loss: 8.7673, g_loss: -0.0000\n",
            "Epoch [391/1000], Step [5/8], d_loss: 5595.7339, g_loss: -0.0000\n",
            "Epoch [391/1000], Step [6/8], d_loss: 11.2653, g_loss: -0.0000\n",
            "Epoch [391/1000], Step [7/8], d_loss: 8.7449, g_loss: -0.0001\n",
            "Epoch [391/1000], Step [8/8], d_loss: 9.0502, g_loss: -0.0000\n",
            "Epoch [392/1000], Step [1/8], d_loss: 5877.3452, g_loss: -0.0000\n",
            "Epoch [392/1000], Step [2/8], d_loss: 79.2759, g_loss: -0.0000\n",
            "Epoch [392/1000], Step [3/8], d_loss: 8.8093, g_loss: -0.0000\n",
            "Epoch [392/1000], Step [4/8], d_loss: 5239.2002, g_loss: -0.0000\n",
            "Epoch [392/1000], Step [5/8], d_loss: 8.8395, g_loss: -0.0000\n",
            "Epoch [392/1000], Step [6/8], d_loss: 8.9723, g_loss: -0.0000\n",
            "Epoch [392/1000], Step [7/8], d_loss: 10.0684, g_loss: -0.0000\n",
            "Epoch [392/1000], Step [8/8], d_loss: 8.8675, g_loss: -0.0000\n",
            "Epoch [393/1000], Step [1/8], d_loss: 8.8993, g_loss: -0.0000\n",
            "Epoch [393/1000], Step [2/8], d_loss: 1555.0339, g_loss: -0.0000\n",
            "Epoch [393/1000], Step [3/8], d_loss: 1532.0039, g_loss: -0.0000\n",
            "Epoch [393/1000], Step [4/8], d_loss: 593.3856, g_loss: -0.0000\n",
            "Epoch [393/1000], Step [5/8], d_loss: 661.8235, g_loss: -0.0000\n",
            "Epoch [393/1000], Step [6/8], d_loss: 8.8124, g_loss: -0.0000\n",
            "Epoch [393/1000], Step [7/8], d_loss: 1158.7628, g_loss: -0.0000\n",
            "Epoch [393/1000], Step [8/8], d_loss: 4143.4224, g_loss: -0.0000\n",
            "Epoch [394/1000], Step [1/8], d_loss: 82.3653, g_loss: -0.0000\n",
            "Epoch [394/1000], Step [2/8], d_loss: 11.1348, g_loss: -0.0000\n",
            "Epoch [394/1000], Step [3/8], d_loss: 457.5128, g_loss: -0.0000\n",
            "Epoch [394/1000], Step [4/8], d_loss: 8.7958, g_loss: -0.0000\n",
            "Epoch [394/1000], Step [5/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [394/1000], Step [6/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [394/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [394/1000], Step [8/8], d_loss: 8.9746, g_loss: -0.0000\n",
            "Epoch [395/1000], Step [1/8], d_loss: 2936.5928, g_loss: -0.0000\n",
            "Epoch [395/1000], Step [2/8], d_loss: 379.0948, g_loss: -0.0000\n",
            "Epoch [395/1000], Step [3/8], d_loss: 222.9553, g_loss: -0.0000\n",
            "Epoch [395/1000], Step [4/8], d_loss: 8.9593, g_loss: -0.0000\n",
            "Epoch [395/1000], Step [5/8], d_loss: 9.0219, g_loss: -0.0000\n",
            "Epoch [395/1000], Step [6/8], d_loss: 1768.9075, g_loss: -0.0000\n",
            "Epoch [395/1000], Step [7/8], d_loss: 8.8131, g_loss: -0.0000\n",
            "Epoch [395/1000], Step [8/8], d_loss: 15.6489, g_loss: -0.0000\n",
            "Epoch [396/1000], Step [1/8], d_loss: 6340.8086, g_loss: -0.0000\n",
            "Epoch [396/1000], Step [2/8], d_loss: 10.1183, g_loss: -0.0000\n",
            "Epoch [396/1000], Step [3/8], d_loss: 192.6345, g_loss: -0.0000\n",
            "Epoch [396/1000], Step [4/8], d_loss: 169.3148, g_loss: -0.0000\n",
            "Epoch [396/1000], Step [5/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [396/1000], Step [6/8], d_loss: 3074.7803, g_loss: -0.0000\n",
            "Epoch [396/1000], Step [7/8], d_loss: 89.8095, g_loss: -0.0001\n",
            "Epoch [396/1000], Step [8/8], d_loss: 302.7619, g_loss: -0.0000\n",
            "Epoch [397/1000], Step [1/8], d_loss: 5286.2295, g_loss: -0.0000\n",
            "Epoch [397/1000], Step [2/8], d_loss: 78.8526, g_loss: -0.0000\n",
            "Epoch [397/1000], Step [3/8], d_loss: 8.6989, g_loss: -0.0000\n",
            "Epoch [397/1000], Step [4/8], d_loss: 1158.5614, g_loss: -0.0000\n",
            "Epoch [397/1000], Step [5/8], d_loss: 9.0152, g_loss: -0.0000\n",
            "Epoch [397/1000], Step [6/8], d_loss: 14.4428, g_loss: -0.0000\n",
            "Epoch [397/1000], Step [7/8], d_loss: 8.9367, g_loss: -0.0000\n",
            "Epoch [397/1000], Step [8/8], d_loss: 8.9865, g_loss: -0.0000\n",
            "Epoch [398/1000], Step [1/8], d_loss: 53.9901, g_loss: -0.0000\n",
            "Epoch [398/1000], Step [2/8], d_loss: 2699.4756, g_loss: -0.0000\n",
            "Epoch [398/1000], Step [3/8], d_loss: 3331.9243, g_loss: -0.0000\n",
            "Epoch [398/1000], Step [4/8], d_loss: 9.0563, g_loss: -0.0000\n",
            "Epoch [398/1000], Step [5/8], d_loss: 298.1771, g_loss: -0.0000\n",
            "Epoch [398/1000], Step [6/8], d_loss: 9.0136, g_loss: -0.0312\n",
            "Epoch [398/1000], Step [7/8], d_loss: 9.1550, g_loss: -0.0000\n",
            "Epoch [398/1000], Step [8/8], d_loss: 571.4418, g_loss: -0.0000\n",
            "Epoch [399/1000], Step [1/8], d_loss: 103.8459, g_loss: -0.0000\n",
            "Epoch [399/1000], Step [2/8], d_loss: 9.0490, g_loss: -0.0000\n",
            "Epoch [399/1000], Step [3/8], d_loss: 11.5241, g_loss: -0.0000\n",
            "Epoch [399/1000], Step [4/8], d_loss: 8.7498, g_loss: -0.0312\n",
            "Epoch [399/1000], Step [5/8], d_loss: 8.8790, g_loss: -0.0000\n",
            "Epoch [399/1000], Step [6/8], d_loss: 309.4129, g_loss: -0.0000\n",
            "Epoch [399/1000], Step [7/8], d_loss: 8.8295, g_loss: -0.0000\n",
            "Epoch [399/1000], Step [8/8], d_loss: 117.5626, g_loss: -0.0000\n",
            "Epoch [400/1000], Step [1/8], d_loss: 9.0309, g_loss: -0.0000\n",
            "Epoch [400/1000], Step [2/8], d_loss: 8.5155, g_loss: -0.0000\n",
            "Epoch [400/1000], Step [3/8], d_loss: 8.6862, g_loss: -0.0000\n",
            "Epoch [400/1000], Step [4/8], d_loss: 514.1216, g_loss: -0.0000\n",
            "Epoch [400/1000], Step [5/8], d_loss: 8.5471, g_loss: -0.0000\n",
            "Epoch [400/1000], Step [6/8], d_loss: 8.9959, g_loss: -0.0000\n",
            "Epoch [400/1000], Step [7/8], d_loss: 9.0232, g_loss: -0.0000\n",
            "Epoch [400/1000], Step [8/8], d_loss: 13.4312, g_loss: -0.0000\n",
            "Epoch [401/1000], Step [1/8], d_loss: 9.6160, g_loss: -0.0000\n",
            "Epoch [401/1000], Step [2/8], d_loss: 212.8686, g_loss: -0.0000\n",
            "Epoch [401/1000], Step [3/8], d_loss: 8.7369, g_loss: -0.0000\n",
            "Epoch [401/1000], Step [4/8], d_loss: 8.8206, g_loss: -0.0000\n",
            "Epoch [401/1000], Step [5/8], d_loss: 9.0625, g_loss: -0.0000\n",
            "Epoch [401/1000], Step [6/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [401/1000], Step [7/8], d_loss: 8.3780, g_loss: -0.0000\n",
            "Epoch [401/1000], Step [8/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [402/1000], Step [1/8], d_loss: 4797.0415, g_loss: -0.0000\n",
            "Epoch [402/1000], Step [2/8], d_loss: 9.0625, g_loss: -0.0000\n",
            "Epoch [402/1000], Step [3/8], d_loss: 13.0120, g_loss: -0.0000\n",
            "Epoch [402/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [402/1000], Step [5/8], d_loss: 9.0104, g_loss: -0.0000\n",
            "Epoch [402/1000], Step [6/8], d_loss: 8.7086, g_loss: -0.0000\n",
            "Epoch [402/1000], Step [7/8], d_loss: 8.7622, g_loss: -0.0000\n",
            "Epoch [402/1000], Step [8/8], d_loss: 70.2725, g_loss: -0.0000\n",
            "Epoch [403/1000], Step [1/8], d_loss: 9.0405, g_loss: -0.0000\n",
            "Epoch [403/1000], Step [2/8], d_loss: 574.2308, g_loss: -0.0000\n",
            "Epoch [403/1000], Step [3/8], d_loss: 2002.8845, g_loss: -0.0000\n",
            "Epoch [403/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [403/1000], Step [5/8], d_loss: 82.7672, g_loss: -0.0000\n",
            "Epoch [403/1000], Step [6/8], d_loss: 8.8087, g_loss: -0.0000\n",
            "Epoch [403/1000], Step [7/8], d_loss: 3246.3765, g_loss: -0.0000\n",
            "Epoch [403/1000], Step [8/8], d_loss: 9.0360, g_loss: -0.0000\n",
            "Epoch [404/1000], Step [1/8], d_loss: 10.4855, g_loss: -0.0000\n",
            "Epoch [404/1000], Step [2/8], d_loss: 1567.0128, g_loss: -0.0000\n",
            "Epoch [404/1000], Step [3/8], d_loss: 993.8651, g_loss: -0.0000\n",
            "Epoch [404/1000], Step [4/8], d_loss: 8.9940, g_loss: -0.0000\n",
            "Epoch [404/1000], Step [5/8], d_loss: 416.3662, g_loss: -0.0000\n",
            "Epoch [404/1000], Step [6/8], d_loss: 8.8997, g_loss: -0.0000\n",
            "Epoch [404/1000], Step [7/8], d_loss: 10.9363, g_loss: -0.0000\n",
            "Epoch [404/1000], Step [8/8], d_loss: 9.0379, g_loss: -0.0000\n",
            "Epoch [405/1000], Step [1/8], d_loss: 1389.2601, g_loss: -0.0000\n",
            "Epoch [405/1000], Step [2/8], d_loss: 9.0299, g_loss: -0.0000\n",
            "Epoch [405/1000], Step [3/8], d_loss: 8.9779, g_loss: -0.0000\n",
            "Epoch [405/1000], Step [4/8], d_loss: 8.7319, g_loss: -0.0000\n",
            "Epoch [405/1000], Step [5/8], d_loss: 8.9854, g_loss: -0.0000\n",
            "Epoch [405/1000], Step [6/8], d_loss: 9.0391, g_loss: -0.0000\n",
            "Epoch [405/1000], Step [7/8], d_loss: 9.0227, g_loss: -0.0000\n",
            "Epoch [405/1000], Step [8/8], d_loss: 8.7814, g_loss: -0.0000\n",
            "Epoch [406/1000], Step [1/8], d_loss: 8.7556, g_loss: -0.0000\n",
            "Epoch [406/1000], Step [2/8], d_loss: 8.9831, g_loss: -0.0000\n",
            "Epoch [406/1000], Step [3/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [406/1000], Step [4/8], d_loss: 9.3866, g_loss: -0.0000\n",
            "Epoch [406/1000], Step [5/8], d_loss: 9.0358, g_loss: -0.0000\n",
            "Epoch [406/1000], Step [6/8], d_loss: 1317.9487, g_loss: -0.0000\n",
            "Epoch [406/1000], Step [7/8], d_loss: 393.1185, g_loss: -0.0000\n",
            "Epoch [406/1000], Step [8/8], d_loss: 9.0384, g_loss: -0.0000\n",
            "Epoch [407/1000], Step [1/8], d_loss: 1874.1962, g_loss: -0.0000\n",
            "Epoch [407/1000], Step [2/8], d_loss: 8.7293, g_loss: -0.0001\n",
            "Epoch [407/1000], Step [3/8], d_loss: 8.7637, g_loss: -0.0000\n",
            "Epoch [407/1000], Step [4/8], d_loss: 8.3778, g_loss: -0.0000\n",
            "Epoch [407/1000], Step [5/8], d_loss: 2033.3053, g_loss: -0.0000\n",
            "Epoch [407/1000], Step [6/8], d_loss: 2300.5737, g_loss: -0.0000\n",
            "Epoch [407/1000], Step [7/8], d_loss: 764.9016, g_loss: -0.0000\n",
            "Epoch [407/1000], Step [8/8], d_loss: 8.5963, g_loss: -0.0000\n",
            "Epoch [408/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [408/1000], Step [2/8], d_loss: 5242.7319, g_loss: -0.0000\n",
            "Epoch [408/1000], Step [3/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [408/1000], Step [4/8], d_loss: 271.0133, g_loss: -0.0000\n",
            "Epoch [408/1000], Step [5/8], d_loss: 8.8397, g_loss: -0.0000\n",
            "Epoch [408/1000], Step [6/8], d_loss: 9.0420, g_loss: -0.0000\n",
            "Epoch [408/1000], Step [7/8], d_loss: 9.0955, g_loss: -0.0000\n",
            "Epoch [408/1000], Step [8/8], d_loss: 8.9966, g_loss: -0.0000\n",
            "Epoch [409/1000], Step [1/8], d_loss: 9.0189, g_loss: -0.0000\n",
            "Epoch [409/1000], Step [2/8], d_loss: 8.8704, g_loss: -0.0000\n",
            "Epoch [409/1000], Step [3/8], d_loss: 120.3244, g_loss: -0.0000\n",
            "Epoch [409/1000], Step [4/8], d_loss: 910.3485, g_loss: -0.0000\n",
            "Epoch [409/1000], Step [5/8], d_loss: 8.9989, g_loss: -0.0000\n",
            "Epoch [409/1000], Step [6/8], d_loss: 8.6954, g_loss: -0.0000\n",
            "Epoch [409/1000], Step [7/8], d_loss: 8.8742, g_loss: -0.0000\n",
            "Epoch [409/1000], Step [8/8], d_loss: 8.5838, g_loss: -0.0001\n",
            "Epoch [410/1000], Step [1/8], d_loss: 7404.6406, g_loss: -0.0000\n",
            "Epoch [410/1000], Step [2/8], d_loss: 9.0128, g_loss: -0.0000\n",
            "Epoch [410/1000], Step [3/8], d_loss: 419.6359, g_loss: -0.0000\n",
            "Epoch [410/1000], Step [4/8], d_loss: 9.2993, g_loss: -0.0000\n",
            "Epoch [410/1000], Step [5/8], d_loss: 1642.5195, g_loss: -0.0000\n",
            "Epoch [410/1000], Step [6/8], d_loss: 347.2638, g_loss: -0.0000\n",
            "Epoch [410/1000], Step [7/8], d_loss: 79.1496, g_loss: -0.0000\n",
            "Epoch [410/1000], Step [8/8], d_loss: 9.0435, g_loss: -0.0000\n",
            "Epoch [411/1000], Step [1/8], d_loss: 2784.7114, g_loss: -0.0000\n",
            "Epoch [411/1000], Step [2/8], d_loss: 15.4688, g_loss: -0.0000\n",
            "Epoch [411/1000], Step [3/8], d_loss: 185.3176, g_loss: -0.0000\n",
            "Epoch [411/1000], Step [4/8], d_loss: 100.0788, g_loss: -0.0000\n",
            "Epoch [411/1000], Step [5/8], d_loss: 2082.3955, g_loss: -0.0000\n",
            "Epoch [411/1000], Step [6/8], d_loss: 8.9786, g_loss: -0.0000\n",
            "Epoch [411/1000], Step [7/8], d_loss: 323.5459, g_loss: -0.0000\n",
            "Epoch [411/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [412/1000], Step [1/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [412/1000], Step [2/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [412/1000], Step [3/8], d_loss: 85.6896, g_loss: -0.0000\n",
            "Epoch [412/1000], Step [4/8], d_loss: 44.4946, g_loss: -0.0000\n",
            "Epoch [412/1000], Step [5/8], d_loss: 9.0192, g_loss: -0.0000\n",
            "Epoch [412/1000], Step [6/8], d_loss: 2582.9919, g_loss: -0.0000\n",
            "Epoch [412/1000], Step [7/8], d_loss: 8.2633, g_loss: -0.0000\n",
            "Epoch [412/1000], Step [8/8], d_loss: 9.0813, g_loss: -0.0000\n",
            "Epoch [413/1000], Step [1/8], d_loss: 1518.7817, g_loss: -0.0000\n",
            "Epoch [413/1000], Step [2/8], d_loss: 76.6964, g_loss: -0.0000\n",
            "Epoch [413/1000], Step [3/8], d_loss: 8.9207, g_loss: -0.0000\n",
            "Epoch [413/1000], Step [4/8], d_loss: 8508.7461, g_loss: -0.0000\n",
            "Epoch [413/1000], Step [5/8], d_loss: 9.5998, g_loss: -0.0000\n",
            "Epoch [413/1000], Step [6/8], d_loss: 78.3813, g_loss: -0.0000\n",
            "Epoch [413/1000], Step [7/8], d_loss: 8.9239, g_loss: -0.0000\n",
            "Epoch [413/1000], Step [8/8], d_loss: 10.5233, g_loss: -0.0000\n",
            "Epoch [414/1000], Step [1/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [414/1000], Step [2/8], d_loss: 9.0293, g_loss: -0.0000\n",
            "Epoch [414/1000], Step [3/8], d_loss: 53.4835, g_loss: -0.0000\n",
            "Epoch [414/1000], Step [4/8], d_loss: 37.7847, g_loss: -0.0000\n",
            "Epoch [414/1000], Step [5/8], d_loss: 479.8714, g_loss: -0.0000\n",
            "Epoch [414/1000], Step [6/8], d_loss: 442.7703, g_loss: -0.0000\n",
            "Epoch [414/1000], Step [7/8], d_loss: 1078.6588, g_loss: -0.0000\n",
            "Epoch [414/1000], Step [8/8], d_loss: 9.0435, g_loss: -0.0000\n",
            "Epoch [415/1000], Step [1/8], d_loss: 1113.6144, g_loss: -0.0000\n",
            "Epoch [415/1000], Step [2/8], d_loss: 48.2104, g_loss: -0.0000\n",
            "Epoch [415/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [415/1000], Step [4/8], d_loss: 1521.5447, g_loss: -0.0000\n",
            "Epoch [415/1000], Step [5/8], d_loss: 8.6650, g_loss: -0.0000\n",
            "Epoch [415/1000], Step [6/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [415/1000], Step [7/8], d_loss: 8.9979, g_loss: -0.0000\n",
            "Epoch [415/1000], Step [8/8], d_loss: 1725.1654, g_loss: -0.0000\n",
            "Epoch [416/1000], Step [1/8], d_loss: 8.9420, g_loss: -0.0000\n",
            "Epoch [416/1000], Step [2/8], d_loss: 8.4481, g_loss: -0.0000\n",
            "Epoch [416/1000], Step [3/8], d_loss: 1807.6754, g_loss: -0.0000\n",
            "Epoch [416/1000], Step [4/8], d_loss: 9.6354, g_loss: -0.0000\n",
            "Epoch [416/1000], Step [5/8], d_loss: 9.0252, g_loss: -0.0000\n",
            "Epoch [416/1000], Step [6/8], d_loss: 1817.8599, g_loss: -0.0000\n",
            "Epoch [416/1000], Step [7/8], d_loss: 9.0611, g_loss: -0.0000\n",
            "Epoch [416/1000], Step [8/8], d_loss: 9.0364, g_loss: -0.0000\n",
            "Epoch [417/1000], Step [1/8], d_loss: 9.0312, g_loss: -0.0309\n",
            "Epoch [417/1000], Step [2/8], d_loss: 8.7120, g_loss: -0.0000\n",
            "Epoch [417/1000], Step [3/8], d_loss: 8.7037, g_loss: -0.0278\n",
            "Epoch [417/1000], Step [4/8], d_loss: 5791.4980, g_loss: -0.0000\n",
            "Epoch [417/1000], Step [5/8], d_loss: 225.4848, g_loss: -0.0000\n",
            "Epoch [417/1000], Step [6/8], d_loss: 7919.8877, g_loss: -0.0002\n",
            "Epoch [417/1000], Step [7/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [417/1000], Step [8/8], d_loss: 4274.9697, g_loss: -0.0435\n",
            "Epoch [418/1000], Step [1/8], d_loss: 109.2714, g_loss: -0.0000\n",
            "Epoch [418/1000], Step [2/8], d_loss: 9.0938, g_loss: -0.0000\n",
            "Epoch [418/1000], Step [3/8], d_loss: 9.0308, g_loss: -0.0312\n",
            "Epoch [418/1000], Step [4/8], d_loss: 8.7719, g_loss: -0.0289\n",
            "Epoch [418/1000], Step [5/8], d_loss: 1460.1349, g_loss: -0.0000\n",
            "Epoch [418/1000], Step [6/8], d_loss: 8.9198, g_loss: -0.0000\n",
            "Epoch [418/1000], Step [7/8], d_loss: 8.7852, g_loss: -0.0312\n",
            "Epoch [418/1000], Step [8/8], d_loss: 3146.2524, g_loss: -0.0000\n",
            "Epoch [419/1000], Step [1/8], d_loss: 8.7563, g_loss: -0.0312\n",
            "Epoch [419/1000], Step [2/8], d_loss: 2079.4875, g_loss: -0.0000\n",
            "Epoch [419/1000], Step [3/8], d_loss: 1871.9755, g_loss: -0.0000\n",
            "Epoch [419/1000], Step [4/8], d_loss: 658.7952, g_loss: -0.0000\n",
            "Epoch [419/1000], Step [5/8], d_loss: 8.8813, g_loss: -0.0000\n",
            "Epoch [419/1000], Step [6/8], d_loss: 32.2965, g_loss: -0.0000\n",
            "Epoch [419/1000], Step [7/8], d_loss: 203.7147, g_loss: -0.0000\n",
            "Epoch [419/1000], Step [8/8], d_loss: 462.0882, g_loss: -0.0000\n",
            "Epoch [420/1000], Step [1/8], d_loss: 9.4148, g_loss: -0.0000\n",
            "Epoch [420/1000], Step [2/8], d_loss: 94.8864, g_loss: -0.0000\n",
            "Epoch [420/1000], Step [3/8], d_loss: 207.0223, g_loss: -0.0000\n",
            "Epoch [420/1000], Step [4/8], d_loss: 341.0204, g_loss: -0.0000\n",
            "Epoch [420/1000], Step [5/8], d_loss: 8.9609, g_loss: -0.0000\n",
            "Epoch [420/1000], Step [6/8], d_loss: 9.0277, g_loss: -0.0000\n",
            "Epoch [420/1000], Step [7/8], d_loss: 8.9995, g_loss: -0.0312\n",
            "Epoch [420/1000], Step [8/8], d_loss: 8.5884, g_loss: -0.0000\n",
            "Epoch [421/1000], Step [1/8], d_loss: 8.7251, g_loss: -0.0000\n",
            "Epoch [421/1000], Step [2/8], d_loss: 183.5879, g_loss: -0.0000\n",
            "Epoch [421/1000], Step [3/8], d_loss: 8.9975, g_loss: -0.0000\n",
            "Epoch [421/1000], Step [4/8], d_loss: 8.9985, g_loss: -0.0000\n",
            "Epoch [421/1000], Step [5/8], d_loss: 188.2534, g_loss: -0.0352\n",
            "Epoch [421/1000], Step [6/8], d_loss: 8.5653, g_loss: -0.0000\n",
            "Epoch [421/1000], Step [7/8], d_loss: 13.7564, g_loss: -0.0000\n",
            "Epoch [421/1000], Step [8/8], d_loss: 108.7325, g_loss: -0.0000\n",
            "Epoch [422/1000], Step [1/8], d_loss: 9.0284, g_loss: -0.0000\n",
            "Epoch [422/1000], Step [2/8], d_loss: 2348.9092, g_loss: -0.0000\n",
            "Epoch [422/1000], Step [3/8], d_loss: 8.8014, g_loss: -0.0000\n",
            "Epoch [422/1000], Step [4/8], d_loss: 9.0351, g_loss: -0.0000\n",
            "Epoch [422/1000], Step [5/8], d_loss: 9.0227, g_loss: -0.0000\n",
            "Epoch [422/1000], Step [6/8], d_loss: 2070.8762, g_loss: -0.0000\n",
            "Epoch [422/1000], Step [7/8], d_loss: 8.9520, g_loss: -0.0000\n",
            "Epoch [422/1000], Step [8/8], d_loss: 762.8176, g_loss: -0.0000\n",
            "Epoch [423/1000], Step [1/8], d_loss: 2767.0520, g_loss: -0.0000\n",
            "Epoch [423/1000], Step [2/8], d_loss: 86.6550, g_loss: -0.0000\n",
            "Epoch [423/1000], Step [3/8], d_loss: 4400.8755, g_loss: -0.0000\n",
            "Epoch [423/1000], Step [4/8], d_loss: 8.6827, g_loss: -0.0002\n",
            "Epoch [423/1000], Step [5/8], d_loss: 3384.4434, g_loss: -0.0000\n",
            "Epoch [423/1000], Step [6/8], d_loss: 9.0615, g_loss: -0.0000\n",
            "Epoch [423/1000], Step [7/8], d_loss: 2867.4575, g_loss: -0.0000\n",
            "Epoch [423/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [424/1000], Step [1/8], d_loss: 457.5762, g_loss: -0.0000\n",
            "Epoch [424/1000], Step [2/8], d_loss: 14.0328, g_loss: -0.0000\n",
            "Epoch [424/1000], Step [3/8], d_loss: 10.2618, g_loss: -0.0000\n",
            "Epoch [424/1000], Step [4/8], d_loss: 8.8804, g_loss: -0.0000\n",
            "Epoch [424/1000], Step [5/8], d_loss: 9.8317, g_loss: -0.0000\n",
            "Epoch [424/1000], Step [6/8], d_loss: 5335.9033, g_loss: -0.0000\n",
            "Epoch [424/1000], Step [7/8], d_loss: 9.1250, g_loss: -0.0000\n",
            "Epoch [424/1000], Step [8/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [425/1000], Step [1/8], d_loss: 501.7269, g_loss: -0.0000\n",
            "Epoch [425/1000], Step [2/8], d_loss: 1357.9227, g_loss: -0.0000\n",
            "Epoch [425/1000], Step [3/8], d_loss: 22.4445, g_loss: -0.0000\n",
            "Epoch [425/1000], Step [4/8], d_loss: 6100.9941, g_loss: -0.0000\n",
            "Epoch [425/1000], Step [5/8], d_loss: 882.7511, g_loss: -0.0000\n",
            "Epoch [425/1000], Step [6/8], d_loss: 34.9208, g_loss: -0.0000\n",
            "Epoch [425/1000], Step [7/8], d_loss: 4853.4604, g_loss: -0.0000\n",
            "Epoch [425/1000], Step [8/8], d_loss: 9.0868, g_loss: -0.0000\n",
            "Epoch [426/1000], Step [1/8], d_loss: 28.2415, g_loss: -0.0000\n",
            "Epoch [426/1000], Step [2/8], d_loss: 5113.9189, g_loss: -0.0000\n",
            "Epoch [426/1000], Step [3/8], d_loss: 9.0288, g_loss: -0.0000\n",
            "Epoch [426/1000], Step [4/8], d_loss: 8.8848, g_loss: -0.0000\n",
            "Epoch [426/1000], Step [5/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [426/1000], Step [6/8], d_loss: 1378.0271, g_loss: -0.0000\n",
            "Epoch [426/1000], Step [7/8], d_loss: 8.4991, g_loss: -0.0000\n",
            "Epoch [426/1000], Step [8/8], d_loss: 9.6429, g_loss: -0.0000\n",
            "Epoch [427/1000], Step [1/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [427/1000], Step [2/8], d_loss: 451.2189, g_loss: -0.0012\n",
            "Epoch [427/1000], Step [3/8], d_loss: 8.8209, g_loss: -0.0312\n",
            "Epoch [427/1000], Step [4/8], d_loss: 8.8593, g_loss: -0.0000\n",
            "Epoch [427/1000], Step [5/8], d_loss: 8.9972, g_loss: -0.0000\n",
            "Epoch [427/1000], Step [6/8], d_loss: 34.3729, g_loss: -0.0000\n",
            "Epoch [427/1000], Step [7/8], d_loss: 28.0845, g_loss: -0.0007\n",
            "Epoch [427/1000], Step [8/8], d_loss: 20.2948, g_loss: -0.0434\n",
            "Epoch [428/1000], Step [1/8], d_loss: 904.2660, g_loss: -0.0000\n",
            "Epoch [428/1000], Step [2/8], d_loss: 212.8773, g_loss: -0.0000\n",
            "Epoch [428/1000], Step [3/8], d_loss: 8.9931, g_loss: -0.0000\n",
            "Epoch [428/1000], Step [4/8], d_loss: 8.9908, g_loss: -0.0000\n",
            "Epoch [428/1000], Step [5/8], d_loss: 10.5133, g_loss: -0.0000\n",
            "Epoch [428/1000], Step [6/8], d_loss: 8.7753, g_loss: -0.0000\n",
            "Epoch [428/1000], Step [7/8], d_loss: 3461.9751, g_loss: -0.0000\n",
            "Epoch [428/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [429/1000], Step [1/8], d_loss: 3040.8010, g_loss: -0.0000\n",
            "Epoch [429/1000], Step [2/8], d_loss: 26.3414, g_loss: -0.0000\n",
            "Epoch [429/1000], Step [3/8], d_loss: 846.7646, g_loss: -0.0000\n",
            "Epoch [429/1000], Step [4/8], d_loss: 1422.3688, g_loss: -0.0000\n",
            "Epoch [429/1000], Step [5/8], d_loss: 726.0098, g_loss: -0.0000\n",
            "Epoch [429/1000], Step [6/8], d_loss: 2980.4668, g_loss: -0.0000\n",
            "Epoch [429/1000], Step [7/8], d_loss: 18.7727, g_loss: -0.0000\n",
            "Epoch [429/1000], Step [8/8], d_loss: 1157.3344, g_loss: -0.0000\n",
            "Epoch [430/1000], Step [1/8], d_loss: 143.9975, g_loss: -0.0191\n",
            "Epoch [430/1000], Step [2/8], d_loss: 46.6437, g_loss: -0.0014\n",
            "Epoch [430/1000], Step [3/8], d_loss: 66.7073, g_loss: -0.0000\n",
            "Epoch [430/1000], Step [4/8], d_loss: 8.9019, g_loss: -0.0000\n",
            "Epoch [430/1000], Step [5/8], d_loss: 8.9481, g_loss: -0.0000\n",
            "Epoch [430/1000], Step [6/8], d_loss: 8.9932, g_loss: -0.0000\n",
            "Epoch [430/1000], Step [7/8], d_loss: 8.9182, g_loss: -0.0000\n",
            "Epoch [430/1000], Step [8/8], d_loss: 2956.6567, g_loss: -0.0000\n",
            "Epoch [431/1000], Step [1/8], d_loss: 8.9898, g_loss: -0.0000\n",
            "Epoch [431/1000], Step [2/8], d_loss: 15.0194, g_loss: -0.0000\n",
            "Epoch [431/1000], Step [3/8], d_loss: 1042.6580, g_loss: -0.0000\n",
            "Epoch [431/1000], Step [4/8], d_loss: 8.9952, g_loss: -0.0000\n",
            "Epoch [431/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [431/1000], Step [6/8], d_loss: 16.9870, g_loss: -0.0000\n",
            "Epoch [431/1000], Step [7/8], d_loss: 1583.2023, g_loss: -0.0000\n",
            "Epoch [431/1000], Step [8/8], d_loss: 891.9554, g_loss: -0.0000\n",
            "Epoch [432/1000], Step [1/8], d_loss: 8.9948, g_loss: -0.0000\n",
            "Epoch [432/1000], Step [2/8], d_loss: 8.7143, g_loss: -0.0000\n",
            "Epoch [432/1000], Step [3/8], d_loss: 162.0573, g_loss: -0.0000\n",
            "Epoch [432/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [432/1000], Step [5/8], d_loss: 37.4955, g_loss: -0.0000\n",
            "Epoch [432/1000], Step [6/8], d_loss: 34.8055, g_loss: -0.0000\n",
            "Epoch [432/1000], Step [7/8], d_loss: 576.0705, g_loss: -0.0000\n",
            "Epoch [432/1000], Step [8/8], d_loss: 280.4452, g_loss: -0.0000\n",
            "Epoch [433/1000], Step [1/8], d_loss: 8.4888, g_loss: -0.0000\n",
            "Epoch [433/1000], Step [2/8], d_loss: 547.7532, g_loss: -0.0000\n",
            "Epoch [433/1000], Step [3/8], d_loss: 8.9991, g_loss: -0.0000\n",
            "Epoch [433/1000], Step [4/8], d_loss: 1195.6833, g_loss: -0.0000\n",
            "Epoch [433/1000], Step [5/8], d_loss: 4592.6357, g_loss: -0.0000\n",
            "Epoch [433/1000], Step [6/8], d_loss: 280.6769, g_loss: -0.0000\n",
            "Epoch [433/1000], Step [7/8], d_loss: 1586.4285, g_loss: -0.0000\n",
            "Epoch [433/1000], Step [8/8], d_loss: 8.5682, g_loss: -0.0000\n",
            "Epoch [434/1000], Step [1/8], d_loss: 5403.7271, g_loss: -0.0000\n",
            "Epoch [434/1000], Step [2/8], d_loss: 25.3085, g_loss: -0.0000\n",
            "Epoch [434/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [434/1000], Step [4/8], d_loss: 1437.0605, g_loss: -0.0000\n",
            "Epoch [434/1000], Step [5/8], d_loss: 8.6951, g_loss: -0.0000\n",
            "Epoch [434/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [434/1000], Step [7/8], d_loss: 8.9949, g_loss: -0.0000\n",
            "Epoch [434/1000], Step [8/8], d_loss: 61.6582, g_loss: -0.0000\n",
            "Epoch [435/1000], Step [1/8], d_loss: 61.9949, g_loss: -0.0000\n",
            "Epoch [435/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [435/1000], Step [3/8], d_loss: 8.8012, g_loss: -0.0000\n",
            "Epoch [435/1000], Step [4/8], d_loss: 3698.9099, g_loss: -0.0000\n",
            "Epoch [435/1000], Step [5/8], d_loss: 150.1737, g_loss: -0.0000\n",
            "Epoch [435/1000], Step [6/8], d_loss: 8.9946, g_loss: -0.0000\n",
            "Epoch [435/1000], Step [7/8], d_loss: 8.9992, g_loss: -0.0000\n",
            "Epoch [435/1000], Step [8/8], d_loss: 8.7966, g_loss: -0.0000\n",
            "Epoch [436/1000], Step [1/8], d_loss: 9.6873, g_loss: -0.0000\n",
            "Epoch [436/1000], Step [2/8], d_loss: 112.5440, g_loss: -0.0000\n",
            "Epoch [436/1000], Step [3/8], d_loss: 10.6458, g_loss: -0.0000\n",
            "Epoch [436/1000], Step [4/8], d_loss: 12.5967, g_loss: -0.0000\n",
            "Epoch [436/1000], Step [5/8], d_loss: 1923.0192, g_loss: -0.0000\n",
            "Epoch [436/1000], Step [6/8], d_loss: 1189.1537, g_loss: -0.0000\n",
            "Epoch [436/1000], Step [7/8], d_loss: 20.6312, g_loss: -0.0000\n",
            "Epoch [436/1000], Step [8/8], d_loss: 114.4099, g_loss: -0.0000\n",
            "Epoch [437/1000], Step [1/8], d_loss: 8.9907, g_loss: -0.0000\n",
            "Epoch [437/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [437/1000], Step [3/8], d_loss: 8.9370, g_loss: -0.0000\n",
            "Epoch [437/1000], Step [4/8], d_loss: 8.6762, g_loss: -0.0000\n",
            "Epoch [437/1000], Step [5/8], d_loss: 2413.0066, g_loss: -0.0000\n",
            "Epoch [437/1000], Step [6/8], d_loss: 30.4949, g_loss: -0.0000\n",
            "Epoch [437/1000], Step [7/8], d_loss: 8.9854, g_loss: -0.0000\n",
            "Epoch [437/1000], Step [8/8], d_loss: 8.6607, g_loss: -0.0000\n",
            "Epoch [438/1000], Step [1/8], d_loss: 69.5215, g_loss: -0.0000\n",
            "Epoch [438/1000], Step [2/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [438/1000], Step [3/8], d_loss: 472.9938, g_loss: -0.0000\n",
            "Epoch [438/1000], Step [4/8], d_loss: 1739.8080, g_loss: -0.0000\n",
            "Epoch [438/1000], Step [5/8], d_loss: 6048.9312, g_loss: -0.0000\n",
            "Epoch [438/1000], Step [6/8], d_loss: 1112.7069, g_loss: -0.0000\n",
            "Epoch [438/1000], Step [7/8], d_loss: 27.7188, g_loss: -0.0000\n",
            "Epoch [438/1000], Step [8/8], d_loss: 1754.5869, g_loss: -0.0000\n",
            "Epoch [439/1000], Step [1/8], d_loss: 8.8773, g_loss: -0.0000\n",
            "Epoch [439/1000], Step [2/8], d_loss: 10.8430, g_loss: -0.0000\n",
            "Epoch [439/1000], Step [3/8], d_loss: 8.8661, g_loss: -0.0000\n",
            "Epoch [439/1000], Step [4/8], d_loss: 9.5122, g_loss: -0.0000\n",
            "Epoch [439/1000], Step [5/8], d_loss: 8.9996, g_loss: -0.0002\n",
            "Epoch [439/1000], Step [6/8], d_loss: 20.4828, g_loss: -0.0000\n",
            "Epoch [439/1000], Step [7/8], d_loss: 615.7524, g_loss: -0.0312\n",
            "Epoch [439/1000], Step [8/8], d_loss: 12.3216, g_loss: -0.0005\n",
            "Epoch [440/1000], Step [1/8], d_loss: 23.9948, g_loss: -0.0000\n",
            "Epoch [440/1000], Step [2/8], d_loss: 40.6916, g_loss: -0.0313\n",
            "Epoch [440/1000], Step [3/8], d_loss: 56.8641, g_loss: -0.0004\n",
            "Epoch [440/1000], Step [4/8], d_loss: 1718.0984, g_loss: -0.0000\n",
            "Epoch [440/1000], Step [5/8], d_loss: 1892.1377, g_loss: -0.0000\n",
            "Epoch [440/1000], Step [6/8], d_loss: 923.3780, g_loss: -0.0000\n",
            "Epoch [440/1000], Step [7/8], d_loss: 14.4821, g_loss: -0.0000\n",
            "Epoch [440/1000], Step [8/8], d_loss: 8.8937, g_loss: -0.0000\n",
            "Epoch [441/1000], Step [1/8], d_loss: 8.8447, g_loss: -0.0000\n",
            "Epoch [441/1000], Step [2/8], d_loss: 4449.7891, g_loss: -0.0000\n",
            "Epoch [441/1000], Step [3/8], d_loss: 969.5301, g_loss: -0.0000\n",
            "Epoch [441/1000], Step [4/8], d_loss: 8.9889, g_loss: -0.0000\n",
            "Epoch [441/1000], Step [5/8], d_loss: 776.9062, g_loss: -0.0000\n",
            "Epoch [441/1000], Step [6/8], d_loss: 1508.8062, g_loss: -0.0000\n",
            "Epoch [441/1000], Step [7/8], d_loss: 8.9957, g_loss: -0.0000\n",
            "Epoch [441/1000], Step [8/8], d_loss: 9.0371, g_loss: -0.0391\n",
            "Epoch [442/1000], Step [1/8], d_loss: 416.6897, g_loss: -0.0002\n",
            "Epoch [442/1000], Step [2/8], d_loss: 8.9986, g_loss: -0.0000\n",
            "Epoch [442/1000], Step [3/8], d_loss: 630.4288, g_loss: -0.0314\n",
            "Epoch [442/1000], Step [4/8], d_loss: 8.9935, g_loss: -0.0000\n",
            "Epoch [442/1000], Step [5/8], d_loss: 8.7588, g_loss: -0.0000\n",
            "Epoch [442/1000], Step [6/8], d_loss: 139.5968, g_loss: -0.0000\n",
            "Epoch [442/1000], Step [7/8], d_loss: 840.6105, g_loss: -0.0000\n",
            "Epoch [442/1000], Step [8/8], d_loss: 9.0512, g_loss: -0.0000\n",
            "Epoch [443/1000], Step [1/8], d_loss: 8.7328, g_loss: -0.0009\n",
            "Epoch [443/1000], Step [2/8], d_loss: 8.9697, g_loss: -0.0194\n",
            "Epoch [443/1000], Step [3/8], d_loss: 3772.4395, g_loss: -0.0002\n",
            "Epoch [443/1000], Step [4/8], d_loss: 1546.1510, g_loss: -0.0000\n",
            "Epoch [443/1000], Step [5/8], d_loss: 8.8007, g_loss: -0.0000\n",
            "Epoch [443/1000], Step [6/8], d_loss: 18.0160, g_loss: -0.0000\n",
            "Epoch [443/1000], Step [7/8], d_loss: 1717.5815, g_loss: -0.0000\n",
            "Epoch [443/1000], Step [8/8], d_loss: 54.9773, g_loss: -0.0354\n",
            "Epoch [444/1000], Step [1/8], d_loss: 8.4785, g_loss: -0.0214\n",
            "Epoch [444/1000], Step [2/8], d_loss: 8.8340, g_loss: -0.0000\n",
            "Epoch [444/1000], Step [3/8], d_loss: 76.0393, g_loss: -0.0000\n",
            "Epoch [444/1000], Step [4/8], d_loss: 934.6953, g_loss: -0.0000\n",
            "Epoch [444/1000], Step [5/8], d_loss: 2183.8584, g_loss: -0.0000\n",
            "Epoch [444/1000], Step [6/8], d_loss: 3156.9893, g_loss: -0.0000\n",
            "Epoch [444/1000], Step [7/8], d_loss: 9.1250, g_loss: -0.0000\n",
            "Epoch [444/1000], Step [8/8], d_loss: 8.6376, g_loss: -0.0000\n",
            "Epoch [445/1000], Step [1/8], d_loss: 85.5764, g_loss: -0.0000\n",
            "Epoch [445/1000], Step [2/8], d_loss: 804.1149, g_loss: -0.0323\n",
            "Epoch [445/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [445/1000], Step [4/8], d_loss: 1884.3215, g_loss: -0.0000\n",
            "Epoch [445/1000], Step [5/8], d_loss: 8.9304, g_loss: -0.0000\n",
            "Epoch [445/1000], Step [6/8], d_loss: 8.9669, g_loss: -0.0000\n",
            "Epoch [445/1000], Step [7/8], d_loss: 186.3413, g_loss: -0.0000\n",
            "Epoch [445/1000], Step [8/8], d_loss: 9.0435, g_loss: -0.0000\n",
            "Epoch [446/1000], Step [1/8], d_loss: 4646.1558, g_loss: -0.0000\n",
            "Epoch [446/1000], Step [2/8], d_loss: 2149.7102, g_loss: -0.0000\n",
            "Epoch [446/1000], Step [3/8], d_loss: 8.8643, g_loss: -0.0000\n",
            "Epoch [446/1000], Step [4/8], d_loss: 5288.0752, g_loss: -0.0000\n",
            "Epoch [446/1000], Step [5/8], d_loss: 8.7372, g_loss: -0.0000\n",
            "Epoch [446/1000], Step [6/8], d_loss: 492.7604, g_loss: -0.0000\n",
            "Epoch [446/1000], Step [7/8], d_loss: 261.3974, g_loss: -0.0000\n",
            "Epoch [446/1000], Step [8/8], d_loss: 9.6534, g_loss: -0.0000\n",
            "Epoch [447/1000], Step [1/8], d_loss: 9.0125, g_loss: -0.0000\n",
            "Epoch [447/1000], Step [2/8], d_loss: 30.5998, g_loss: -0.0000\n",
            "Epoch [447/1000], Step [3/8], d_loss: 180.8906, g_loss: -0.0000\n",
            "Epoch [447/1000], Step [4/8], d_loss: 9.8914, g_loss: -0.0000\n",
            "Epoch [447/1000], Step [5/8], d_loss: 391.8412, g_loss: -0.0000\n",
            "Epoch [447/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [447/1000], Step [7/8], d_loss: 775.5119, g_loss: -0.0000\n",
            "Epoch [447/1000], Step [8/8], d_loss: 9.0428, g_loss: -0.0000\n",
            "Epoch [448/1000], Step [1/8], d_loss: 14.9411, g_loss: -0.0000\n",
            "Epoch [448/1000], Step [2/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [448/1000], Step [3/8], d_loss: 2963.3640, g_loss: -0.0000\n",
            "Epoch [448/1000], Step [4/8], d_loss: 13.0045, g_loss: -0.0000\n",
            "Epoch [448/1000], Step [5/8], d_loss: 166.7201, g_loss: -0.0000\n",
            "Epoch [448/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0301\n",
            "Epoch [448/1000], Step [7/8], d_loss: 219.9095, g_loss: -0.0000\n",
            "Epoch [448/1000], Step [8/8], d_loss: 13.7277, g_loss: -0.0000\n",
            "Epoch [449/1000], Step [1/8], d_loss: 2742.4658, g_loss: -0.0009\n",
            "Epoch [449/1000], Step [2/8], d_loss: 9.0235, g_loss: -0.0000\n",
            "Epoch [449/1000], Step [3/8], d_loss: 2212.2388, g_loss: -0.0000\n",
            "Epoch [449/1000], Step [4/8], d_loss: 227.6891, g_loss: -0.0000\n",
            "Epoch [449/1000], Step [5/8], d_loss: 3069.3938, g_loss: -0.0000\n",
            "Epoch [449/1000], Step [6/8], d_loss: 1663.7048, g_loss: -0.0000\n",
            "Epoch [449/1000], Step [7/8], d_loss: 9.0300, g_loss: -0.0000\n",
            "Epoch [449/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [450/1000], Step [1/8], d_loss: 8.6055, g_loss: -0.0000\n",
            "Epoch [450/1000], Step [2/8], d_loss: 1065.5895, g_loss: -0.0000\n",
            "Epoch [450/1000], Step [3/8], d_loss: 12.1569, g_loss: -0.0000\n",
            "Epoch [450/1000], Step [4/8], d_loss: 9.0251, g_loss: -0.0000\n",
            "Epoch [450/1000], Step [5/8], d_loss: 9.0623, g_loss: -0.0000\n",
            "Epoch [450/1000], Step [6/8], d_loss: 3648.3887, g_loss: -0.0000\n",
            "Epoch [450/1000], Step [7/8], d_loss: 9.0309, g_loss: -0.0000\n",
            "Epoch [450/1000], Step [8/8], d_loss: 9.0153, g_loss: -0.0409\n",
            "Epoch [451/1000], Step [1/8], d_loss: 1661.3311, g_loss: -0.0000\n",
            "Epoch [451/1000], Step [2/8], d_loss: 24.2635, g_loss: -0.0000\n",
            "Epoch [451/1000], Step [3/8], d_loss: 11.8343, g_loss: -0.0000\n",
            "Epoch [451/1000], Step [4/8], d_loss: 203.5268, g_loss: -0.0000\n",
            "Epoch [451/1000], Step [5/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [451/1000], Step [6/8], d_loss: 8.9897, g_loss: -0.0000\n",
            "Epoch [451/1000], Step [7/8], d_loss: 32.8432, g_loss: -0.0000\n",
            "Epoch [451/1000], Step [8/8], d_loss: 1483.9486, g_loss: -0.0450\n",
            "Epoch [452/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [452/1000], Step [2/8], d_loss: 8.7576, g_loss: -0.0000\n",
            "Epoch [452/1000], Step [3/8], d_loss: 1325.2002, g_loss: -0.0000\n",
            "Epoch [452/1000], Step [4/8], d_loss: 8.9947, g_loss: -0.0000\n",
            "Epoch [452/1000], Step [5/8], d_loss: 737.2467, g_loss: -0.0313\n",
            "Epoch [452/1000], Step [6/8], d_loss: 202.6445, g_loss: -0.0000\n",
            "Epoch [452/1000], Step [7/8], d_loss: 175.4893, g_loss: -0.0000\n",
            "Epoch [452/1000], Step [8/8], d_loss: 8.9190, g_loss: -0.0000\n",
            "Epoch [453/1000], Step [1/8], d_loss: 8.7110, g_loss: -0.0000\n",
            "Epoch [453/1000], Step [2/8], d_loss: 125.7185, g_loss: -0.0000\n",
            "Epoch [453/1000], Step [3/8], d_loss: 1379.1422, g_loss: -0.0000\n",
            "Epoch [453/1000], Step [4/8], d_loss: 8.9941, g_loss: -0.0000\n",
            "Epoch [453/1000], Step [5/8], d_loss: 1443.5071, g_loss: -0.0000\n",
            "Epoch [453/1000], Step [6/8], d_loss: 29.4763, g_loss: -0.0000\n",
            "Epoch [453/1000], Step [7/8], d_loss: 11.6339, g_loss: -0.0446\n",
            "Epoch [453/1000], Step [8/8], d_loss: 1568.9927, g_loss: -0.0000\n",
            "Epoch [454/1000], Step [1/8], d_loss: 17.4154, g_loss: -0.0000\n",
            "Epoch [454/1000], Step [2/8], d_loss: 8.9322, g_loss: -0.0047\n",
            "Epoch [454/1000], Step [3/8], d_loss: 39.6931, g_loss: -0.0000\n",
            "Epoch [454/1000], Step [4/8], d_loss: 9.3428, g_loss: -0.0000\n",
            "Epoch [454/1000], Step [5/8], d_loss: 28.0971, g_loss: -0.0000\n",
            "Epoch [454/1000], Step [6/8], d_loss: 8.9436, g_loss: -0.0000\n",
            "Epoch [454/1000], Step [7/8], d_loss: 8.9991, g_loss: -0.0000\n",
            "Epoch [454/1000], Step [8/8], d_loss: 8.5228, g_loss: -0.0435\n",
            "Epoch [455/1000], Step [1/8], d_loss: 8.9803, g_loss: -0.0312\n",
            "Epoch [455/1000], Step [2/8], d_loss: 268.2187, g_loss: -0.0000\n",
            "Epoch [455/1000], Step [3/8], d_loss: 9.0007, g_loss: -0.0000\n",
            "Epoch [455/1000], Step [4/8], d_loss: 3343.2747, g_loss: -0.0000\n",
            "Epoch [455/1000], Step [5/8], d_loss: 9.7292, g_loss: -0.0000\n",
            "Epoch [455/1000], Step [6/8], d_loss: 8.9987, g_loss: -0.0002\n",
            "Epoch [455/1000], Step [7/8], d_loss: 25.6287, g_loss: -0.0000\n",
            "Epoch [455/1000], Step [8/8], d_loss: 9.0003, g_loss: -0.0000\n",
            "Epoch [456/1000], Step [1/8], d_loss: 1601.7908, g_loss: -0.0000\n",
            "Epoch [456/1000], Step [2/8], d_loss: 1071.2126, g_loss: -0.0000\n",
            "Epoch [456/1000], Step [3/8], d_loss: 1566.4062, g_loss: -0.0000\n",
            "Epoch [456/1000], Step [4/8], d_loss: 8.9998, g_loss: -0.0005\n",
            "Epoch [456/1000], Step [5/8], d_loss: 63.8871, g_loss: -0.0000\n",
            "Epoch [456/1000], Step [6/8], d_loss: 1182.8331, g_loss: -0.0000\n",
            "Epoch [456/1000], Step [7/8], d_loss: 107.3280, g_loss: -0.0000\n",
            "Epoch [456/1000], Step [8/8], d_loss: 167.9679, g_loss: -0.0000\n",
            "Epoch [457/1000], Step [1/8], d_loss: 1011.8717, g_loss: -0.0000\n",
            "Epoch [457/1000], Step [2/8], d_loss: 3985.9453, g_loss: -0.0000\n",
            "Epoch [457/1000], Step [3/8], d_loss: 2166.2524, g_loss: -0.0000\n",
            "Epoch [457/1000], Step [4/8], d_loss: 8.9763, g_loss: -0.0000\n",
            "Epoch [457/1000], Step [5/8], d_loss: 702.4528, g_loss: -0.0000\n",
            "Epoch [457/1000], Step [6/8], d_loss: 83.1327, g_loss: -0.0000\n",
            "Epoch [457/1000], Step [7/8], d_loss: 8.9899, g_loss: -0.0000\n",
            "Epoch [457/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [458/1000], Step [1/8], d_loss: 13.0396, g_loss: -0.0000\n",
            "Epoch [458/1000], Step [2/8], d_loss: 8.7503, g_loss: -0.0000\n",
            "Epoch [458/1000], Step [3/8], d_loss: 9436.7266, g_loss: -0.0000\n",
            "Epoch [458/1000], Step [4/8], d_loss: 1994.4357, g_loss: -0.0000\n",
            "Epoch [458/1000], Step [5/8], d_loss: 8.8615, g_loss: -0.0312\n",
            "Epoch [458/1000], Step [6/8], d_loss: 282.5060, g_loss: -0.0000\n",
            "Epoch [458/1000], Step [7/8], d_loss: 2160.5083, g_loss: -0.0312\n",
            "Epoch [458/1000], Step [8/8], d_loss: 11.7947, g_loss: -0.0000\n",
            "Epoch [459/1000], Step [1/8], d_loss: 4472.1899, g_loss: -0.0000\n",
            "Epoch [459/1000], Step [2/8], d_loss: 8.6940, g_loss: -0.0000\n",
            "Epoch [459/1000], Step [3/8], d_loss: 289.5121, g_loss: -0.0000\n",
            "Epoch [459/1000], Step [4/8], d_loss: 48.5022, g_loss: -0.0000\n",
            "Epoch [459/1000], Step [5/8], d_loss: 700.3118, g_loss: -0.0000\n",
            "Epoch [459/1000], Step [6/8], d_loss: 8.9856, g_loss: -0.0000\n",
            "Epoch [459/1000], Step [7/8], d_loss: 118.3917, g_loss: -0.0000\n",
            "Epoch [459/1000], Step [8/8], d_loss: 247.2858, g_loss: -0.0000\n",
            "Epoch [460/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [460/1000], Step [2/8], d_loss: 9.9623, g_loss: -0.0000\n",
            "Epoch [460/1000], Step [3/8], d_loss: 8.7147, g_loss: -0.0159\n",
            "Epoch [460/1000], Step [4/8], d_loss: 9.0198, g_loss: -0.0000\n",
            "Epoch [460/1000], Step [5/8], d_loss: 572.0052, g_loss: -0.0114\n",
            "Epoch [460/1000], Step [6/8], d_loss: 12.7177, g_loss: -0.0000\n",
            "Epoch [460/1000], Step [7/8], d_loss: 1295.9025, g_loss: -0.0000\n",
            "Epoch [460/1000], Step [8/8], d_loss: 9.0435, g_loss: -0.0000\n",
            "Epoch [461/1000], Step [1/8], d_loss: 426.7335, g_loss: -0.0000\n",
            "Epoch [461/1000], Step [2/8], d_loss: 8.9556, g_loss: -0.0000\n",
            "Epoch [461/1000], Step [3/8], d_loss: 16.7919, g_loss: -0.0313\n",
            "Epoch [461/1000], Step [4/8], d_loss: 8.8519, g_loss: -0.0000\n",
            "Epoch [461/1000], Step [5/8], d_loss: 8.9604, g_loss: -0.0000\n",
            "Epoch [461/1000], Step [6/8], d_loss: 1103.6228, g_loss: -0.0000\n",
            "Epoch [461/1000], Step [7/8], d_loss: 8.4620, g_loss: -0.0000\n",
            "Epoch [461/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [462/1000], Step [1/8], d_loss: 8.9983, g_loss: -0.0000\n",
            "Epoch [462/1000], Step [2/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [462/1000], Step [3/8], d_loss: 9481.2451, g_loss: -0.0000\n",
            "Epoch [462/1000], Step [4/8], d_loss: 8.3802, g_loss: -0.0201\n",
            "Epoch [462/1000], Step [5/8], d_loss: 8.9989, g_loss: -0.0084\n",
            "Epoch [462/1000], Step [6/8], d_loss: 8.3774, g_loss: -0.0000\n",
            "Epoch [462/1000], Step [7/8], d_loss: 8.5451, g_loss: -0.0000\n",
            "Epoch [462/1000], Step [8/8], d_loss: 286.5213, g_loss: -0.0000\n",
            "Epoch [463/1000], Step [1/8], d_loss: 23.8800, g_loss: -0.0010\n",
            "Epoch [463/1000], Step [2/8], d_loss: 1214.7802, g_loss: -0.0000\n",
            "Epoch [463/1000], Step [3/8], d_loss: 8.9637, g_loss: -0.0000\n",
            "Epoch [463/1000], Step [4/8], d_loss: 1011.3390, g_loss: -0.0276\n",
            "Epoch [463/1000], Step [5/8], d_loss: 8.9841, g_loss: -0.0000\n",
            "Epoch [463/1000], Step [6/8], d_loss: 677.8359, g_loss: -0.0000\n",
            "Epoch [463/1000], Step [7/8], d_loss: 12.5667, g_loss: -0.0000\n",
            "Epoch [463/1000], Step [8/8], d_loss: 8.9936, g_loss: -0.0000\n",
            "Epoch [464/1000], Step [1/8], d_loss: 1792.7020, g_loss: -0.0000\n",
            "Epoch [464/1000], Step [2/8], d_loss: 274.4909, g_loss: -0.0000\n",
            "Epoch [464/1000], Step [3/8], d_loss: 8.9925, g_loss: -0.0000\n",
            "Epoch [464/1000], Step [4/8], d_loss: 600.9488, g_loss: -0.0000\n",
            "Epoch [464/1000], Step [5/8], d_loss: 8.9828, g_loss: -0.0000\n",
            "Epoch [464/1000], Step [6/8], d_loss: 665.6327, g_loss: -0.0000\n",
            "Epoch [464/1000], Step [7/8], d_loss: 1579.5789, g_loss: -0.0000\n",
            "Epoch [464/1000], Step [8/8], d_loss: 2445.8711, g_loss: -0.0000\n",
            "Epoch [465/1000], Step [1/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [465/1000], Step [2/8], d_loss: 1483.0302, g_loss: -0.0000\n",
            "Epoch [465/1000], Step [3/8], d_loss: 30.5739, g_loss: -0.0384\n",
            "Epoch [465/1000], Step [4/8], d_loss: 1910.6395, g_loss: -0.0000\n",
            "Epoch [465/1000], Step [5/8], d_loss: 718.0558, g_loss: -0.0000\n",
            "Epoch [465/1000], Step [6/8], d_loss: 73.5168, g_loss: -0.0000\n",
            "Epoch [465/1000], Step [7/8], d_loss: 218.2324, g_loss: -0.0000\n",
            "Epoch [465/1000], Step [8/8], d_loss: 268.4746, g_loss: -0.0000\n",
            "Epoch [466/1000], Step [1/8], d_loss: 70.2374, g_loss: -0.0000\n",
            "Epoch [466/1000], Step [2/8], d_loss: 690.0503, g_loss: -0.0000\n",
            "Epoch [466/1000], Step [3/8], d_loss: 9.0477, g_loss: -0.0000\n",
            "Epoch [466/1000], Step [4/8], d_loss: 622.7657, g_loss: -0.0000\n",
            "Epoch [466/1000], Step [5/8], d_loss: 8.8708, g_loss: -0.0000\n",
            "Epoch [466/1000], Step [6/8], d_loss: 281.7751, g_loss: -0.0000\n",
            "Epoch [466/1000], Step [7/8], d_loss: 3390.8516, g_loss: -0.0188\n",
            "Epoch [466/1000], Step [8/8], d_loss: 11.1633, g_loss: -0.0000\n",
            "Epoch [467/1000], Step [1/8], d_loss: 8.9965, g_loss: -0.0000\n",
            "Epoch [467/1000], Step [2/8], d_loss: 8.7300, g_loss: -0.0313\n",
            "Epoch [467/1000], Step [3/8], d_loss: 1420.4380, g_loss: -0.0001\n",
            "Epoch [467/1000], Step [4/8], d_loss: 797.5033, g_loss: -0.0006\n",
            "Epoch [467/1000], Step [5/8], d_loss: 527.5959, g_loss: -0.0000\n",
            "Epoch [467/1000], Step [6/8], d_loss: 9.0605, g_loss: -0.0000\n",
            "Epoch [467/1000], Step [7/8], d_loss: 55.6230, g_loss: -0.0000\n",
            "Epoch [467/1000], Step [8/8], d_loss: 1621.1405, g_loss: -0.0000\n",
            "Epoch [468/1000], Step [1/8], d_loss: 268.5180, g_loss: -0.0009\n",
            "Epoch [468/1000], Step [2/8], d_loss: 982.0343, g_loss: -0.0000\n",
            "Epoch [468/1000], Step [3/8], d_loss: 9.0253, g_loss: -0.0001\n",
            "Epoch [468/1000], Step [4/8], d_loss: 724.1403, g_loss: -0.0000\n",
            "Epoch [468/1000], Step [5/8], d_loss: 8.9964, g_loss: -0.0004\n",
            "Epoch [468/1000], Step [6/8], d_loss: 8.9974, g_loss: -0.0000\n",
            "Epoch [468/1000], Step [7/8], d_loss: 17.9110, g_loss: -0.0000\n",
            "Epoch [468/1000], Step [8/8], d_loss: 31.1138, g_loss: -0.0001\n",
            "Epoch [469/1000], Step [1/8], d_loss: 9.0308, g_loss: -0.0063\n",
            "Epoch [469/1000], Step [2/8], d_loss: 260.3040, g_loss: -0.0313\n",
            "Epoch [469/1000], Step [3/8], d_loss: 4211.2041, g_loss: -0.0000\n",
            "Epoch [469/1000], Step [4/8], d_loss: 8.9585, g_loss: -0.0102\n",
            "Epoch [469/1000], Step [5/8], d_loss: 120.5410, g_loss: -0.0623\n",
            "Epoch [469/1000], Step [6/8], d_loss: 3721.7332, g_loss: -0.0000\n",
            "Epoch [469/1000], Step [7/8], d_loss: 8.8637, g_loss: -0.0000\n",
            "Epoch [469/1000], Step [8/8], d_loss: 9.0225, g_loss: -0.0046\n",
            "Epoch [470/1000], Step [1/8], d_loss: 1037.5936, g_loss: -0.0000\n",
            "Epoch [470/1000], Step [2/8], d_loss: 8.3859, g_loss: -0.0000\n",
            "Epoch [470/1000], Step [3/8], d_loss: 8.9257, g_loss: -0.0000\n",
            "Epoch [470/1000], Step [4/8], d_loss: 511.8644, g_loss: -0.0000\n",
            "Epoch [470/1000], Step [5/8], d_loss: 18.1550, g_loss: -0.0000\n",
            "Epoch [470/1000], Step [6/8], d_loss: 8.9998, g_loss: -0.0264\n",
            "Epoch [470/1000], Step [7/8], d_loss: 537.9439, g_loss: -0.0209\n",
            "Epoch [470/1000], Step [8/8], d_loss: 9.0054, g_loss: -0.0000\n",
            "Epoch [471/1000], Step [1/8], d_loss: 9.0625, g_loss: -0.0000\n",
            "Epoch [471/1000], Step [2/8], d_loss: 1302.7823, g_loss: -0.0000\n",
            "Epoch [471/1000], Step [3/8], d_loss: 151.5839, g_loss: -0.0000\n",
            "Epoch [471/1000], Step [4/8], d_loss: 952.7168, g_loss: -0.0000\n",
            "Epoch [471/1000], Step [5/8], d_loss: 11.0398, g_loss: -0.0000\n",
            "Epoch [471/1000], Step [6/8], d_loss: 9.0124, g_loss: -0.0001\n",
            "Epoch [471/1000], Step [7/8], d_loss: 8.6746, g_loss: -0.0001\n",
            "Epoch [471/1000], Step [8/8], d_loss: 8.9992, g_loss: -0.0000\n",
            "Epoch [472/1000], Step [1/8], d_loss: 8.9570, g_loss: -0.0000\n",
            "Epoch [472/1000], Step [2/8], d_loss: 239.8091, g_loss: -0.0000\n",
            "Epoch [472/1000], Step [3/8], d_loss: 429.8295, g_loss: -0.0000\n",
            "Epoch [472/1000], Step [4/8], d_loss: 1580.4319, g_loss: -0.0003\n",
            "Epoch [472/1000], Step [5/8], d_loss: 8.9248, g_loss: -0.0000\n",
            "Epoch [472/1000], Step [6/8], d_loss: 1791.7791, g_loss: -0.0000\n",
            "Epoch [472/1000], Step [7/8], d_loss: 365.1265, g_loss: -0.0312\n",
            "Epoch [472/1000], Step [8/8], d_loss: 9.0336, g_loss: -0.0000\n",
            "Epoch [473/1000], Step [1/8], d_loss: 8.8196, g_loss: -0.0000\n",
            "Epoch [473/1000], Step [2/8], d_loss: 9.0453, g_loss: -0.0000\n",
            "Epoch [473/1000], Step [3/8], d_loss: 8.9281, g_loss: -0.0000\n",
            "Epoch [473/1000], Step [4/8], d_loss: 8.8826, g_loss: -0.0000\n",
            "Epoch [473/1000], Step [5/8], d_loss: 239.3422, g_loss: -0.0000\n",
            "Epoch [473/1000], Step [6/8], d_loss: 8.9402, g_loss: -0.0000\n",
            "Epoch [473/1000], Step [7/8], d_loss: 8.9611, g_loss: -0.0000\n",
            "Epoch [473/1000], Step [8/8], d_loss: 296.5209, g_loss: -0.0000\n",
            "Epoch [474/1000], Step [1/8], d_loss: 104.5701, g_loss: -0.0000\n",
            "Epoch [474/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [474/1000], Step [3/8], d_loss: 916.9814, g_loss: -0.0210\n",
            "Epoch [474/1000], Step [4/8], d_loss: 759.7349, g_loss: -0.0000\n",
            "Epoch [474/1000], Step [5/8], d_loss: 8.9903, g_loss: -0.0000\n",
            "Epoch [474/1000], Step [6/8], d_loss: 1403.5662, g_loss: -0.0000\n",
            "Epoch [474/1000], Step [7/8], d_loss: 22.6460, g_loss: -0.0000\n",
            "Epoch [474/1000], Step [8/8], d_loss: 86.0743, g_loss: -0.0000\n",
            "Epoch [475/1000], Step [1/8], d_loss: 49.7981, g_loss: -0.0000\n",
            "Epoch [475/1000], Step [2/8], d_loss: 51.0396, g_loss: -0.0000\n",
            "Epoch [475/1000], Step [3/8], d_loss: 973.6140, g_loss: -0.0000\n",
            "Epoch [475/1000], Step [4/8], d_loss: 1114.7524, g_loss: -0.0000\n",
            "Epoch [475/1000], Step [5/8], d_loss: 42.4863, g_loss: -0.0000\n",
            "Epoch [475/1000], Step [6/8], d_loss: 13.1968, g_loss: -0.0000\n",
            "Epoch [475/1000], Step [7/8], d_loss: 116.2219, g_loss: -0.0000\n",
            "Epoch [475/1000], Step [8/8], d_loss: 8.9676, g_loss: -0.0420\n",
            "Epoch [476/1000], Step [1/8], d_loss: 8.8953, g_loss: -0.0027\n",
            "Epoch [476/1000], Step [2/8], d_loss: 2432.1582, g_loss: -0.0000\n",
            "Epoch [476/1000], Step [3/8], d_loss: 455.3108, g_loss: -0.0000\n",
            "Epoch [476/1000], Step [4/8], d_loss: 519.3475, g_loss: -0.0000\n",
            "Epoch [476/1000], Step [5/8], d_loss: 13.3808, g_loss: -0.0000\n",
            "Epoch [476/1000], Step [6/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [476/1000], Step [7/8], d_loss: 2168.8125, g_loss: -0.0000\n",
            "Epoch [476/1000], Step [8/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [477/1000], Step [1/8], d_loss: 1258.0068, g_loss: -0.0000\n",
            "Epoch [477/1000], Step [2/8], d_loss: 994.6984, g_loss: -0.0000\n",
            "Epoch [477/1000], Step [3/8], d_loss: 8.9993, g_loss: -0.0007\n",
            "Epoch [477/1000], Step [4/8], d_loss: 726.0419, g_loss: -0.0000\n",
            "Epoch [477/1000], Step [5/8], d_loss: 8.6742, g_loss: -0.0000\n",
            "Epoch [477/1000], Step [6/8], d_loss: 103.8316, g_loss: -0.0000\n",
            "Epoch [477/1000], Step [7/8], d_loss: 10.4701, g_loss: -0.0000\n",
            "Epoch [477/1000], Step [8/8], d_loss: 1565.3063, g_loss: -0.0001\n",
            "Epoch [478/1000], Step [1/8], d_loss: 557.5331, g_loss: -0.0001\n",
            "Epoch [478/1000], Step [2/8], d_loss: 2244.6060, g_loss: -0.0000\n",
            "Epoch [478/1000], Step [3/8], d_loss: 418.3912, g_loss: -0.0000\n",
            "Epoch [478/1000], Step [4/8], d_loss: 10.3153, g_loss: -0.0000\n",
            "Epoch [478/1000], Step [5/8], d_loss: 1482.2008, g_loss: -0.0001\n",
            "Epoch [478/1000], Step [6/8], d_loss: 197.8605, g_loss: -0.0008\n",
            "Epoch [478/1000], Step [7/8], d_loss: 3669.3896, g_loss: -0.0001\n",
            "Epoch [478/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0435\n",
            "Epoch [479/1000], Step [1/8], d_loss: 9.0224, g_loss: -0.0000\n",
            "Epoch [479/1000], Step [2/8], d_loss: 8.7324, g_loss: -0.0000\n",
            "Epoch [479/1000], Step [3/8], d_loss: 987.6721, g_loss: -0.0001\n",
            "Epoch [479/1000], Step [4/8], d_loss: 547.3173, g_loss: -0.0000\n",
            "Epoch [479/1000], Step [5/8], d_loss: 8.9995, g_loss: -0.0000\n",
            "Epoch [479/1000], Step [6/8], d_loss: 8.8837, g_loss: -0.0000\n",
            "Epoch [479/1000], Step [7/8], d_loss: 2124.7532, g_loss: -0.0554\n",
            "Epoch [479/1000], Step [8/8], d_loss: 8.9830, g_loss: -0.0861\n",
            "Epoch [480/1000], Step [1/8], d_loss: 9.4344, g_loss: -0.0000\n",
            "Epoch [480/1000], Step [2/8], d_loss: 4488.3896, g_loss: -0.0000\n",
            "Epoch [480/1000], Step [3/8], d_loss: 2571.4175, g_loss: -0.0000\n",
            "Epoch [480/1000], Step [4/8], d_loss: 8.9130, g_loss: -0.0000\n",
            "Epoch [480/1000], Step [5/8], d_loss: 759.9573, g_loss: -0.0000\n",
            "Epoch [480/1000], Step [6/8], d_loss: 103.9355, g_loss: -0.0356\n",
            "Epoch [480/1000], Step [7/8], d_loss: 8.3877, g_loss: -0.0009\n",
            "Epoch [480/1000], Step [8/8], d_loss: 8.9299, g_loss: -0.0000\n",
            "Epoch [481/1000], Step [1/8], d_loss: 8.9670, g_loss: -0.0313\n",
            "Epoch [481/1000], Step [2/8], d_loss: 258.1013, g_loss: -0.0000\n",
            "Epoch [481/1000], Step [3/8], d_loss: 98.3424, g_loss: -0.0000\n",
            "Epoch [481/1000], Step [4/8], d_loss: 1744.9364, g_loss: -0.0000\n",
            "Epoch [481/1000], Step [5/8], d_loss: 1162.5460, g_loss: -0.0000\n",
            "Epoch [481/1000], Step [6/8], d_loss: 2930.7556, g_loss: -0.0000\n",
            "Epoch [481/1000], Step [7/8], d_loss: 4959.0293, g_loss: -0.0000\n",
            "Epoch [481/1000], Step [8/8], d_loss: 698.4290, g_loss: -0.0000\n",
            "Epoch [482/1000], Step [1/8], d_loss: 18.6827, g_loss: -0.0000\n",
            "Epoch [482/1000], Step [2/8], d_loss: 22.2168, g_loss: -0.0000\n",
            "Epoch [482/1000], Step [3/8], d_loss: 5804.2383, g_loss: -0.0000\n",
            "Epoch [482/1000], Step [4/8], d_loss: 11.4412, g_loss: -0.0000\n",
            "Epoch [482/1000], Step [5/8], d_loss: 8.9553, g_loss: -0.0000\n",
            "Epoch [482/1000], Step [6/8], d_loss: 9.0275, g_loss: -0.0000\n",
            "Epoch [482/1000], Step [7/8], d_loss: 352.5761, g_loss: -0.0000\n",
            "Epoch [482/1000], Step [8/8], d_loss: 8.9413, g_loss: -0.0001\n",
            "Epoch [483/1000], Step [1/8], d_loss: 136.6610, g_loss: -0.0000\n",
            "Epoch [483/1000], Step [2/8], d_loss: 26.1564, g_loss: -0.0000\n",
            "Epoch [483/1000], Step [3/8], d_loss: 316.8340, g_loss: -0.0000\n",
            "Epoch [483/1000], Step [4/8], d_loss: 72.5568, g_loss: -0.0000\n",
            "Epoch [483/1000], Step [5/8], d_loss: 8.9160, g_loss: -0.0000\n",
            "Epoch [483/1000], Step [6/8], d_loss: 449.8376, g_loss: -0.0000\n",
            "Epoch [483/1000], Step [7/8], d_loss: 8.9949, g_loss: -0.0000\n",
            "Epoch [483/1000], Step [8/8], d_loss: 8.9996, g_loss: -0.0001\n",
            "Epoch [484/1000], Step [1/8], d_loss: 8.6068, g_loss: -0.0000\n",
            "Epoch [484/1000], Step [2/8], d_loss: 17.6903, g_loss: -0.0000\n",
            "Epoch [484/1000], Step [3/8], d_loss: 51.8548, g_loss: -0.0000\n",
            "Epoch [484/1000], Step [4/8], d_loss: 14.6468, g_loss: -0.0000\n",
            "Epoch [484/1000], Step [5/8], d_loss: 171.0493, g_loss: -0.0000\n",
            "Epoch [484/1000], Step [6/8], d_loss: 8.2688, g_loss: -0.0001\n",
            "Epoch [484/1000], Step [7/8], d_loss: 8.9948, g_loss: -0.0000\n",
            "Epoch [484/1000], Step [8/8], d_loss: 8.9719, g_loss: -0.0015\n",
            "Epoch [485/1000], Step [1/8], d_loss: 2127.1057, g_loss: -0.0000\n",
            "Epoch [485/1000], Step [2/8], d_loss: 2802.4109, g_loss: -0.0000\n",
            "Epoch [485/1000], Step [3/8], d_loss: 67.2239, g_loss: -0.0310\n",
            "Epoch [485/1000], Step [4/8], d_loss: 8.9938, g_loss: -0.0000\n",
            "Epoch [485/1000], Step [5/8], d_loss: 8.8521, g_loss: -0.0001\n",
            "Epoch [485/1000], Step [6/8], d_loss: 8.9040, g_loss: -0.0000\n",
            "Epoch [485/1000], Step [7/8], d_loss: 527.5761, g_loss: -0.0000\n",
            "Epoch [485/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [486/1000], Step [1/8], d_loss: 1119.3993, g_loss: -0.0000\n",
            "Epoch [486/1000], Step [2/8], d_loss: 8.9806, g_loss: -0.0000\n",
            "Epoch [486/1000], Step [3/8], d_loss: 8.5070, g_loss: -0.0000\n",
            "Epoch [486/1000], Step [4/8], d_loss: 34.8619, g_loss: -0.0000\n",
            "Epoch [486/1000], Step [5/8], d_loss: 8.9854, g_loss: -0.0000\n",
            "Epoch [486/1000], Step [6/8], d_loss: 8.8407, g_loss: -0.0000\n",
            "Epoch [486/1000], Step [7/8], d_loss: 711.4348, g_loss: -0.0000\n",
            "Epoch [486/1000], Step [8/8], d_loss: 8.9980, g_loss: -0.0000\n",
            "Epoch [487/1000], Step [1/8], d_loss: 935.0502, g_loss: -0.0086\n",
            "Epoch [487/1000], Step [2/8], d_loss: 48.2627, g_loss: -0.0000\n",
            "Epoch [487/1000], Step [3/8], d_loss: 2458.9084, g_loss: -0.0000\n",
            "Epoch [487/1000], Step [4/8], d_loss: 787.6896, g_loss: -0.0001\n",
            "Epoch [487/1000], Step [5/8], d_loss: 264.3781, g_loss: -0.0000\n",
            "Epoch [487/1000], Step [6/8], d_loss: 8.9953, g_loss: -0.0006\n",
            "Epoch [487/1000], Step [7/8], d_loss: 56.6843, g_loss: -0.0000\n",
            "Epoch [487/1000], Step [8/8], d_loss: 8.4753, g_loss: -0.0000\n",
            "Epoch [488/1000], Step [1/8], d_loss: 8.9495, g_loss: -0.0000\n",
            "Epoch [488/1000], Step [2/8], d_loss: 4157.3721, g_loss: -0.0000\n",
            "Epoch [488/1000], Step [3/8], d_loss: 8.9938, g_loss: -0.0000\n",
            "Epoch [488/1000], Step [4/8], d_loss: 8.7742, g_loss: -0.0000\n",
            "Epoch [488/1000], Step [5/8], d_loss: 1714.7948, g_loss: -0.0000\n",
            "Epoch [488/1000], Step [6/8], d_loss: 237.5591, g_loss: -0.0000\n",
            "Epoch [488/1000], Step [7/8], d_loss: 8.9462, g_loss: -0.0000\n",
            "Epoch [488/1000], Step [8/8], d_loss: 35.9673, g_loss: -0.0000\n",
            "Epoch [489/1000], Step [1/8], d_loss: 720.4129, g_loss: -0.0000\n",
            "Epoch [489/1000], Step [2/8], d_loss: 8.6963, g_loss: -0.0000\n",
            "Epoch [489/1000], Step [3/8], d_loss: 117.9935, g_loss: -0.0000\n",
            "Epoch [489/1000], Step [4/8], d_loss: 80.1845, g_loss: -0.0001\n",
            "Epoch [489/1000], Step [5/8], d_loss: 3108.0605, g_loss: -0.0000\n",
            "Epoch [489/1000], Step [6/8], d_loss: 18.8515, g_loss: -0.0016\n",
            "Epoch [489/1000], Step [7/8], d_loss: 611.0468, g_loss: -0.0000\n",
            "Epoch [489/1000], Step [8/8], d_loss: 43.4807, g_loss: -0.0000\n",
            "Epoch [490/1000], Step [1/8], d_loss: 521.1018, g_loss: -0.0000\n",
            "Epoch [490/1000], Step [2/8], d_loss: 4121.9277, g_loss: -0.0006\n",
            "Epoch [490/1000], Step [3/8], d_loss: 3291.6616, g_loss: -0.0002\n",
            "Epoch [490/1000], Step [4/8], d_loss: 711.6428, g_loss: -0.0000\n",
            "Epoch [490/1000], Step [5/8], d_loss: 8.9728, g_loss: -0.0000\n",
            "Epoch [490/1000], Step [6/8], d_loss: 931.4442, g_loss: -0.0000\n",
            "Epoch [490/1000], Step [7/8], d_loss: 1601.8176, g_loss: -0.0000\n",
            "Epoch [490/1000], Step [8/8], d_loss: 8.9778, g_loss: -0.0000\n",
            "Epoch [491/1000], Step [1/8], d_loss: 103.4107, g_loss: -0.0000\n",
            "Epoch [491/1000], Step [2/8], d_loss: 9.0146, g_loss: -0.0287\n",
            "Epoch [491/1000], Step [3/8], d_loss: 1055.9102, g_loss: -0.0481\n",
            "Epoch [491/1000], Step [4/8], d_loss: 4194.6992, g_loss: -0.0001\n",
            "Epoch [491/1000], Step [5/8], d_loss: 127.0345, g_loss: -0.0000\n",
            "Epoch [491/1000], Step [6/8], d_loss: 527.5245, g_loss: -0.0328\n",
            "Epoch [491/1000], Step [7/8], d_loss: 442.2950, g_loss: -0.0001\n",
            "Epoch [491/1000], Step [8/8], d_loss: 9.0111, g_loss: -0.0000\n",
            "Epoch [492/1000], Step [1/8], d_loss: 171.2197, g_loss: -0.0549\n",
            "Epoch [492/1000], Step [2/8], d_loss: 13.3135, g_loss: -0.0625\n",
            "Epoch [492/1000], Step [3/8], d_loss: 8.9599, g_loss: -0.0001\n",
            "Epoch [492/1000], Step [4/8], d_loss: 8.9321, g_loss: -0.0000\n",
            "Epoch [492/1000], Step [5/8], d_loss: 8.9892, g_loss: -0.0000\n",
            "Epoch [492/1000], Step [6/8], d_loss: 8.7514, g_loss: -0.0000\n",
            "Epoch [492/1000], Step [7/8], d_loss: 8.9709, g_loss: -0.0000\n",
            "Epoch [492/1000], Step [8/8], d_loss: 12.6700, g_loss: -0.0000\n",
            "Epoch [493/1000], Step [1/8], d_loss: 2441.7971, g_loss: -0.0000\n",
            "Epoch [493/1000], Step [2/8], d_loss: 8.6214, g_loss: -0.0623\n",
            "Epoch [493/1000], Step [3/8], d_loss: 274.3537, g_loss: -0.0000\n",
            "Epoch [493/1000], Step [4/8], d_loss: 2591.3440, g_loss: -0.0000\n",
            "Epoch [493/1000], Step [5/8], d_loss: 481.6593, g_loss: -0.0000\n",
            "Epoch [493/1000], Step [6/8], d_loss: 1226.2947, g_loss: -0.0000\n",
            "Epoch [493/1000], Step [7/8], d_loss: 129.4720, g_loss: -0.0000\n",
            "Epoch [493/1000], Step [8/8], d_loss: 9.0427, g_loss: -0.0000\n",
            "Epoch [494/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [494/1000], Step [2/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [494/1000], Step [3/8], d_loss: 5793.2993, g_loss: -0.0000\n",
            "Epoch [494/1000], Step [4/8], d_loss: 265.4402, g_loss: -0.0000\n",
            "Epoch [494/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [494/1000], Step [6/8], d_loss: 13.4872, g_loss: -0.0000\n",
            "Epoch [494/1000], Step [7/8], d_loss: 535.5701, g_loss: -0.0000\n",
            "Epoch [494/1000], Step [8/8], d_loss: 12.1119, g_loss: -0.0000\n",
            "Epoch [495/1000], Step [1/8], d_loss: 1748.9122, g_loss: -0.0000\n",
            "Epoch [495/1000], Step [2/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [495/1000], Step [3/8], d_loss: 8.5990, g_loss: -0.0000\n",
            "Epoch [495/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [495/1000], Step [5/8], d_loss: 96.3323, g_loss: -0.0001\n",
            "Epoch [495/1000], Step [6/8], d_loss: 7192.9131, g_loss: -0.0000\n",
            "Epoch [495/1000], Step [7/8], d_loss: 8.5972, g_loss: -0.0000\n",
            "Epoch [495/1000], Step [8/8], d_loss: 3867.1016, g_loss: -0.0000\n",
            "Epoch [496/1000], Step [1/8], d_loss: 9.0794, g_loss: -0.0000\n",
            "Epoch [496/1000], Step [2/8], d_loss: 13.7158, g_loss: -0.0000\n",
            "Epoch [496/1000], Step [3/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [496/1000], Step [4/8], d_loss: 8.8603, g_loss: -0.0000\n",
            "Epoch [496/1000], Step [5/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [496/1000], Step [6/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [496/1000], Step [7/8], d_loss: 280.3306, g_loss: -0.0000\n",
            "Epoch [496/1000], Step [8/8], d_loss: 488.8668, g_loss: -0.0000\n",
            "Epoch [497/1000], Step [1/8], d_loss: 8.9130, g_loss: -0.0000\n",
            "Epoch [497/1000], Step [2/8], d_loss: 8.5097, g_loss: -0.0000\n",
            "Epoch [497/1000], Step [3/8], d_loss: 8.9896, g_loss: -0.0000\n",
            "Epoch [497/1000], Step [4/8], d_loss: 2583.3186, g_loss: -0.0122\n",
            "Epoch [497/1000], Step [5/8], d_loss: 9.0312, g_loss: -0.0312\n",
            "Epoch [497/1000], Step [6/8], d_loss: 16.0366, g_loss: -0.0000\n",
            "Epoch [497/1000], Step [7/8], d_loss: 8.9196, g_loss: -0.0138\n",
            "Epoch [497/1000], Step [8/8], d_loss: 9.0004, g_loss: -0.0000\n",
            "Epoch [498/1000], Step [1/8], d_loss: 8.7425, g_loss: -0.0000\n",
            "Epoch [498/1000], Step [2/8], d_loss: 248.7270, g_loss: -0.0000\n",
            "Epoch [498/1000], Step [3/8], d_loss: 10.1211, g_loss: -0.0313\n",
            "Epoch [498/1000], Step [4/8], d_loss: 9.0224, g_loss: -0.0625\n",
            "Epoch [498/1000], Step [5/8], d_loss: 10976.0195, g_loss: -0.0000\n",
            "Epoch [498/1000], Step [6/8], d_loss: 2065.7109, g_loss: -0.0022\n",
            "Epoch [498/1000], Step [7/8], d_loss: 24.0149, g_loss: -0.0000\n",
            "Epoch [498/1000], Step [8/8], d_loss: 5278.6802, g_loss: -0.0000\n",
            "Epoch [499/1000], Step [1/8], d_loss: 8.9098, g_loss: -0.0314\n",
            "Epoch [499/1000], Step [2/8], d_loss: 9.0625, g_loss: -0.0252\n",
            "Epoch [499/1000], Step [3/8], d_loss: 8.7506, g_loss: -0.0296\n",
            "Epoch [499/1000], Step [4/8], d_loss: 833.4767, g_loss: -0.1006\n",
            "Epoch [499/1000], Step [5/8], d_loss: 9.0019, g_loss: -0.0236\n",
            "Epoch [499/1000], Step [6/8], d_loss: 8.9874, g_loss: -0.0312\n",
            "Epoch [499/1000], Step [7/8], d_loss: 1482.7955, g_loss: -0.0000\n",
            "Epoch [499/1000], Step [8/8], d_loss: 2263.8018, g_loss: -0.0000\n",
            "Epoch [500/1000], Step [1/8], d_loss: 28.8457, g_loss: -0.0313\n",
            "Epoch [500/1000], Step [2/8], d_loss: 15.7767, g_loss: -0.0000\n",
            "Epoch [500/1000], Step [3/8], d_loss: 8.7194, g_loss: -0.0000\n",
            "Epoch [500/1000], Step [4/8], d_loss: 8.9334, g_loss: -0.0000\n",
            "Epoch [500/1000], Step [5/8], d_loss: 8.8715, g_loss: -0.0000\n",
            "Epoch [500/1000], Step [6/8], d_loss: 8398.6377, g_loss: -0.0000\n",
            "Epoch [500/1000], Step [7/8], d_loss: 14.3486, g_loss: -0.0008\n",
            "Epoch [500/1000], Step [8/8], d_loss: 9.3659, g_loss: -0.0000\n",
            "Epoch [501/1000], Step [1/8], d_loss: 14.8582, g_loss: -0.0000\n",
            "Epoch [501/1000], Step [2/8], d_loss: 1958.5875, g_loss: -0.0104\n",
            "Epoch [501/1000], Step [3/8], d_loss: 8.8646, g_loss: -0.0001\n",
            "Epoch [501/1000], Step [4/8], d_loss: 51.7141, g_loss: -0.0000\n",
            "Epoch [501/1000], Step [5/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [501/1000], Step [6/8], d_loss: 8.9908, g_loss: -0.0007\n",
            "Epoch [501/1000], Step [7/8], d_loss: 13.7549, g_loss: -0.0000\n",
            "Epoch [501/1000], Step [8/8], d_loss: 6370.8340, g_loss: -0.0000\n",
            "Epoch [502/1000], Step [1/8], d_loss: 11.4623, g_loss: -0.0027\n",
            "Epoch [502/1000], Step [2/8], d_loss: 1671.5659, g_loss: -0.0000\n",
            "Epoch [502/1000], Step [3/8], d_loss: 9.0301, g_loss: -0.0000\n",
            "Epoch [502/1000], Step [4/8], d_loss: 441.1252, g_loss: -0.0000\n",
            "Epoch [502/1000], Step [5/8], d_loss: 21.2096, g_loss: -0.0000\n",
            "Epoch [502/1000], Step [6/8], d_loss: 1044.9363, g_loss: -0.0000\n",
            "Epoch [502/1000], Step [7/8], d_loss: 22.4579, g_loss: -0.0000\n",
            "Epoch [502/1000], Step [8/8], d_loss: 8.6751, g_loss: -0.0000\n",
            "Epoch [503/1000], Step [1/8], d_loss: 1135.0537, g_loss: -0.0312\n",
            "Epoch [503/1000], Step [2/8], d_loss: 8.6402, g_loss: -0.0000\n",
            "Epoch [503/1000], Step [3/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [503/1000], Step [4/8], d_loss: 8.9896, g_loss: -0.0000\n",
            "Epoch [503/1000], Step [5/8], d_loss: 66.5223, g_loss: -0.0312\n",
            "Epoch [503/1000], Step [6/8], d_loss: 2330.7415, g_loss: -0.0370\n",
            "Epoch [503/1000], Step [7/8], d_loss: 8.8582, g_loss: -0.0313\n",
            "Epoch [503/1000], Step [8/8], d_loss: 10.8082, g_loss: -0.0141\n",
            "Epoch [504/1000], Step [1/8], d_loss: 4487.3325, g_loss: -0.0000\n",
            "Epoch [504/1000], Step [2/8], d_loss: 1032.0496, g_loss: -0.0625\n",
            "Epoch [504/1000], Step [3/8], d_loss: 1918.5518, g_loss: -0.0000\n",
            "Epoch [504/1000], Step [4/8], d_loss: 2359.8184, g_loss: -0.0000\n",
            "Epoch [504/1000], Step [5/8], d_loss: 8.7392, g_loss: -0.0000\n",
            "Epoch [504/1000], Step [6/8], d_loss: 48.7336, g_loss: -0.0328\n",
            "Epoch [504/1000], Step [7/8], d_loss: 50.7261, g_loss: -0.0016\n",
            "Epoch [504/1000], Step [8/8], d_loss: 42.6246, g_loss: -0.0000\n",
            "Epoch [505/1000], Step [1/8], d_loss: 287.1258, g_loss: -0.0000\n",
            "Epoch [505/1000], Step [2/8], d_loss: 29.4133, g_loss: -0.0001\n",
            "Epoch [505/1000], Step [3/8], d_loss: 951.5062, g_loss: -0.0625\n",
            "Epoch [505/1000], Step [4/8], d_loss: 132.1258, g_loss: -0.0294\n",
            "Epoch [505/1000], Step [5/8], d_loss: 8.5723, g_loss: -0.0000\n",
            "Epoch [505/1000], Step [6/8], d_loss: 35.6003, g_loss: -0.0000\n",
            "Epoch [505/1000], Step [7/8], d_loss: 8.9984, g_loss: -0.0000\n",
            "Epoch [505/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [506/1000], Step [1/8], d_loss: 11.6387, g_loss: -0.0000\n",
            "Epoch [506/1000], Step [2/8], d_loss: 8.7055, g_loss: -0.0000\n",
            "Epoch [506/1000], Step [3/8], d_loss: 8.7852, g_loss: -0.0000\n",
            "Epoch [506/1000], Step [4/8], d_loss: 5051.7812, g_loss: -0.0313\n",
            "Epoch [506/1000], Step [5/8], d_loss: 8.6767, g_loss: -0.0013\n",
            "Epoch [506/1000], Step [6/8], d_loss: 9.0116, g_loss: -0.0001\n",
            "Epoch [506/1000], Step [7/8], d_loss: 8.9057, g_loss: -0.0000\n",
            "Epoch [506/1000], Step [8/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [507/1000], Step [1/8], d_loss: 8.6726, g_loss: -0.0000\n",
            "Epoch [507/1000], Step [2/8], d_loss: 76.9489, g_loss: -0.0000\n",
            "Epoch [507/1000], Step [3/8], d_loss: 9.0222, g_loss: -0.0000\n",
            "Epoch [507/1000], Step [4/8], d_loss: 3143.4712, g_loss: -0.0000\n",
            "Epoch [507/1000], Step [5/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [507/1000], Step [6/8], d_loss: 8.9891, g_loss: -0.0000\n",
            "Epoch [507/1000], Step [7/8], d_loss: 8.7623, g_loss: -0.0000\n",
            "Epoch [507/1000], Step [8/8], d_loss: 8.2985, g_loss: -0.0000\n",
            "Epoch [508/1000], Step [1/8], d_loss: 298.5425, g_loss: -0.0000\n",
            "Epoch [508/1000], Step [2/8], d_loss: 8.9299, g_loss: -0.0000\n",
            "Epoch [508/1000], Step [3/8], d_loss: 2433.6721, g_loss: -0.0000\n",
            "Epoch [508/1000], Step [4/8], d_loss: 283.1487, g_loss: -0.0000\n",
            "Epoch [508/1000], Step [5/8], d_loss: 9.1250, g_loss: -0.0000\n",
            "Epoch [508/1000], Step [6/8], d_loss: 688.0802, g_loss: -0.0313\n",
            "Epoch [508/1000], Step [7/8], d_loss: 235.6371, g_loss: -0.0000\n",
            "Epoch [508/1000], Step [8/8], d_loss: 597.0038, g_loss: -0.0000\n",
            "Epoch [509/1000], Step [1/8], d_loss: 4020.9507, g_loss: -0.0000\n",
            "Epoch [509/1000], Step [2/8], d_loss: 6611.5776, g_loss: -0.0000\n",
            "Epoch [509/1000], Step [3/8], d_loss: 9.0235, g_loss: -0.0000\n",
            "Epoch [509/1000], Step [4/8], d_loss: 805.4315, g_loss: -0.0000\n",
            "Epoch [509/1000], Step [5/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [509/1000], Step [6/8], d_loss: 9.0909, g_loss: -0.0000\n",
            "Epoch [509/1000], Step [7/8], d_loss: 833.6186, g_loss: -0.0000\n",
            "Epoch [509/1000], Step [8/8], d_loss: 151.6389, g_loss: -0.0000\n",
            "Epoch [510/1000], Step [1/8], d_loss: 9.0303, g_loss: -0.0000\n",
            "Epoch [510/1000], Step [2/8], d_loss: 8.7499, g_loss: -0.0000\n",
            "Epoch [510/1000], Step [3/8], d_loss: 24.4196, g_loss: -0.0000\n",
            "Epoch [510/1000], Step [4/8], d_loss: 631.8807, g_loss: -0.0000\n",
            "Epoch [510/1000], Step [5/8], d_loss: 118.0684, g_loss: -0.0000\n",
            "Epoch [510/1000], Step [6/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [510/1000], Step [7/8], d_loss: 379.8310, g_loss: -0.0000\n",
            "Epoch [510/1000], Step [8/8], d_loss: 550.7623, g_loss: -0.0000\n",
            "Epoch [511/1000], Step [1/8], d_loss: 8.9479, g_loss: -0.0000\n",
            "Epoch [511/1000], Step [2/8], d_loss: 8.9223, g_loss: -0.0000\n",
            "Epoch [511/1000], Step [3/8], d_loss: 9.2763, g_loss: -0.0000\n",
            "Epoch [511/1000], Step [4/8], d_loss: 9.0470, g_loss: -0.0000\n",
            "Epoch [511/1000], Step [5/8], d_loss: 8.9933, g_loss: -0.0000\n",
            "Epoch [511/1000], Step [6/8], d_loss: 3268.0718, g_loss: -0.0000\n",
            "Epoch [511/1000], Step [7/8], d_loss: 8.9971, g_loss: -0.0000\n",
            "Epoch [511/1000], Step [8/8], d_loss: 9.0870, g_loss: -0.0000\n",
            "Epoch [512/1000], Step [1/8], d_loss: 9.0597, g_loss: -0.0000\n",
            "Epoch [512/1000], Step [2/8], d_loss: 2841.7136, g_loss: -0.0000\n",
            "Epoch [512/1000], Step [3/8], d_loss: 8.7509, g_loss: -0.0000\n",
            "Epoch [512/1000], Step [4/8], d_loss: 243.6152, g_loss: -0.0000\n",
            "Epoch [512/1000], Step [5/8], d_loss: 13.8830, g_loss: -0.0000\n",
            "Epoch [512/1000], Step [6/8], d_loss: 8.9698, g_loss: -0.0000\n",
            "Epoch [512/1000], Step [7/8], d_loss: 8.7624, g_loss: -0.0000\n",
            "Epoch [512/1000], Step [8/8], d_loss: 23.2684, g_loss: -0.0000\n",
            "Epoch [513/1000], Step [1/8], d_loss: 8.7113, g_loss: -0.0000\n",
            "Epoch [513/1000], Step [2/8], d_loss: 27.6676, g_loss: -0.0000\n",
            "Epoch [513/1000], Step [3/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [513/1000], Step [4/8], d_loss: 17.0465, g_loss: -0.0000\n",
            "Epoch [513/1000], Step [5/8], d_loss: 8.7188, g_loss: -0.0000\n",
            "Epoch [513/1000], Step [6/8], d_loss: 15.5043, g_loss: -0.0000\n",
            "Epoch [513/1000], Step [7/8], d_loss: 1282.0500, g_loss: -0.0000\n",
            "Epoch [513/1000], Step [8/8], d_loss: 963.6680, g_loss: -0.0000\n",
            "Epoch [514/1000], Step [1/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [514/1000], Step [2/8], d_loss: 9.0926, g_loss: -0.0000\n",
            "Epoch [514/1000], Step [3/8], d_loss: 8.9844, g_loss: -0.0000\n",
            "Epoch [514/1000], Step [4/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [514/1000], Step [5/8], d_loss: 5152.9814, g_loss: -0.0000\n",
            "Epoch [514/1000], Step [6/8], d_loss: 13.5277, g_loss: -0.0000\n",
            "Epoch [514/1000], Step [7/8], d_loss: 8.9989, g_loss: -0.0000\n",
            "Epoch [514/1000], Step [8/8], d_loss: 326.5549, g_loss: -0.0000\n",
            "Epoch [515/1000], Step [1/8], d_loss: 9.6373, g_loss: -0.0000\n",
            "Epoch [515/1000], Step [2/8], d_loss: 282.0096, g_loss: -0.0000\n",
            "Epoch [515/1000], Step [3/8], d_loss: 9.0834, g_loss: -0.0006\n",
            "Epoch [515/1000], Step [4/8], d_loss: 8.9985, g_loss: -0.0000\n",
            "Epoch [515/1000], Step [5/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [515/1000], Step [6/8], d_loss: 1304.4836, g_loss: -0.0000\n",
            "Epoch [515/1000], Step [7/8], d_loss: 1169.4783, g_loss: -0.0000\n",
            "Epoch [515/1000], Step [8/8], d_loss: 9.0433, g_loss: -0.0000\n",
            "Epoch [516/1000], Step [1/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [516/1000], Step [2/8], d_loss: 9.0937, g_loss: -0.0000\n",
            "Epoch [516/1000], Step [3/8], d_loss: 137.6904, g_loss: -0.0000\n",
            "Epoch [516/1000], Step [4/8], d_loss: 9.0100, g_loss: -0.0000\n",
            "Epoch [516/1000], Step [5/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [516/1000], Step [6/8], d_loss: 9.0310, g_loss: -0.0000\n",
            "Epoch [516/1000], Step [7/8], d_loss: 8.5157, g_loss: -0.0000\n",
            "Epoch [516/1000], Step [8/8], d_loss: 9.0422, g_loss: -0.0000\n",
            "Epoch [517/1000], Step [1/8], d_loss: 9.0203, g_loss: -0.0000\n",
            "Epoch [517/1000], Step [2/8], d_loss: 9.0311, g_loss: -0.0000\n",
            "Epoch [517/1000], Step [3/8], d_loss: 5158.2246, g_loss: -0.0000\n",
            "Epoch [517/1000], Step [4/8], d_loss: 8.9102, g_loss: -0.0312\n",
            "Epoch [517/1000], Step [5/8], d_loss: 6896.9004, g_loss: -0.0000\n",
            "Epoch [517/1000], Step [6/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [517/1000], Step [7/8], d_loss: 2563.2629, g_loss: -0.0000\n",
            "Epoch [517/1000], Step [8/8], d_loss: 9.0102, g_loss: -0.0000\n",
            "Epoch [518/1000], Step [1/8], d_loss: 1017.4404, g_loss: -0.0000\n",
            "Epoch [518/1000], Step [2/8], d_loss: 2715.8457, g_loss: -0.0628\n",
            "Epoch [518/1000], Step [3/8], d_loss: 8.9966, g_loss: -0.0312\n",
            "Epoch [518/1000], Step [4/8], d_loss: 8.9485, g_loss: -0.0000\n",
            "Epoch [518/1000], Step [5/8], d_loss: 320.7268, g_loss: -0.0000\n",
            "Epoch [518/1000], Step [6/8], d_loss: 88.4147, g_loss: -0.0079\n",
            "Epoch [518/1000], Step [7/8], d_loss: 107.5520, g_loss: -0.0005\n",
            "Epoch [518/1000], Step [8/8], d_loss: 8.5046, g_loss: -0.0000\n",
            "Epoch [519/1000], Step [1/8], d_loss: 8.6327, g_loss: -0.0000\n",
            "Epoch [519/1000], Step [2/8], d_loss: 12.2278, g_loss: -0.0000\n",
            "Epoch [519/1000], Step [3/8], d_loss: 12.3312, g_loss: -0.0000\n",
            "Epoch [519/1000], Step [4/8], d_loss: 130.8472, g_loss: -0.0000\n",
            "Epoch [519/1000], Step [5/8], d_loss: 8.9782, g_loss: -0.0000\n",
            "Epoch [519/1000], Step [6/8], d_loss: 1852.5961, g_loss: -0.0000\n",
            "Epoch [519/1000], Step [7/8], d_loss: 1116.4218, g_loss: -0.0000\n",
            "Epoch [519/1000], Step [8/8], d_loss: 8.6369, g_loss: -0.0000\n",
            "Epoch [520/1000], Step [1/8], d_loss: 1572.4619, g_loss: -0.0000\n",
            "Epoch [520/1000], Step [2/8], d_loss: 9.0846, g_loss: -0.0000\n",
            "Epoch [520/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0278\n",
            "Epoch [520/1000], Step [4/8], d_loss: 33.8286, g_loss: -0.0000\n",
            "Epoch [520/1000], Step [5/8], d_loss: 1203.8231, g_loss: -0.0003\n",
            "Epoch [520/1000], Step [6/8], d_loss: 9.0310, g_loss: -0.0317\n",
            "Epoch [520/1000], Step [7/8], d_loss: 2088.0193, g_loss: -0.0648\n",
            "Epoch [520/1000], Step [8/8], d_loss: 9.0869, g_loss: -0.0000\n",
            "Epoch [521/1000], Step [1/8], d_loss: 1760.3881, g_loss: -0.0000\n",
            "Epoch [521/1000], Step [2/8], d_loss: 8.8030, g_loss: -0.0000\n",
            "Epoch [521/1000], Step [3/8], d_loss: 480.5867, g_loss: -0.0000\n",
            "Epoch [521/1000], Step [4/8], d_loss: 9.6757, g_loss: -0.0000\n",
            "Epoch [521/1000], Step [5/8], d_loss: 9.5047, g_loss: -0.0000\n",
            "Epoch [521/1000], Step [6/8], d_loss: 346.3233, g_loss: -0.0000\n",
            "Epoch [521/1000], Step [7/8], d_loss: 9.0306, g_loss: -0.0000\n",
            "Epoch [521/1000], Step [8/8], d_loss: 8.9785, g_loss: -0.0000\n",
            "Epoch [522/1000], Step [1/8], d_loss: 1391.4670, g_loss: -0.0000\n",
            "Epoch [522/1000], Step [2/8], d_loss: 9.0306, g_loss: -0.0000\n",
            "Epoch [522/1000], Step [3/8], d_loss: 12.1952, g_loss: -0.0000\n",
            "Epoch [522/1000], Step [4/8], d_loss: 8.8991, g_loss: -0.0000\n",
            "Epoch [522/1000], Step [5/8], d_loss: 8.7718, g_loss: -0.0000\n",
            "Epoch [522/1000], Step [6/8], d_loss: 9.0937, g_loss: -0.0000\n",
            "Epoch [522/1000], Step [7/8], d_loss: 8.9773, g_loss: -0.0000\n",
            "Epoch [522/1000], Step [8/8], d_loss: 8.6797, g_loss: -0.0000\n",
            "Epoch [523/1000], Step [1/8], d_loss: 8.9741, g_loss: -0.0000\n",
            "Epoch [523/1000], Step [2/8], d_loss: 755.2182, g_loss: -0.0000\n",
            "Epoch [523/1000], Step [3/8], d_loss: 1226.2483, g_loss: -0.0000\n",
            "Epoch [523/1000], Step [4/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [523/1000], Step [5/8], d_loss: 2837.5027, g_loss: -0.0000\n",
            "Epoch [523/1000], Step [6/8], d_loss: 2363.8555, g_loss: -0.0000\n",
            "Epoch [523/1000], Step [7/8], d_loss: 11.1591, g_loss: -0.0000\n",
            "Epoch [523/1000], Step [8/8], d_loss: 8.8366, g_loss: -0.0000\n",
            "Epoch [524/1000], Step [1/8], d_loss: 9.0298, g_loss: -0.0000\n",
            "Epoch [524/1000], Step [2/8], d_loss: 8.7198, g_loss: -0.0000\n",
            "Epoch [524/1000], Step [3/8], d_loss: 3336.1284, g_loss: -0.0000\n",
            "Epoch [524/1000], Step [4/8], d_loss: 9.0310, g_loss: -0.0000\n",
            "Epoch [524/1000], Step [5/8], d_loss: 9.0311, g_loss: -0.0000\n",
            "Epoch [524/1000], Step [6/8], d_loss: 8.6968, g_loss: -0.0000\n",
            "Epoch [524/1000], Step [7/8], d_loss: 869.3145, g_loss: -0.0000\n",
            "Epoch [524/1000], Step [8/8], d_loss: 1742.0632, g_loss: -0.0373\n",
            "Epoch [525/1000], Step [1/8], d_loss: 1358.6968, g_loss: -0.0000\n",
            "Epoch [525/1000], Step [2/8], d_loss: 9.0313, g_loss: -0.0000\n",
            "Epoch [525/1000], Step [3/8], d_loss: 9.0309, g_loss: -0.0000\n",
            "Epoch [525/1000], Step [4/8], d_loss: 262.7092, g_loss: -0.0000\n",
            "Epoch [525/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [525/1000], Step [6/8], d_loss: 8.5304, g_loss: -0.0000\n",
            "Epoch [525/1000], Step [7/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [525/1000], Step [8/8], d_loss: 9.0864, g_loss: -0.0001\n",
            "Epoch [526/1000], Step [1/8], d_loss: 13.9010, g_loss: -0.0000\n",
            "Epoch [526/1000], Step [2/8], d_loss: 20.9368, g_loss: -0.0312\n",
            "Epoch [526/1000], Step [3/8], d_loss: 9.0624, g_loss: -0.0000\n",
            "Epoch [526/1000], Step [4/8], d_loss: 10.1113, g_loss: -0.0000\n",
            "Epoch [526/1000], Step [5/8], d_loss: 9.0564, g_loss: -0.0000\n",
            "Epoch [526/1000], Step [6/8], d_loss: 2037.4734, g_loss: -0.0000\n",
            "Epoch [526/1000], Step [7/8], d_loss: 5754.3296, g_loss: -0.0000\n",
            "Epoch [526/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0396\n",
            "Epoch [527/1000], Step [1/8], d_loss: 92.4638, g_loss: -0.0000\n",
            "Epoch [527/1000], Step [2/8], d_loss: 9.0358, g_loss: -0.0000\n",
            "Epoch [527/1000], Step [3/8], d_loss: 2371.0579, g_loss: -0.0000\n",
            "Epoch [527/1000], Step [4/8], d_loss: 2864.2803, g_loss: -0.0000\n",
            "Epoch [527/1000], Step [5/8], d_loss: 8.5844, g_loss: -0.0000\n",
            "Epoch [527/1000], Step [6/8], d_loss: 4888.3789, g_loss: -0.0000\n",
            "Epoch [527/1000], Step [7/8], d_loss: 3270.0244, g_loss: -0.0000\n",
            "Epoch [527/1000], Step [8/8], d_loss: 8.9494, g_loss: -0.0000\n",
            "Epoch [528/1000], Step [1/8], d_loss: 8.9430, g_loss: -0.0007\n",
            "Epoch [528/1000], Step [2/8], d_loss: 8.8897, g_loss: -0.0000\n",
            "Epoch [528/1000], Step [3/8], d_loss: 18.1284, g_loss: -0.0000\n",
            "Epoch [528/1000], Step [4/8], d_loss: 14.7716, g_loss: -0.0000\n",
            "Epoch [528/1000], Step [5/8], d_loss: 1369.9539, g_loss: -0.0000\n",
            "Epoch [528/1000], Step [6/8], d_loss: 183.2867, g_loss: -0.0000\n",
            "Epoch [528/1000], Step [7/8], d_loss: 8.8161, g_loss: -0.0000\n",
            "Epoch [528/1000], Step [8/8], d_loss: 9.0392, g_loss: -0.0000\n",
            "Epoch [529/1000], Step [1/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [529/1000], Step [2/8], d_loss: 8.9978, g_loss: -0.0000\n",
            "Epoch [529/1000], Step [3/8], d_loss: 10.8111, g_loss: -0.0000\n",
            "Epoch [529/1000], Step [4/8], d_loss: 2070.3445, g_loss: -0.0000\n",
            "Epoch [529/1000], Step [5/8], d_loss: 1635.0979, g_loss: -0.0000\n",
            "Epoch [529/1000], Step [6/8], d_loss: 9.0608, g_loss: -0.0000\n",
            "Epoch [529/1000], Step [7/8], d_loss: 9.0297, g_loss: -0.0000\n",
            "Epoch [529/1000], Step [8/8], d_loss: 8.5949, g_loss: -0.0000\n",
            "Epoch [530/1000], Step [1/8], d_loss: 8.8474, g_loss: -0.0011\n",
            "Epoch [530/1000], Step [2/8], d_loss: 44.6677, g_loss: -0.0000\n",
            "Epoch [530/1000], Step [3/8], d_loss: 145.6952, g_loss: -0.0000\n",
            "Epoch [530/1000], Step [4/8], d_loss: 9.0661, g_loss: -0.0000\n",
            "Epoch [530/1000], Step [5/8], d_loss: 9.0620, g_loss: -0.0000\n",
            "Epoch [530/1000], Step [6/8], d_loss: 342.4883, g_loss: -0.0000\n",
            "Epoch [530/1000], Step [7/8], d_loss: 3665.7036, g_loss: -0.0000\n",
            "Epoch [530/1000], Step [8/8], d_loss: 8.9956, g_loss: -0.0000\n",
            "Epoch [531/1000], Step [1/8], d_loss: 8.5852, g_loss: -0.0000\n",
            "Epoch [531/1000], Step [2/8], d_loss: 8.6083, g_loss: -0.0000\n",
            "Epoch [531/1000], Step [3/8], d_loss: 8.9954, g_loss: -0.0000\n",
            "Epoch [531/1000], Step [4/8], d_loss: 8.7044, g_loss: -0.0294\n",
            "Epoch [531/1000], Step [5/8], d_loss: 8.9735, g_loss: -0.0073\n",
            "Epoch [531/1000], Step [6/8], d_loss: 8.9919, g_loss: -0.0001\n",
            "Epoch [531/1000], Step [7/8], d_loss: 242.1193, g_loss: -0.0000\n",
            "Epoch [531/1000], Step [8/8], d_loss: 9.0262, g_loss: -0.0000\n",
            "Epoch [532/1000], Step [1/8], d_loss: 30.1568, g_loss: -0.0000\n",
            "Epoch [532/1000], Step [2/8], d_loss: 1573.3572, g_loss: -0.0000\n",
            "Epoch [532/1000], Step [3/8], d_loss: 3752.7388, g_loss: -0.0000\n",
            "Epoch [532/1000], Step [4/8], d_loss: 8.9599, g_loss: -0.0000\n",
            "Epoch [532/1000], Step [5/8], d_loss: 8.7187, g_loss: -0.0000\n",
            "Epoch [532/1000], Step [6/8], d_loss: 8.9707, g_loss: -0.0314\n",
            "Epoch [532/1000], Step [7/8], d_loss: 8.5717, g_loss: -0.0000\n",
            "Epoch [532/1000], Step [8/8], d_loss: 8.6186, g_loss: -0.0000\n",
            "Epoch [533/1000], Step [1/8], d_loss: 8.9524, g_loss: -0.0000\n",
            "Epoch [533/1000], Step [2/8], d_loss: 2834.0061, g_loss: -0.0000\n",
            "Epoch [533/1000], Step [3/8], d_loss: 21.9716, g_loss: -0.0000\n",
            "Epoch [533/1000], Step [4/8], d_loss: 49.5744, g_loss: -0.0000\n",
            "Epoch [533/1000], Step [5/8], d_loss: 9.3025, g_loss: -0.0000\n",
            "Epoch [533/1000], Step [6/8], d_loss: 18.3024, g_loss: -0.0294\n",
            "Epoch [533/1000], Step [7/8], d_loss: 1644.1758, g_loss: -0.0000\n",
            "Epoch [533/1000], Step [8/8], d_loss: 2478.1238, g_loss: -0.0000\n",
            "Epoch [534/1000], Step [1/8], d_loss: 7738.0938, g_loss: -0.0000\n",
            "Epoch [534/1000], Step [2/8], d_loss: 5659.0903, g_loss: -0.0000\n",
            "Epoch [534/1000], Step [3/8], d_loss: 306.7779, g_loss: -0.0002\n",
            "Epoch [534/1000], Step [4/8], d_loss: 8.7530, g_loss: -0.0000\n",
            "Epoch [534/1000], Step [5/8], d_loss: 9.0074, g_loss: -0.0000\n",
            "Epoch [534/1000], Step [6/8], d_loss: 4420.9478, g_loss: -0.0000\n",
            "Epoch [534/1000], Step [7/8], d_loss: 8.8365, g_loss: -0.0001\n",
            "Epoch [534/1000], Step [8/8], d_loss: 9.0047, g_loss: -0.0000\n",
            "Epoch [535/1000], Step [1/8], d_loss: 8.8767, g_loss: -0.0000\n",
            "Epoch [535/1000], Step [2/8], d_loss: 8.9993, g_loss: -0.0000\n",
            "Epoch [535/1000], Step [3/8], d_loss: 122.9731, g_loss: -0.0313\n",
            "Epoch [535/1000], Step [4/8], d_loss: 10.8689, g_loss: -0.0583\n",
            "Epoch [535/1000], Step [5/8], d_loss: 1213.9723, g_loss: -0.0000\n",
            "Epoch [535/1000], Step [6/8], d_loss: 393.6228, g_loss: -0.0219\n",
            "Epoch [535/1000], Step [7/8], d_loss: 8.9761, g_loss: -0.0000\n",
            "Epoch [535/1000], Step [8/8], d_loss: 9.0373, g_loss: -0.0434\n",
            "Epoch [536/1000], Step [1/8], d_loss: 5615.9365, g_loss: -0.0000\n",
            "Epoch [536/1000], Step [2/8], d_loss: 1120.9640, g_loss: -0.0000\n",
            "Epoch [536/1000], Step [3/8], d_loss: 8.7232, g_loss: -0.0000\n",
            "Epoch [536/1000], Step [4/8], d_loss: 451.7096, g_loss: -0.0000\n",
            "Epoch [536/1000], Step [5/8], d_loss: 8.8311, g_loss: -0.0000\n",
            "Epoch [536/1000], Step [6/8], d_loss: 14.3359, g_loss: -0.0000\n",
            "Epoch [536/1000], Step [7/8], d_loss: 2577.0757, g_loss: -0.0136\n",
            "Epoch [536/1000], Step [8/8], d_loss: 1303.4950, g_loss: -0.0435\n",
            "Epoch [537/1000], Step [1/8], d_loss: 324.7489, g_loss: -0.0000\n",
            "Epoch [537/1000], Step [2/8], d_loss: 9.0247, g_loss: -0.0000\n",
            "Epoch [537/1000], Step [3/8], d_loss: 8.9975, g_loss: -0.0000\n",
            "Epoch [537/1000], Step [4/8], d_loss: 13991.9473, g_loss: -0.0035\n",
            "Epoch [537/1000], Step [5/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [537/1000], Step [6/8], d_loss: 9020.6191, g_loss: -0.0361\n",
            "Epoch [537/1000], Step [7/8], d_loss: 369.7701, g_loss: -0.0000\n",
            "Epoch [537/1000], Step [8/8], d_loss: 8.9782, g_loss: -0.0296\n",
            "Epoch [538/1000], Step [1/8], d_loss: 8.9935, g_loss: -0.0000\n",
            "Epoch [538/1000], Step [2/8], d_loss: 343.5201, g_loss: -0.0001\n",
            "Epoch [538/1000], Step [3/8], d_loss: 660.5435, g_loss: -0.0000\n",
            "Epoch [538/1000], Step [4/8], d_loss: 4346.8721, g_loss: -0.0000\n",
            "Epoch [538/1000], Step [5/8], d_loss: 13.2457, g_loss: -0.0000\n",
            "Epoch [538/1000], Step [6/8], d_loss: 474.2027, g_loss: -0.0000\n",
            "Epoch [538/1000], Step [7/8], d_loss: 8.9044, g_loss: -0.0023\n",
            "Epoch [538/1000], Step [8/8], d_loss: 3080.8894, g_loss: -0.0001\n",
            "Epoch [539/1000], Step [1/8], d_loss: 8.9013, g_loss: -0.0000\n",
            "Epoch [539/1000], Step [2/8], d_loss: 8.8963, g_loss: -0.0000\n",
            "Epoch [539/1000], Step [3/8], d_loss: 9.6432, g_loss: -0.0000\n",
            "Epoch [539/1000], Step [4/8], d_loss: 9.0003, g_loss: -0.0000\n",
            "Epoch [539/1000], Step [5/8], d_loss: 1630.1915, g_loss: -0.0004\n",
            "Epoch [539/1000], Step [6/8], d_loss: 9.0288, g_loss: -0.0000\n",
            "Epoch [539/1000], Step [7/8], d_loss: 19.1263, g_loss: -0.0000\n",
            "Epoch [539/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [540/1000], Step [1/8], d_loss: 143.1980, g_loss: -0.0000\n",
            "Epoch [540/1000], Step [2/8], d_loss: 8.9831, g_loss: -0.0000\n",
            "Epoch [540/1000], Step [3/8], d_loss: 9.7736, g_loss: -0.0000\n",
            "Epoch [540/1000], Step [4/8], d_loss: 12.9265, g_loss: -0.0000\n",
            "Epoch [540/1000], Step [5/8], d_loss: 1884.0796, g_loss: -0.0000\n",
            "Epoch [540/1000], Step [6/8], d_loss: 8.9181, g_loss: -0.0000\n",
            "Epoch [540/1000], Step [7/8], d_loss: 8.9957, g_loss: -0.0000\n",
            "Epoch [540/1000], Step [8/8], d_loss: 1406.9741, g_loss: -0.0000\n",
            "Epoch [541/1000], Step [1/8], d_loss: 1518.1531, g_loss: -0.0303\n",
            "Epoch [541/1000], Step [2/8], d_loss: 3285.2634, g_loss: -0.0000\n",
            "Epoch [541/1000], Step [3/8], d_loss: 1496.6598, g_loss: -0.0000\n",
            "Epoch [541/1000], Step [4/8], d_loss: 364.7778, g_loss: -0.0000\n",
            "Epoch [541/1000], Step [5/8], d_loss: 485.9818, g_loss: -0.0313\n",
            "Epoch [541/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [541/1000], Step [7/8], d_loss: 8.9811, g_loss: -0.0318\n",
            "Epoch [541/1000], Step [8/8], d_loss: 5496.6670, g_loss: -0.0000\n",
            "Epoch [542/1000], Step [1/8], d_loss: 9.2121, g_loss: -0.0000\n",
            "Epoch [542/1000], Step [2/8], d_loss: 8.6939, g_loss: -0.0000\n",
            "Epoch [542/1000], Step [3/8], d_loss: 8.9549, g_loss: -0.0000\n",
            "Epoch [542/1000], Step [4/8], d_loss: 9.0172, g_loss: -0.0000\n",
            "Epoch [542/1000], Step [5/8], d_loss: 121.3198, g_loss: -0.0000\n",
            "Epoch [542/1000], Step [6/8], d_loss: 8.7592, g_loss: -0.0001\n",
            "Epoch [542/1000], Step [7/8], d_loss: 11.6026, g_loss: -0.0000\n",
            "Epoch [542/1000], Step [8/8], d_loss: 1616.5051, g_loss: -0.0000\n",
            "Epoch [543/1000], Step [1/8], d_loss: 8.9707, g_loss: -0.0316\n",
            "Epoch [543/1000], Step [2/8], d_loss: 1009.3116, g_loss: -0.0000\n",
            "Epoch [543/1000], Step [3/8], d_loss: 8.8750, g_loss: -0.0000\n",
            "Epoch [543/1000], Step [4/8], d_loss: 48.9049, g_loss: -0.0000\n",
            "Epoch [543/1000], Step [5/8], d_loss: 8.9995, g_loss: -0.0000\n",
            "Epoch [543/1000], Step [6/8], d_loss: 8.9933, g_loss: -0.0000\n",
            "Epoch [543/1000], Step [7/8], d_loss: 9.0004, g_loss: -0.0000\n",
            "Epoch [543/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [544/1000], Step [1/8], d_loss: 579.1116, g_loss: -0.0000\n",
            "Epoch [544/1000], Step [2/8], d_loss: 3045.6895, g_loss: -0.0002\n",
            "Epoch [544/1000], Step [3/8], d_loss: 3041.1177, g_loss: -0.0000\n",
            "Epoch [544/1000], Step [4/8], d_loss: 8.7878, g_loss: -0.0247\n",
            "Epoch [544/1000], Step [5/8], d_loss: 947.4044, g_loss: -0.0312\n",
            "Epoch [544/1000], Step [6/8], d_loss: 196.7150, g_loss: -0.0000\n",
            "Epoch [544/1000], Step [7/8], d_loss: 45.5677, g_loss: -0.0000\n",
            "Epoch [544/1000], Step [8/8], d_loss: 7975.0166, g_loss: -0.0000\n",
            "Epoch [545/1000], Step [1/8], d_loss: 8.9771, g_loss: -0.0000\n",
            "Epoch [545/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [545/1000], Step [3/8], d_loss: 1018.9474, g_loss: -0.0000\n",
            "Epoch [545/1000], Step [4/8], d_loss: 8.2417, g_loss: -0.0000\n",
            "Epoch [545/1000], Step [5/8], d_loss: 473.9231, g_loss: -0.0000\n",
            "Epoch [545/1000], Step [6/8], d_loss: 36.3934, g_loss: -0.0000\n",
            "Epoch [545/1000], Step [7/8], d_loss: 8.9242, g_loss: -0.0000\n",
            "Epoch [545/1000], Step [8/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [546/1000], Step [1/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [546/1000], Step [2/8], d_loss: 8.9743, g_loss: -0.0000\n",
            "Epoch [546/1000], Step [3/8], d_loss: 33.1855, g_loss: -0.0000\n",
            "Epoch [546/1000], Step [4/8], d_loss: 124.3492, g_loss: -0.0000\n",
            "Epoch [546/1000], Step [5/8], d_loss: 8.9971, g_loss: -0.0000\n",
            "Epoch [546/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [546/1000], Step [7/8], d_loss: 22.7629, g_loss: -0.0000\n",
            "Epoch [546/1000], Step [8/8], d_loss: 8.6955, g_loss: -0.0863\n",
            "Epoch [547/1000], Step [1/8], d_loss: 9.0001, g_loss: -0.0026\n",
            "Epoch [547/1000], Step [2/8], d_loss: 263.6788, g_loss: -0.0312\n",
            "Epoch [547/1000], Step [3/8], d_loss: 1791.5909, g_loss: -0.0000\n",
            "Epoch [547/1000], Step [4/8], d_loss: 166.4737, g_loss: -0.0000\n",
            "Epoch [547/1000], Step [5/8], d_loss: 8.9815, g_loss: -0.0000\n",
            "Epoch [547/1000], Step [6/8], d_loss: 14.8892, g_loss: -0.0002\n",
            "Epoch [547/1000], Step [7/8], d_loss: 3952.4402, g_loss: -0.0000\n",
            "Epoch [547/1000], Step [8/8], d_loss: 9.0405, g_loss: -0.0000\n",
            "Epoch [548/1000], Step [1/8], d_loss: 638.8254, g_loss: -0.0000\n",
            "Epoch [548/1000], Step [2/8], d_loss: 274.7140, g_loss: -0.0000\n",
            "Epoch [548/1000], Step [3/8], d_loss: 59.3282, g_loss: -0.0000\n",
            "Epoch [548/1000], Step [4/8], d_loss: 2211.8452, g_loss: -0.0000\n",
            "Epoch [548/1000], Step [5/8], d_loss: 8.6412, g_loss: -0.0034\n",
            "Epoch [548/1000], Step [6/8], d_loss: 7044.6904, g_loss: -0.0000\n",
            "Epoch [548/1000], Step [7/8], d_loss: 8.8633, g_loss: -0.0000\n",
            "Epoch [548/1000], Step [8/8], d_loss: 212.2218, g_loss: -0.0000\n",
            "Epoch [549/1000], Step [1/8], d_loss: 2389.4800, g_loss: -0.0239\n",
            "Epoch [549/1000], Step [2/8], d_loss: 8.6647, g_loss: -0.0313\n",
            "Epoch [549/1000], Step [3/8], d_loss: 8.9987, g_loss: -0.0000\n",
            "Epoch [549/1000], Step [4/8], d_loss: 47.9423, g_loss: -0.0306\n",
            "Epoch [549/1000], Step [5/8], d_loss: 25.6762, g_loss: -0.0000\n",
            "Epoch [549/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [549/1000], Step [7/8], d_loss: 8.9596, g_loss: -0.0000\n",
            "Epoch [549/1000], Step [8/8], d_loss: 21.8764, g_loss: -0.0000\n",
            "Epoch [550/1000], Step [1/8], d_loss: 33.1010, g_loss: -0.0000\n",
            "Epoch [550/1000], Step [2/8], d_loss: 8056.9248, g_loss: -0.0000\n",
            "Epoch [550/1000], Step [3/8], d_loss: 7539.1436, g_loss: -0.0020\n",
            "Epoch [550/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [550/1000], Step [5/8], d_loss: 3022.0112, g_loss: -0.0004\n",
            "Epoch [550/1000], Step [6/8], d_loss: 8.9947, g_loss: -0.0001\n",
            "Epoch [550/1000], Step [7/8], d_loss: 315.4240, g_loss: -0.0000\n",
            "Epoch [550/1000], Step [8/8], d_loss: 8.6558, g_loss: -0.0004\n",
            "Epoch [551/1000], Step [1/8], d_loss: 195.7831, g_loss: -0.0000\n",
            "Epoch [551/1000], Step [2/8], d_loss: 12.2842, g_loss: -0.0621\n",
            "Epoch [551/1000], Step [3/8], d_loss: 8.9993, g_loss: -0.0000\n",
            "Epoch [551/1000], Step [4/8], d_loss: 138.8243, g_loss: -0.0000\n",
            "Epoch [551/1000], Step [5/8], d_loss: 8.8933, g_loss: -0.0000\n",
            "Epoch [551/1000], Step [6/8], d_loss: 9.5627, g_loss: -0.0148\n",
            "Epoch [551/1000], Step [7/8], d_loss: 8.9689, g_loss: -0.0000\n",
            "Epoch [551/1000], Step [8/8], d_loss: 14.3196, g_loss: -0.0000\n",
            "Epoch [552/1000], Step [1/8], d_loss: 9.0026, g_loss: -0.0000\n",
            "Epoch [552/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [552/1000], Step [3/8], d_loss: 2656.8811, g_loss: -0.0000\n",
            "Epoch [552/1000], Step [4/8], d_loss: 8969.3496, g_loss: -0.0000\n",
            "Epoch [552/1000], Step [5/8], d_loss: 9.0238, g_loss: -0.0000\n",
            "Epoch [552/1000], Step [6/8], d_loss: 8.7516, g_loss: -0.0000\n",
            "Epoch [552/1000], Step [7/8], d_loss: 757.9353, g_loss: -0.0000\n",
            "Epoch [552/1000], Step [8/8], d_loss: 5051.2188, g_loss: -0.0000\n",
            "Epoch [553/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [553/1000], Step [2/8], d_loss: 148.6189, g_loss: -0.0000\n",
            "Epoch [553/1000], Step [3/8], d_loss: 9.0254, g_loss: -0.0000\n",
            "Epoch [553/1000], Step [4/8], d_loss: 8.7920, g_loss: -0.0000\n",
            "Epoch [553/1000], Step [5/8], d_loss: 186.3289, g_loss: -0.0000\n",
            "Epoch [553/1000], Step [6/8], d_loss: 8.9970, g_loss: -0.0000\n",
            "Epoch [553/1000], Step [7/8], d_loss: 8.9469, g_loss: -0.0000\n",
            "Epoch [553/1000], Step [8/8], d_loss: 2985.6411, g_loss: -0.0000\n",
            "Epoch [554/1000], Step [1/8], d_loss: 1672.2185, g_loss: -0.0000\n",
            "Epoch [554/1000], Step [2/8], d_loss: 619.7458, g_loss: -0.0000\n",
            "Epoch [554/1000], Step [3/8], d_loss: 8.9814, g_loss: -0.0000\n",
            "Epoch [554/1000], Step [4/8], d_loss: 8.9968, g_loss: -0.0000\n",
            "Epoch [554/1000], Step [5/8], d_loss: 2903.2664, g_loss: -0.0000\n",
            "Epoch [554/1000], Step [6/8], d_loss: 11.6831, g_loss: -0.0312\n",
            "Epoch [554/1000], Step [7/8], d_loss: 8.9693, g_loss: -0.0311\n",
            "Epoch [554/1000], Step [8/8], d_loss: 1093.2825, g_loss: -0.0000\n",
            "Epoch [555/1000], Step [1/8], d_loss: 8.4013, g_loss: -0.0313\n",
            "Epoch [555/1000], Step [2/8], d_loss: 8.6424, g_loss: -0.0000\n",
            "Epoch [555/1000], Step [3/8], d_loss: 9.2593, g_loss: -0.0016\n",
            "Epoch [555/1000], Step [4/8], d_loss: 599.2025, g_loss: -0.0000\n",
            "Epoch [555/1000], Step [5/8], d_loss: 8.6883, g_loss: -0.0000\n",
            "Epoch [555/1000], Step [6/8], d_loss: 571.5005, g_loss: -0.0000\n",
            "Epoch [555/1000], Step [7/8], d_loss: 10780.7383, g_loss: -0.0000\n",
            "Epoch [555/1000], Step [8/8], d_loss: 8.5816, g_loss: -0.0000\n",
            "Epoch [556/1000], Step [1/8], d_loss: 296.8021, g_loss: -0.0010\n",
            "Epoch [556/1000], Step [2/8], d_loss: 8.9983, g_loss: -0.0000\n",
            "Epoch [556/1000], Step [3/8], d_loss: 140.8827, g_loss: -0.0000\n",
            "Epoch [556/1000], Step [4/8], d_loss: 4141.3623, g_loss: -0.0000\n",
            "Epoch [556/1000], Step [5/8], d_loss: 9.0311, g_loss: -0.0027\n",
            "Epoch [556/1000], Step [6/8], d_loss: 926.1241, g_loss: -0.0000\n",
            "Epoch [556/1000], Step [7/8], d_loss: 8.7185, g_loss: -0.0000\n",
            "Epoch [556/1000], Step [8/8], d_loss: 11.2142, g_loss: -0.0000\n",
            "Epoch [557/1000], Step [1/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [557/1000], Step [2/8], d_loss: 704.4498, g_loss: -0.0000\n",
            "Epoch [557/1000], Step [3/8], d_loss: 8.9278, g_loss: -0.0011\n",
            "Epoch [557/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [557/1000], Step [5/8], d_loss: 8.9286, g_loss: -0.0000\n",
            "Epoch [557/1000], Step [6/8], d_loss: 8.9415, g_loss: -0.0000\n",
            "Epoch [557/1000], Step [7/8], d_loss: 3567.5591, g_loss: -0.0000\n",
            "Epoch [557/1000], Step [8/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [558/1000], Step [1/8], d_loss: 266.6327, g_loss: -0.0000\n",
            "Epoch [558/1000], Step [2/8], d_loss: 8.9978, g_loss: -0.0000\n",
            "Epoch [558/1000], Step [3/8], d_loss: 9.0152, g_loss: -0.0324\n",
            "Epoch [558/1000], Step [4/8], d_loss: 8.5877, g_loss: -0.0000\n",
            "Epoch [558/1000], Step [5/8], d_loss: 3879.9297, g_loss: -0.0000\n",
            "Epoch [558/1000], Step [6/8], d_loss: 16.7101, g_loss: -0.0000\n",
            "Epoch [558/1000], Step [7/8], d_loss: 8.8720, g_loss: -0.0312\n",
            "Epoch [558/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [559/1000], Step [1/8], d_loss: 595.6264, g_loss: -0.0000\n",
            "Epoch [559/1000], Step [2/8], d_loss: 865.6958, g_loss: -0.0000\n",
            "Epoch [559/1000], Step [3/8], d_loss: 8.9588, g_loss: -0.0000\n",
            "Epoch [559/1000], Step [4/8], d_loss: 739.3502, g_loss: -0.0000\n",
            "Epoch [559/1000], Step [5/8], d_loss: 8.4710, g_loss: -0.0000\n",
            "Epoch [559/1000], Step [6/8], d_loss: 3304.3184, g_loss: -0.0000\n",
            "Epoch [559/1000], Step [7/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [559/1000], Step [8/8], d_loss: 4443.1338, g_loss: -0.0000\n",
            "Epoch [560/1000], Step [1/8], d_loss: 14.8289, g_loss: -0.0015\n",
            "Epoch [560/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [560/1000], Step [3/8], d_loss: 20.8505, g_loss: -0.0000\n",
            "Epoch [560/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [560/1000], Step [5/8], d_loss: 8.9984, g_loss: -0.0874\n",
            "Epoch [560/1000], Step [6/8], d_loss: 9.0076, g_loss: -0.0007\n",
            "Epoch [560/1000], Step [7/8], d_loss: 857.2883, g_loss: -0.0000\n",
            "Epoch [560/1000], Step [8/8], d_loss: 8.9735, g_loss: -0.0001\n",
            "Epoch [561/1000], Step [1/8], d_loss: 5296.6919, g_loss: -0.0000\n",
            "Epoch [561/1000], Step [2/8], d_loss: 8.9958, g_loss: -0.0003\n",
            "Epoch [561/1000], Step [3/8], d_loss: 63.2467, g_loss: -0.0000\n",
            "Epoch [561/1000], Step [4/8], d_loss: 2755.0942, g_loss: -0.0000\n",
            "Epoch [561/1000], Step [5/8], d_loss: 8.9856, g_loss: -0.0000\n",
            "Epoch [561/1000], Step [6/8], d_loss: 228.3790, g_loss: -0.0002\n",
            "Epoch [561/1000], Step [7/8], d_loss: 326.5877, g_loss: -0.0000\n",
            "Epoch [561/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [562/1000], Step [1/8], d_loss: 234.1132, g_loss: -0.0000\n",
            "Epoch [562/1000], Step [2/8], d_loss: 2019.4836, g_loss: -0.0000\n",
            "Epoch [562/1000], Step [3/8], d_loss: 902.8367, g_loss: -0.0000\n",
            "Epoch [562/1000], Step [4/8], d_loss: 41.1569, g_loss: -0.0000\n",
            "Epoch [562/1000], Step [5/8], d_loss: 8.4286, g_loss: -0.0000\n",
            "Epoch [562/1000], Step [6/8], d_loss: 8.9992, g_loss: -0.0000\n",
            "Epoch [562/1000], Step [7/8], d_loss: 39.7629, g_loss: -0.0000\n",
            "Epoch [562/1000], Step [8/8], d_loss: 8.5694, g_loss: -0.0001\n",
            "Epoch [563/1000], Step [1/8], d_loss: 8.6200, g_loss: -0.0580\n",
            "Epoch [563/1000], Step [2/8], d_loss: 9.6995, g_loss: -0.0000\n",
            "Epoch [563/1000], Step [3/8], d_loss: 74.3044, g_loss: -0.0632\n",
            "Epoch [563/1000], Step [4/8], d_loss: 9.1546, g_loss: -0.0000\n",
            "Epoch [563/1000], Step [5/8], d_loss: 153.9908, g_loss: -0.0014\n",
            "Epoch [563/1000], Step [6/8], d_loss: 8.9617, g_loss: -0.0312\n",
            "Epoch [563/1000], Step [7/8], d_loss: 9.0256, g_loss: -0.0001\n",
            "Epoch [563/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [564/1000], Step [1/8], d_loss: 3697.4238, g_loss: -0.0000\n",
            "Epoch [564/1000], Step [2/8], d_loss: 12.6800, g_loss: -0.0000\n",
            "Epoch [564/1000], Step [3/8], d_loss: 9.0010, g_loss: -0.0000\n",
            "Epoch [564/1000], Step [4/8], d_loss: 8.8913, g_loss: -0.0000\n",
            "Epoch [564/1000], Step [5/8], d_loss: 8.9909, g_loss: -0.0000\n",
            "Epoch [564/1000], Step [6/8], d_loss: 8.7338, g_loss: -0.0001\n",
            "Epoch [564/1000], Step [7/8], d_loss: 8.7546, g_loss: -0.0000\n",
            "Epoch [564/1000], Step [8/8], d_loss: 8.6226, g_loss: -0.0000\n",
            "Epoch [565/1000], Step [1/8], d_loss: 9.0633, g_loss: -0.0000\n",
            "Epoch [565/1000], Step [2/8], d_loss: 4393.7686, g_loss: -0.0274\n",
            "Epoch [565/1000], Step [3/8], d_loss: 573.2283, g_loss: -0.0000\n",
            "Epoch [565/1000], Step [4/8], d_loss: 8.9169, g_loss: -0.0000\n",
            "Epoch [565/1000], Step [5/8], d_loss: 8.5154, g_loss: -0.0208\n",
            "Epoch [565/1000], Step [6/8], d_loss: 8.5148, g_loss: -0.0001\n",
            "Epoch [565/1000], Step [7/8], d_loss: 9.0011, g_loss: -0.0000\n",
            "Epoch [565/1000], Step [8/8], d_loss: 9.0026, g_loss: -0.0010\n",
            "Epoch [566/1000], Step [1/8], d_loss: 2251.6963, g_loss: -0.0000\n",
            "Epoch [566/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [566/1000], Step [3/8], d_loss: 2246.2454, g_loss: -0.0000\n",
            "Epoch [566/1000], Step [4/8], d_loss: 1426.2993, g_loss: -0.0002\n",
            "Epoch [566/1000], Step [5/8], d_loss: 9.0269, g_loss: -0.0288\n",
            "Epoch [566/1000], Step [6/8], d_loss: 451.6764, g_loss: -0.0001\n",
            "Epoch [566/1000], Step [7/8], d_loss: 106.5616, g_loss: -0.0000\n",
            "Epoch [566/1000], Step [8/8], d_loss: 539.5292, g_loss: -0.0000\n",
            "Epoch [567/1000], Step [1/8], d_loss: 17.1212, g_loss: -0.0000\n",
            "Epoch [567/1000], Step [2/8], d_loss: 5042.7007, g_loss: -0.0000\n",
            "Epoch [567/1000], Step [3/8], d_loss: 8.9998, g_loss: -0.0004\n",
            "Epoch [567/1000], Step [4/8], d_loss: 659.7614, g_loss: -0.0000\n",
            "Epoch [567/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [567/1000], Step [6/8], d_loss: 8.8782, g_loss: -0.0000\n",
            "Epoch [567/1000], Step [7/8], d_loss: 9.3287, g_loss: -0.0275\n",
            "Epoch [567/1000], Step [8/8], d_loss: 2176.4766, g_loss: -0.0000\n",
            "Epoch [568/1000], Step [1/8], d_loss: 530.9882, g_loss: -0.0000\n",
            "Epoch [568/1000], Step [2/8], d_loss: 11.5089, g_loss: -0.0000\n",
            "Epoch [568/1000], Step [3/8], d_loss: 8.9842, g_loss: -0.0000\n",
            "Epoch [568/1000], Step [4/8], d_loss: 517.4478, g_loss: -0.0000\n",
            "Epoch [568/1000], Step [5/8], d_loss: 9.3090, g_loss: -0.0001\n",
            "Epoch [568/1000], Step [6/8], d_loss: 179.5986, g_loss: -0.0000\n",
            "Epoch [568/1000], Step [7/8], d_loss: 8.9806, g_loss: -0.0000\n",
            "Epoch [568/1000], Step [8/8], d_loss: 3691.9846, g_loss: -0.0000\n",
            "Epoch [569/1000], Step [1/8], d_loss: 77.8818, g_loss: -0.0002\n",
            "Epoch [569/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0312\n",
            "Epoch [569/1000], Step [3/8], d_loss: 4967.1392, g_loss: -0.0089\n",
            "Epoch [569/1000], Step [4/8], d_loss: 100.9185, g_loss: -0.0000\n",
            "Epoch [569/1000], Step [5/8], d_loss: 48.0616, g_loss: -0.0000\n",
            "Epoch [569/1000], Step [6/8], d_loss: 4237.6318, g_loss: -0.0001\n",
            "Epoch [569/1000], Step [7/8], d_loss: 9.0076, g_loss: -0.0012\n",
            "Epoch [569/1000], Step [8/8], d_loss: 1124.9819, g_loss: -0.0147\n",
            "Epoch [570/1000], Step [1/8], d_loss: 8.5958, g_loss: -0.0306\n",
            "Epoch [570/1000], Step [2/8], d_loss: 8.9751, g_loss: -0.0000\n",
            "Epoch [570/1000], Step [3/8], d_loss: 9.0654, g_loss: -0.0011\n",
            "Epoch [570/1000], Step [4/8], d_loss: 4769.2603, g_loss: -0.0000\n",
            "Epoch [570/1000], Step [5/8], d_loss: 8.8617, g_loss: -0.0000\n",
            "Epoch [570/1000], Step [6/8], d_loss: 3688.4641, g_loss: -0.0000\n",
            "Epoch [570/1000], Step [7/8], d_loss: 1762.4478, g_loss: -0.0000\n",
            "Epoch [570/1000], Step [8/8], d_loss: 8.9999, g_loss: -0.0435\n",
            "Epoch [571/1000], Step [1/8], d_loss: 11.9263, g_loss: -0.0000\n",
            "Epoch [571/1000], Step [2/8], d_loss: 11.0346, g_loss: -0.0000\n",
            "Epoch [571/1000], Step [3/8], d_loss: 2517.2791, g_loss: -0.0000\n",
            "Epoch [571/1000], Step [4/8], d_loss: 2308.0466, g_loss: -0.0000\n",
            "Epoch [571/1000], Step [5/8], d_loss: 9.0005, g_loss: -0.0000\n",
            "Epoch [571/1000], Step [6/8], d_loss: 1708.8478, g_loss: -0.0000\n",
            "Epoch [571/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [571/1000], Step [8/8], d_loss: 303.2066, g_loss: -0.0000\n",
            "Epoch [572/1000], Step [1/8], d_loss: 77.9982, g_loss: -0.0001\n",
            "Epoch [572/1000], Step [2/8], d_loss: 40.4598, g_loss: -0.0008\n",
            "Epoch [572/1000], Step [3/8], d_loss: 8.9211, g_loss: -0.0000\n",
            "Epoch [572/1000], Step [4/8], d_loss: 721.9056, g_loss: -0.0014\n",
            "Epoch [572/1000], Step [5/8], d_loss: 9.0245, g_loss: -0.0000\n",
            "Epoch [572/1000], Step [6/8], d_loss: 6628.9409, g_loss: -0.0065\n",
            "Epoch [572/1000], Step [7/8], d_loss: 5049.7705, g_loss: -0.0000\n",
            "Epoch [572/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [573/1000], Step [1/8], d_loss: 2338.5278, g_loss: -0.0000\n",
            "Epoch [573/1000], Step [2/8], d_loss: 17676.0000, g_loss: -0.0000\n",
            "Epoch [573/1000], Step [3/8], d_loss: 787.1957, g_loss: -0.0000\n",
            "Epoch [573/1000], Step [4/8], d_loss: 8.7944, g_loss: -0.0000\n",
            "Epoch [573/1000], Step [5/8], d_loss: 8.9996, g_loss: -0.0003\n",
            "Epoch [573/1000], Step [6/8], d_loss: 3596.7217, g_loss: -0.0000\n",
            "Epoch [573/1000], Step [7/8], d_loss: 343.3569, g_loss: -0.0000\n",
            "Epoch [573/1000], Step [8/8], d_loss: 231.4974, g_loss: -0.0417\n",
            "Epoch [574/1000], Step [1/8], d_loss: 8.8780, g_loss: -0.0000\n",
            "Epoch [574/1000], Step [2/8], d_loss: 2927.8108, g_loss: -0.0000\n",
            "Epoch [574/1000], Step [3/8], d_loss: 25.6792, g_loss: -0.0000\n",
            "Epoch [574/1000], Step [4/8], d_loss: 19.3518, g_loss: -0.0123\n",
            "Epoch [574/1000], Step [5/8], d_loss: 261.6163, g_loss: -0.0000\n",
            "Epoch [574/1000], Step [6/8], d_loss: 8.9929, g_loss: -0.0000\n",
            "Epoch [574/1000], Step [7/8], d_loss: 8.8369, g_loss: -0.0000\n",
            "Epoch [574/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [575/1000], Step [1/8], d_loss: 8.8848, g_loss: -0.0000\n",
            "Epoch [575/1000], Step [2/8], d_loss: 1284.3416, g_loss: -0.0042\n",
            "Epoch [575/1000], Step [3/8], d_loss: 1985.0056, g_loss: -0.0000\n",
            "Epoch [575/1000], Step [4/8], d_loss: 40.4752, g_loss: -0.0000\n",
            "Epoch [575/1000], Step [5/8], d_loss: 10.3117, g_loss: -0.0000\n",
            "Epoch [575/1000], Step [6/8], d_loss: 371.7305, g_loss: -0.0000\n",
            "Epoch [575/1000], Step [7/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [575/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [576/1000], Step [1/8], d_loss: 8.7762, g_loss: -0.0295\n",
            "Epoch [576/1000], Step [2/8], d_loss: 28.8020, g_loss: -0.0314\n",
            "Epoch [576/1000], Step [3/8], d_loss: 9.0186, g_loss: -0.0000\n",
            "Epoch [576/1000], Step [4/8], d_loss: 8.7664, g_loss: -0.0000\n",
            "Epoch [576/1000], Step [5/8], d_loss: 9.9744, g_loss: -0.0000\n",
            "Epoch [576/1000], Step [6/8], d_loss: 8.7146, g_loss: -0.0002\n",
            "Epoch [576/1000], Step [7/8], d_loss: 9.0222, g_loss: -0.0000\n",
            "Epoch [576/1000], Step [8/8], d_loss: 8.9821, g_loss: -0.0000\n",
            "Epoch [577/1000], Step [1/8], d_loss: 392.7787, g_loss: -0.0000\n",
            "Epoch [577/1000], Step [2/8], d_loss: 1786.7478, g_loss: -0.0035\n",
            "Epoch [577/1000], Step [3/8], d_loss: 6639.4028, g_loss: -0.0000\n",
            "Epoch [577/1000], Step [4/8], d_loss: 53.8809, g_loss: -0.0000\n",
            "Epoch [577/1000], Step [5/8], d_loss: 8.9949, g_loss: -0.0001\n",
            "Epoch [577/1000], Step [6/8], d_loss: 2754.5444, g_loss: -0.0000\n",
            "Epoch [577/1000], Step [7/8], d_loss: 284.2144, g_loss: -0.0001\n",
            "Epoch [577/1000], Step [8/8], d_loss: 6581.2539, g_loss: -0.0000\n",
            "Epoch [578/1000], Step [1/8], d_loss: 1265.0289, g_loss: -0.0002\n",
            "Epoch [578/1000], Step [2/8], d_loss: 29.3454, g_loss: -0.0000\n",
            "Epoch [578/1000], Step [3/8], d_loss: 10800.2100, g_loss: -0.0000\n",
            "Epoch [578/1000], Step [4/8], d_loss: 4685.4028, g_loss: -0.0000\n",
            "Epoch [578/1000], Step [5/8], d_loss: 14.9887, g_loss: -0.0000\n",
            "Epoch [578/1000], Step [6/8], d_loss: 691.2899, g_loss: -0.0000\n",
            "Epoch [578/1000], Step [7/8], d_loss: 223.1004, g_loss: -0.0312\n",
            "Epoch [578/1000], Step [8/8], d_loss: 9.0652, g_loss: -0.0000\n",
            "Epoch [579/1000], Step [1/8], d_loss: 8.9773, g_loss: -0.0287\n",
            "Epoch [579/1000], Step [2/8], d_loss: 2399.4941, g_loss: -0.0000\n",
            "Epoch [579/1000], Step [3/8], d_loss: 9.0014, g_loss: -0.0000\n",
            "Epoch [579/1000], Step [4/8], d_loss: 8.7041, g_loss: -0.0000\n",
            "Epoch [579/1000], Step [5/8], d_loss: 8.9097, g_loss: -0.0000\n",
            "Epoch [579/1000], Step [6/8], d_loss: 97.5121, g_loss: -0.0000\n",
            "Epoch [579/1000], Step [7/8], d_loss: 2623.3386, g_loss: -0.0000\n",
            "Epoch [579/1000], Step [8/8], d_loss: 1294.6960, g_loss: -0.0000\n",
            "Epoch [580/1000], Step [1/8], d_loss: 8.7970, g_loss: -0.0000\n",
            "Epoch [580/1000], Step [2/8], d_loss: 54.6980, g_loss: -0.0000\n",
            "Epoch [580/1000], Step [3/8], d_loss: 8.9378, g_loss: -0.0000\n",
            "Epoch [580/1000], Step [4/8], d_loss: 12.0308, g_loss: -0.0273\n",
            "Epoch [580/1000], Step [5/8], d_loss: 2355.9619, g_loss: -0.0000\n",
            "Epoch [580/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [580/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [580/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [581/1000], Step [1/8], d_loss: 8.9176, g_loss: -0.0000\n",
            "Epoch [581/1000], Step [2/8], d_loss: 208.6467, g_loss: -0.0000\n",
            "Epoch [581/1000], Step [3/8], d_loss: 8.4277, g_loss: -0.0000\n",
            "Epoch [581/1000], Step [4/8], d_loss: 156.4089, g_loss: -0.0000\n",
            "Epoch [581/1000], Step [5/8], d_loss: 8.9995, g_loss: -0.0000\n",
            "Epoch [581/1000], Step [6/8], d_loss: 566.7748, g_loss: -0.0000\n",
            "Epoch [581/1000], Step [7/8], d_loss: 419.8312, g_loss: -0.0075\n",
            "Epoch [581/1000], Step [8/8], d_loss: 26.4186, g_loss: -0.0000\n",
            "Epoch [582/1000], Step [1/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [582/1000], Step [2/8], d_loss: 8.9651, g_loss: -0.0000\n",
            "Epoch [582/1000], Step [3/8], d_loss: 16.7698, g_loss: -0.0000\n",
            "Epoch [582/1000], Step [4/8], d_loss: 8.8415, g_loss: -0.0000\n",
            "Epoch [582/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [582/1000], Step [6/8], d_loss: 80.3416, g_loss: -0.0000\n",
            "Epoch [582/1000], Step [7/8], d_loss: 11.2996, g_loss: -0.0000\n",
            "Epoch [582/1000], Step [8/8], d_loss: 8.8863, g_loss: -0.0000\n",
            "Epoch [583/1000], Step [1/8], d_loss: 40.3542, g_loss: -0.0000\n",
            "Epoch [583/1000], Step [2/8], d_loss: 9.0079, g_loss: -0.0000\n",
            "Epoch [583/1000], Step [3/8], d_loss: 1113.5487, g_loss: -0.0000\n",
            "Epoch [583/1000], Step [4/8], d_loss: 8.3220, g_loss: -0.0000\n",
            "Epoch [583/1000], Step [5/8], d_loss: 314.5886, g_loss: -0.0000\n",
            "Epoch [583/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [583/1000], Step [7/8], d_loss: 74.0563, g_loss: -0.0001\n",
            "Epoch [583/1000], Step [8/8], d_loss: 8.9451, g_loss: -0.0000\n",
            "Epoch [584/1000], Step [1/8], d_loss: 8.6455, g_loss: -0.0000\n",
            "Epoch [584/1000], Step [2/8], d_loss: 8.7531, g_loss: -0.0000\n",
            "Epoch [584/1000], Step [3/8], d_loss: 8.8473, g_loss: -0.0000\n",
            "Epoch [584/1000], Step [4/8], d_loss: 9.0177, g_loss: -0.0000\n",
            "Epoch [584/1000], Step [5/8], d_loss: 8.9982, g_loss: -0.0000\n",
            "Epoch [584/1000], Step [6/8], d_loss: 1553.5027, g_loss: -0.0000\n",
            "Epoch [584/1000], Step [7/8], d_loss: 26.4575, g_loss: -0.0000\n",
            "Epoch [584/1000], Step [8/8], d_loss: 2505.1785, g_loss: -0.0000\n",
            "Epoch [585/1000], Step [1/8], d_loss: 14713.4375, g_loss: -0.0000\n",
            "Epoch [585/1000], Step [2/8], d_loss: 3700.0715, g_loss: -0.0312\n",
            "Epoch [585/1000], Step [3/8], d_loss: 3596.1128, g_loss: -0.0000\n",
            "Epoch [585/1000], Step [4/8], d_loss: 1572.6488, g_loss: -0.0000\n",
            "Epoch [585/1000], Step [5/8], d_loss: 23.3453, g_loss: -0.0000\n",
            "Epoch [585/1000], Step [6/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [585/1000], Step [7/8], d_loss: 8.9938, g_loss: -0.0000\n",
            "Epoch [585/1000], Step [8/8], d_loss: 8.8789, g_loss: -0.0000\n",
            "Epoch [586/1000], Step [1/8], d_loss: 4757.9639, g_loss: -0.0000\n",
            "Epoch [586/1000], Step [2/8], d_loss: 6772.6006, g_loss: -0.0000\n",
            "Epoch [586/1000], Step [3/8], d_loss: 8.9141, g_loss: -0.0000\n",
            "Epoch [586/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [586/1000], Step [5/8], d_loss: 2127.6160, g_loss: -0.0000\n",
            "Epoch [586/1000], Step [6/8], d_loss: 11.7270, g_loss: -0.0000\n",
            "Epoch [586/1000], Step [7/8], d_loss: 8.9992, g_loss: -0.0000\n",
            "Epoch [586/1000], Step [8/8], d_loss: 8.7866, g_loss: -0.0000\n",
            "Epoch [587/1000], Step [1/8], d_loss: 8.8335, g_loss: -0.0000\n",
            "Epoch [587/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [587/1000], Step [3/8], d_loss: 334.4727, g_loss: -0.0000\n",
            "Epoch [587/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [587/1000], Step [5/8], d_loss: 8.9972, g_loss: -0.0000\n",
            "Epoch [587/1000], Step [6/8], d_loss: 521.4406, g_loss: -0.0000\n",
            "Epoch [587/1000], Step [7/8], d_loss: 9.2501, g_loss: -0.0000\n",
            "Epoch [587/1000], Step [8/8], d_loss: 18.3752, g_loss: -0.0438\n",
            "Epoch [588/1000], Step [1/8], d_loss: 317.9302, g_loss: -0.0000\n",
            "Epoch [588/1000], Step [2/8], d_loss: 8.9873, g_loss: -0.0000\n",
            "Epoch [588/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [588/1000], Step [4/8], d_loss: 37.0065, g_loss: -0.0000\n",
            "Epoch [588/1000], Step [5/8], d_loss: 8.9990, g_loss: -0.0000\n",
            "Epoch [588/1000], Step [6/8], d_loss: 9.0004, g_loss: -0.0253\n",
            "Epoch [588/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [588/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [589/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [589/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [589/1000], Step [3/8], d_loss: 3158.3667, g_loss: -0.0154\n",
            "Epoch [589/1000], Step [4/8], d_loss: 4262.0508, g_loss: -0.0000\n",
            "Epoch [589/1000], Step [5/8], d_loss: 8.9356, g_loss: -0.0007\n",
            "Epoch [589/1000], Step [6/8], d_loss: 8.9921, g_loss: -0.0000\n",
            "Epoch [589/1000], Step [7/8], d_loss: 6586.3574, g_loss: -0.0000\n",
            "Epoch [589/1000], Step [8/8], d_loss: 1158.9109, g_loss: -0.0000\n",
            "Epoch [590/1000], Step [1/8], d_loss: 13.2883, g_loss: -0.0000\n",
            "Epoch [590/1000], Step [2/8], d_loss: 8.8005, g_loss: -0.0000\n",
            "Epoch [590/1000], Step [3/8], d_loss: 8.9470, g_loss: -0.0000\n",
            "Epoch [590/1000], Step [4/8], d_loss: 8.8706, g_loss: -0.0002\n",
            "Epoch [590/1000], Step [5/8], d_loss: 8.4394, g_loss: -0.0000\n",
            "Epoch [590/1000], Step [6/8], d_loss: 32.3784, g_loss: -0.0000\n",
            "Epoch [590/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [590/1000], Step [8/8], d_loss: 9.0347, g_loss: -0.0000\n",
            "Epoch [591/1000], Step [1/8], d_loss: 8.9990, g_loss: -0.0000\n",
            "Epoch [591/1000], Step [2/8], d_loss: 8.8006, g_loss: -0.0000\n",
            "Epoch [591/1000], Step [3/8], d_loss: 1484.5581, g_loss: -0.0000\n",
            "Epoch [591/1000], Step [4/8], d_loss: 8.8713, g_loss: -0.0312\n",
            "Epoch [591/1000], Step [5/8], d_loss: 13758.6035, g_loss: -0.0000\n",
            "Epoch [591/1000], Step [6/8], d_loss: 309.0586, g_loss: -0.0139\n",
            "Epoch [591/1000], Step [7/8], d_loss: 88.5835, g_loss: -0.0000\n",
            "Epoch [591/1000], Step [8/8], d_loss: 9.0347, g_loss: -0.0000\n",
            "Epoch [592/1000], Step [1/8], d_loss: 8.4738, g_loss: -0.0026\n",
            "Epoch [592/1000], Step [2/8], d_loss: 8.9788, g_loss: -0.0001\n",
            "Epoch [592/1000], Step [3/8], d_loss: 9.0312, g_loss: -0.0007\n",
            "Epoch [592/1000], Step [4/8], d_loss: 8.9662, g_loss: -0.0000\n",
            "Epoch [592/1000], Step [5/8], d_loss: 30.7349, g_loss: -0.0000\n",
            "Epoch [592/1000], Step [6/8], d_loss: 9.0444, g_loss: -0.0000\n",
            "Epoch [592/1000], Step [7/8], d_loss: 8.8564, g_loss: -0.0000\n",
            "Epoch [592/1000], Step [8/8], d_loss: 21.7200, g_loss: -0.0000\n",
            "Epoch [593/1000], Step [1/8], d_loss: 8.6580, g_loss: -0.0000\n",
            "Epoch [593/1000], Step [2/8], d_loss: 8.9371, g_loss: -0.0000\n",
            "Epoch [593/1000], Step [3/8], d_loss: 45.1215, g_loss: -0.0162\n",
            "Epoch [593/1000], Step [4/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [593/1000], Step [5/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [593/1000], Step [6/8], d_loss: 8.9924, g_loss: -0.0000\n",
            "Epoch [593/1000], Step [7/8], d_loss: 36.8578, g_loss: -0.0000\n",
            "Epoch [593/1000], Step [8/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [594/1000], Step [1/8], d_loss: 60.6144, g_loss: -0.0000\n",
            "Epoch [594/1000], Step [2/8], d_loss: 149.5050, g_loss: -0.0000\n",
            "Epoch [594/1000], Step [3/8], d_loss: 9.0297, g_loss: -0.0000\n",
            "Epoch [594/1000], Step [4/8], d_loss: 3340.6514, g_loss: -0.0623\n",
            "Epoch [594/1000], Step [5/8], d_loss: 1371.6263, g_loss: -0.0000\n",
            "Epoch [594/1000], Step [6/8], d_loss: 3625.6973, g_loss: -0.0000\n",
            "Epoch [594/1000], Step [7/8], d_loss: 66.8391, g_loss: -0.0000\n",
            "Epoch [594/1000], Step [8/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [595/1000], Step [1/8], d_loss: 8.9991, g_loss: -0.0000\n",
            "Epoch [595/1000], Step [2/8], d_loss: 2141.0593, g_loss: -0.0000\n",
            "Epoch [595/1000], Step [3/8], d_loss: 4196.8096, g_loss: -0.0057\n",
            "Epoch [595/1000], Step [4/8], d_loss: 8.9835, g_loss: -0.0000\n",
            "Epoch [595/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0313\n",
            "Epoch [595/1000], Step [6/8], d_loss: 10.3483, g_loss: -0.0000\n",
            "Epoch [595/1000], Step [7/8], d_loss: 1848.2278, g_loss: -0.0000\n",
            "Epoch [595/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [596/1000], Step [1/8], d_loss: 2800.6729, g_loss: -0.0312\n",
            "Epoch [596/1000], Step [2/8], d_loss: 8.5236, g_loss: -0.0000\n",
            "Epoch [596/1000], Step [3/8], d_loss: 8.9895, g_loss: -0.0000\n",
            "Epoch [596/1000], Step [4/8], d_loss: 5963.6543, g_loss: -0.0000\n",
            "Epoch [596/1000], Step [5/8], d_loss: 8.9903, g_loss: -0.0000\n",
            "Epoch [596/1000], Step [6/8], d_loss: 13.1535, g_loss: -0.0000\n",
            "Epoch [596/1000], Step [7/8], d_loss: 503.0515, g_loss: -0.0000\n",
            "Epoch [596/1000], Step [8/8], d_loss: 8.6919, g_loss: -0.0000\n",
            "Epoch [597/1000], Step [1/8], d_loss: 1121.5635, g_loss: -0.0000\n",
            "Epoch [597/1000], Step [2/8], d_loss: 8.8138, g_loss: -0.0000\n",
            "Epoch [597/1000], Step [3/8], d_loss: 2192.9185, g_loss: -0.0000\n",
            "Epoch [597/1000], Step [4/8], d_loss: 1456.8392, g_loss: -0.0000\n",
            "Epoch [597/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [597/1000], Step [6/8], d_loss: 8.9407, g_loss: -0.0000\n",
            "Epoch [597/1000], Step [7/8], d_loss: 8.9947, g_loss: -0.0313\n",
            "Epoch [597/1000], Step [8/8], d_loss: 9.0435, g_loss: -0.0000\n",
            "Epoch [598/1000], Step [1/8], d_loss: 76.3260, g_loss: -0.0000\n",
            "Epoch [598/1000], Step [2/8], d_loss: 263.6793, g_loss: -0.0000\n",
            "Epoch [598/1000], Step [3/8], d_loss: 664.9368, g_loss: -0.0000\n",
            "Epoch [598/1000], Step [4/8], d_loss: 8.9851, g_loss: -0.0298\n",
            "Epoch [598/1000], Step [5/8], d_loss: 9.2857, g_loss: -0.0000\n",
            "Epoch [598/1000], Step [6/8], d_loss: 1019.3398, g_loss: -0.0022\n",
            "Epoch [598/1000], Step [7/8], d_loss: 8.9473, g_loss: -0.0000\n",
            "Epoch [598/1000], Step [8/8], d_loss: 8.9993, g_loss: -0.0435\n",
            "Epoch [599/1000], Step [1/8], d_loss: 4571.4160, g_loss: -0.0000\n",
            "Epoch [599/1000], Step [2/8], d_loss: 36.1076, g_loss: -0.0309\n",
            "Epoch [599/1000], Step [3/8], d_loss: 2283.5259, g_loss: -0.0000\n",
            "Epoch [599/1000], Step [4/8], d_loss: 10.2206, g_loss: -0.0000\n",
            "Epoch [599/1000], Step [5/8], d_loss: 2672.9666, g_loss: -0.0000\n",
            "Epoch [599/1000], Step [6/8], d_loss: 8.8630, g_loss: -0.0000\n",
            "Epoch [599/1000], Step [7/8], d_loss: 787.1690, g_loss: -0.0000\n",
            "Epoch [599/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [600/1000], Step [1/8], d_loss: 8.9982, g_loss: -0.0000\n",
            "Epoch [600/1000], Step [2/8], d_loss: 62.3600, g_loss: -0.0000\n",
            "Epoch [600/1000], Step [3/8], d_loss: 1684.3999, g_loss: -0.0000\n",
            "Epoch [600/1000], Step [4/8], d_loss: 1670.8362, g_loss: -0.0000\n",
            "Epoch [600/1000], Step [5/8], d_loss: 9.0015, g_loss: -0.0000\n",
            "Epoch [600/1000], Step [6/8], d_loss: 4278.5532, g_loss: -0.0008\n",
            "Epoch [600/1000], Step [7/8], d_loss: 9.0313, g_loss: -0.0000\n",
            "Epoch [600/1000], Step [8/8], d_loss: 8.9635, g_loss: -0.0000\n",
            "Epoch [601/1000], Step [1/8], d_loss: 8.9524, g_loss: -0.0000\n",
            "Epoch [601/1000], Step [2/8], d_loss: 2849.6372, g_loss: -0.0000\n",
            "Epoch [601/1000], Step [3/8], d_loss: 519.8322, g_loss: -0.0000\n",
            "Epoch [601/1000], Step [4/8], d_loss: 8.8691, g_loss: -0.0000\n",
            "Epoch [601/1000], Step [5/8], d_loss: 9.6581, g_loss: -0.0000\n",
            "Epoch [601/1000], Step [6/8], d_loss: 11304.5908, g_loss: -0.0003\n",
            "Epoch [601/1000], Step [7/8], d_loss: 8.7629, g_loss: -0.0000\n",
            "Epoch [601/1000], Step [8/8], d_loss: 9.0743, g_loss: -0.0000\n",
            "Epoch [602/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [602/1000], Step [2/8], d_loss: 1052.4185, g_loss: -0.0002\n",
            "Epoch [602/1000], Step [3/8], d_loss: 8.7340, g_loss: -0.0000\n",
            "Epoch [602/1000], Step [4/8], d_loss: 2858.6782, g_loss: -0.0000\n",
            "Epoch [602/1000], Step [5/8], d_loss: 8.9739, g_loss: -0.0000\n",
            "Epoch [602/1000], Step [6/8], d_loss: 29.5178, g_loss: -0.0000\n",
            "Epoch [602/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [602/1000], Step [8/8], d_loss: 19.1782, g_loss: -0.0000\n",
            "Epoch [603/1000], Step [1/8], d_loss: 8.9842, g_loss: -0.0280\n",
            "Epoch [603/1000], Step [2/8], d_loss: 8.8350, g_loss: -0.0000\n",
            "Epoch [603/1000], Step [3/8], d_loss: 8.8970, g_loss: -0.0000\n",
            "Epoch [603/1000], Step [4/8], d_loss: 1506.5386, g_loss: -0.0000\n",
            "Epoch [603/1000], Step [5/8], d_loss: 9.0311, g_loss: -0.0000\n",
            "Epoch [603/1000], Step [6/8], d_loss: 9.0301, g_loss: -0.0000\n",
            "Epoch [603/1000], Step [7/8], d_loss: 3370.1340, g_loss: -0.0000\n",
            "Epoch [603/1000], Step [8/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [604/1000], Step [1/8], d_loss: 8.9751, g_loss: -0.0000\n",
            "Epoch [604/1000], Step [2/8], d_loss: 10.3993, g_loss: -0.0000\n",
            "Epoch [604/1000], Step [3/8], d_loss: 822.8801, g_loss: -0.0000\n",
            "Epoch [604/1000], Step [4/8], d_loss: 2236.5288, g_loss: -0.0000\n",
            "Epoch [604/1000], Step [5/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [604/1000], Step [6/8], d_loss: 8.7474, g_loss: -0.0000\n",
            "Epoch [604/1000], Step [7/8], d_loss: 2362.8916, g_loss: -0.0000\n",
            "Epoch [604/1000], Step [8/8], d_loss: 9.0408, g_loss: -0.0435\n",
            "Epoch [605/1000], Step [1/8], d_loss: 8.9970, g_loss: -0.0000\n",
            "Epoch [605/1000], Step [2/8], d_loss: 791.0229, g_loss: -0.0000\n",
            "Epoch [605/1000], Step [3/8], d_loss: 1374.5182, g_loss: -0.0000\n",
            "Epoch [605/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [605/1000], Step [5/8], d_loss: 711.8453, g_loss: -0.0282\n",
            "Epoch [605/1000], Step [6/8], d_loss: 8.9826, g_loss: -0.0180\n",
            "Epoch [605/1000], Step [7/8], d_loss: 9.0302, g_loss: -0.0000\n",
            "Epoch [605/1000], Step [8/8], d_loss: 3841.8384, g_loss: -0.0000\n",
            "Epoch [606/1000], Step [1/8], d_loss: 8.7292, g_loss: -0.0000\n",
            "Epoch [606/1000], Step [2/8], d_loss: 3943.2910, g_loss: -0.0000\n",
            "Epoch [606/1000], Step [3/8], d_loss: 802.5757, g_loss: -0.0000\n",
            "Epoch [606/1000], Step [4/8], d_loss: 7328.8398, g_loss: -0.0000\n",
            "Epoch [606/1000], Step [5/8], d_loss: 10.1480, g_loss: -0.0000\n",
            "Epoch [606/1000], Step [6/8], d_loss: 10.2058, g_loss: -0.0000\n",
            "Epoch [606/1000], Step [7/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [606/1000], Step [8/8], d_loss: 3954.7693, g_loss: -0.0000\n",
            "Epoch [607/1000], Step [1/8], d_loss: 34.5192, g_loss: -0.0000\n",
            "Epoch [607/1000], Step [2/8], d_loss: 10.1620, g_loss: -0.0004\n",
            "Epoch [607/1000], Step [3/8], d_loss: 6061.7729, g_loss: -0.0000\n",
            "Epoch [607/1000], Step [4/8], d_loss: 70.6655, g_loss: -0.0313\n",
            "Epoch [607/1000], Step [5/8], d_loss: 8.9953, g_loss: -0.0000\n",
            "Epoch [607/1000], Step [6/8], d_loss: 139.1372, g_loss: -0.0238\n",
            "Epoch [607/1000], Step [7/8], d_loss: 8.7935, g_loss: -0.0000\n",
            "Epoch [607/1000], Step [8/8], d_loss: 8.5753, g_loss: -0.0000\n",
            "Epoch [608/1000], Step [1/8], d_loss: 508.2770, g_loss: -0.0222\n",
            "Epoch [608/1000], Step [2/8], d_loss: 9.0314, g_loss: -0.0000\n",
            "Epoch [608/1000], Step [3/8], d_loss: 1954.8477, g_loss: -0.0000\n",
            "Epoch [608/1000], Step [4/8], d_loss: 8.9930, g_loss: -0.0000\n",
            "Epoch [608/1000], Step [5/8], d_loss: 4449.3989, g_loss: -0.0000\n",
            "Epoch [608/1000], Step [6/8], d_loss: 82.8758, g_loss: -0.0000\n",
            "Epoch [608/1000], Step [7/8], d_loss: 112.1683, g_loss: -0.0048\n",
            "Epoch [608/1000], Step [8/8], d_loss: 15.6648, g_loss: -0.0000\n",
            "Epoch [609/1000], Step [1/8], d_loss: 8.9978, g_loss: -0.0000\n",
            "Epoch [609/1000], Step [2/8], d_loss: 9.0937, g_loss: -0.0000\n",
            "Epoch [609/1000], Step [3/8], d_loss: 2044.2465, g_loss: -0.0003\n",
            "Epoch [609/1000], Step [4/8], d_loss: 4258.1841, g_loss: -0.0022\n",
            "Epoch [609/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [609/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [609/1000], Step [7/8], d_loss: 8.9755, g_loss: -0.0000\n",
            "Epoch [609/1000], Step [8/8], d_loss: 9864.3779, g_loss: -0.0000\n",
            "Epoch [610/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [610/1000], Step [2/8], d_loss: 36.3957, g_loss: -0.0000\n",
            "Epoch [610/1000], Step [3/8], d_loss: 19.6537, g_loss: -0.0000\n",
            "Epoch [610/1000], Step [4/8], d_loss: 402.8697, g_loss: -0.0000\n",
            "Epoch [610/1000], Step [5/8], d_loss: 9.8306, g_loss: -0.0000\n",
            "Epoch [610/1000], Step [6/8], d_loss: 8.7562, g_loss: -0.0000\n",
            "Epoch [610/1000], Step [7/8], d_loss: 999.4534, g_loss: -0.0002\n",
            "Epoch [610/1000], Step [8/8], d_loss: 8.9985, g_loss: -0.0000\n",
            "Epoch [611/1000], Step [1/8], d_loss: 12.4692, g_loss: -0.0000\n",
            "Epoch [611/1000], Step [2/8], d_loss: 9.0100, g_loss: -0.0004\n",
            "Epoch [611/1000], Step [3/8], d_loss: 8.9989, g_loss: -0.0001\n",
            "Epoch [611/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0002\n",
            "Epoch [611/1000], Step [5/8], d_loss: 31.4892, g_loss: -0.0000\n",
            "Epoch [611/1000], Step [6/8], d_loss: 8.9993, g_loss: -0.0003\n",
            "Epoch [611/1000], Step [7/8], d_loss: 9.0003, g_loss: -0.0000\n",
            "Epoch [611/1000], Step [8/8], d_loss: 148.1951, g_loss: -0.0000\n",
            "Epoch [612/1000], Step [1/8], d_loss: 368.8730, g_loss: -0.0000\n",
            "Epoch [612/1000], Step [2/8], d_loss: 8.9958, g_loss: -0.0006\n",
            "Epoch [612/1000], Step [3/8], d_loss: 57.2445, g_loss: -0.0000\n",
            "Epoch [612/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [612/1000], Step [5/8], d_loss: 742.3672, g_loss: -0.0001\n",
            "Epoch [612/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0001\n",
            "Epoch [612/1000], Step [7/8], d_loss: 11.0449, g_loss: -0.0000\n",
            "Epoch [612/1000], Step [8/8], d_loss: 1351.6791, g_loss: -0.0000\n",
            "Epoch [613/1000], Step [1/8], d_loss: 776.4117, g_loss: -0.0000\n",
            "Epoch [613/1000], Step [2/8], d_loss: 1674.7070, g_loss: -0.0000\n",
            "Epoch [613/1000], Step [3/8], d_loss: 1001.8253, g_loss: -0.0000\n",
            "Epoch [613/1000], Step [4/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [613/1000], Step [5/8], d_loss: 8.9921, g_loss: -0.0000\n",
            "Epoch [613/1000], Step [6/8], d_loss: 1086.7366, g_loss: -0.0000\n",
            "Epoch [613/1000], Step [7/8], d_loss: 1716.9640, g_loss: -0.0000\n",
            "Epoch [613/1000], Step [8/8], d_loss: 5234.2227, g_loss: -0.0000\n",
            "Epoch [614/1000], Step [1/8], d_loss: 8.9542, g_loss: -0.0000\n",
            "Epoch [614/1000], Step [2/8], d_loss: 9.3772, g_loss: -0.0000\n",
            "Epoch [614/1000], Step [3/8], d_loss: 545.4907, g_loss: -0.0015\n",
            "Epoch [614/1000], Step [4/8], d_loss: 60.9223, g_loss: -0.0000\n",
            "Epoch [614/1000], Step [5/8], d_loss: 9.0087, g_loss: -0.0000\n",
            "Epoch [614/1000], Step [6/8], d_loss: 8.8918, g_loss: -0.0000\n",
            "Epoch [614/1000], Step [7/8], d_loss: 328.0708, g_loss: -0.0000\n",
            "Epoch [614/1000], Step [8/8], d_loss: 42.1149, g_loss: -0.0000\n",
            "Epoch [615/1000], Step [1/8], d_loss: 8.7899, g_loss: -0.0000\n",
            "Epoch [615/1000], Step [2/8], d_loss: 2117.6211, g_loss: -0.0000\n",
            "Epoch [615/1000], Step [3/8], d_loss: 77.2772, g_loss: -0.0000\n",
            "Epoch [615/1000], Step [4/8], d_loss: 9088.2129, g_loss: -0.0004\n",
            "Epoch [615/1000], Step [5/8], d_loss: 8.9945, g_loss: -0.0000\n",
            "Epoch [615/1000], Step [6/8], d_loss: 9.0187, g_loss: -0.0000\n",
            "Epoch [615/1000], Step [7/8], d_loss: 8.8175, g_loss: -0.0000\n",
            "Epoch [615/1000], Step [8/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [616/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0001\n",
            "Epoch [616/1000], Step [2/8], d_loss: 4293.0391, g_loss: -0.0000\n",
            "Epoch [616/1000], Step [3/8], d_loss: 8.9999, g_loss: -0.0004\n",
            "Epoch [616/1000], Step [4/8], d_loss: 8.7930, g_loss: -0.0000\n",
            "Epoch [616/1000], Step [5/8], d_loss: 8.7341, g_loss: -0.0000\n",
            "Epoch [616/1000], Step [6/8], d_loss: 8.9437, g_loss: -0.0625\n",
            "Epoch [616/1000], Step [7/8], d_loss: 17.3758, g_loss: -0.0000\n",
            "Epoch [616/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [617/1000], Step [1/8], d_loss: 3296.4890, g_loss: -0.0000\n",
            "Epoch [617/1000], Step [2/8], d_loss: 861.4986, g_loss: -0.0000\n",
            "Epoch [617/1000], Step [3/8], d_loss: 131.6334, g_loss: -0.0000\n",
            "Epoch [617/1000], Step [4/8], d_loss: 20.3575, g_loss: -0.0000\n",
            "Epoch [617/1000], Step [5/8], d_loss: 2940.8203, g_loss: -0.0313\n",
            "Epoch [617/1000], Step [6/8], d_loss: 439.1318, g_loss: -0.0000\n",
            "Epoch [617/1000], Step [7/8], d_loss: 8.7702, g_loss: -0.0000\n",
            "Epoch [617/1000], Step [8/8], d_loss: 1772.3193, g_loss: -0.0000\n",
            "Epoch [618/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0001\n",
            "Epoch [618/1000], Step [2/8], d_loss: 9.0051, g_loss: -0.0000\n",
            "Epoch [618/1000], Step [3/8], d_loss: 507.1231, g_loss: -0.0000\n",
            "Epoch [618/1000], Step [4/8], d_loss: 9.0112, g_loss: -0.0000\n",
            "Epoch [618/1000], Step [5/8], d_loss: 8.7007, g_loss: -0.0000\n",
            "Epoch [618/1000], Step [6/8], d_loss: 148.1089, g_loss: -0.0225\n",
            "Epoch [618/1000], Step [7/8], d_loss: 16.0013, g_loss: -0.0000\n",
            "Epoch [618/1000], Step [8/8], d_loss: 3381.9966, g_loss: -0.0000\n",
            "Epoch [619/1000], Step [1/8], d_loss: 8.7661, g_loss: -0.0000\n",
            "Epoch [619/1000], Step [2/8], d_loss: 8.8970, g_loss: -0.0000\n",
            "Epoch [619/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [619/1000], Step [4/8], d_loss: 420.5758, g_loss: -0.0000\n",
            "Epoch [619/1000], Step [5/8], d_loss: 37.0920, g_loss: -0.0000\n",
            "Epoch [619/1000], Step [6/8], d_loss: 3199.3416, g_loss: -0.0000\n",
            "Epoch [619/1000], Step [7/8], d_loss: 8.6702, g_loss: -0.0000\n",
            "Epoch [619/1000], Step [8/8], d_loss: 8.9642, g_loss: -0.0000\n",
            "Epoch [620/1000], Step [1/8], d_loss: 14788.7139, g_loss: -0.0000\n",
            "Epoch [620/1000], Step [2/8], d_loss: 8.9641, g_loss: -0.0000\n",
            "Epoch [620/1000], Step [3/8], d_loss: 10.3813, g_loss: -0.0312\n",
            "Epoch [620/1000], Step [4/8], d_loss: 8676.0547, g_loss: -0.0001\n",
            "Epoch [620/1000], Step [5/8], d_loss: 8.9706, g_loss: -0.0000\n",
            "Epoch [620/1000], Step [6/8], d_loss: 8.9892, g_loss: -0.0000\n",
            "Epoch [620/1000], Step [7/8], d_loss: 8.9792, g_loss: -0.0000\n",
            "Epoch [620/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [621/1000], Step [1/8], d_loss: 8.6650, g_loss: -0.0000\n",
            "Epoch [621/1000], Step [2/8], d_loss: 3800.2986, g_loss: -0.0000\n",
            "Epoch [621/1000], Step [3/8], d_loss: 1571.6821, g_loss: -0.0000\n",
            "Epoch [621/1000], Step [4/8], d_loss: 7027.5962, g_loss: -0.0000\n",
            "Epoch [621/1000], Step [5/8], d_loss: 1228.3430, g_loss: -0.0000\n",
            "Epoch [621/1000], Step [6/8], d_loss: 8738.7373, g_loss: -0.0000\n",
            "Epoch [621/1000], Step [7/8], d_loss: 570.9176, g_loss: -0.0000\n",
            "Epoch [621/1000], Step [8/8], d_loss: 29.1479, g_loss: -0.0000\n",
            "Epoch [622/1000], Step [1/8], d_loss: 8.8940, g_loss: -0.0000\n",
            "Epoch [622/1000], Step [2/8], d_loss: 11729.2158, g_loss: -0.0015\n",
            "Epoch [622/1000], Step [3/8], d_loss: 8.9872, g_loss: -0.0000\n",
            "Epoch [622/1000], Step [4/8], d_loss: 8.9498, g_loss: -0.0000\n",
            "Epoch [622/1000], Step [5/8], d_loss: 8.7744, g_loss: -0.0002\n",
            "Epoch [622/1000], Step [6/8], d_loss: 111.1791, g_loss: -0.0675\n",
            "Epoch [622/1000], Step [7/8], d_loss: 8.9995, g_loss: -0.0000\n",
            "Epoch [622/1000], Step [8/8], d_loss: 9.0667, g_loss: -0.0000\n",
            "Epoch [623/1000], Step [1/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [623/1000], Step [2/8], d_loss: 5915.3154, g_loss: -0.0000\n",
            "Epoch [623/1000], Step [3/8], d_loss: 108.3177, g_loss: -0.0000\n",
            "Epoch [623/1000], Step [4/8], d_loss: 13.2530, g_loss: -0.0000\n",
            "Epoch [623/1000], Step [5/8], d_loss: 14462.9873, g_loss: -0.0492\n",
            "Epoch [623/1000], Step [6/8], d_loss: 4547.7334, g_loss: -0.0310\n",
            "Epoch [623/1000], Step [7/8], d_loss: 8.9795, g_loss: -0.0000\n",
            "Epoch [623/1000], Step [8/8], d_loss: 9.0137, g_loss: -0.0000\n",
            "Epoch [624/1000], Step [1/8], d_loss: 8831.0596, g_loss: -0.0000\n",
            "Epoch [624/1000], Step [2/8], d_loss: 5671.8013, g_loss: -0.0003\n",
            "Epoch [624/1000], Step [3/8], d_loss: 114.7218, g_loss: -0.0000\n",
            "Epoch [624/1000], Step [4/8], d_loss: 8.9981, g_loss: -0.0000\n",
            "Epoch [624/1000], Step [5/8], d_loss: 8.8682, g_loss: -0.0004\n",
            "Epoch [624/1000], Step [6/8], d_loss: 3054.2607, g_loss: -0.0004\n",
            "Epoch [624/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0495\n",
            "Epoch [624/1000], Step [8/8], d_loss: 8.9965, g_loss: -0.0000\n",
            "Epoch [625/1000], Step [1/8], d_loss: 8.6346, g_loss: -0.0000\n",
            "Epoch [625/1000], Step [2/8], d_loss: 281.3330, g_loss: -0.0333\n",
            "Epoch [625/1000], Step [3/8], d_loss: 8.7968, g_loss: -0.0001\n",
            "Epoch [625/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0011\n",
            "Epoch [625/1000], Step [5/8], d_loss: 8.9981, g_loss: -0.0000\n",
            "Epoch [625/1000], Step [6/8], d_loss: 14.3887, g_loss: -0.0000\n",
            "Epoch [625/1000], Step [7/8], d_loss: 8.8596, g_loss: -0.0000\n",
            "Epoch [625/1000], Step [8/8], d_loss: 8.9910, g_loss: -0.0000\n",
            "Epoch [626/1000], Step [1/8], d_loss: 8.9767, g_loss: -0.0000\n",
            "Epoch [626/1000], Step [2/8], d_loss: 19.6226, g_loss: -0.0000\n",
            "Epoch [626/1000], Step [3/8], d_loss: 8.9534, g_loss: -0.0000\n",
            "Epoch [626/1000], Step [4/8], d_loss: 8.8858, g_loss: -0.0000\n",
            "Epoch [626/1000], Step [5/8], d_loss: 320.8102, g_loss: -0.0000\n",
            "Epoch [626/1000], Step [6/8], d_loss: 3148.6753, g_loss: -0.0001\n",
            "Epoch [626/1000], Step [7/8], d_loss: 34.3753, g_loss: -0.0000\n",
            "Epoch [626/1000], Step [8/8], d_loss: 3258.3191, g_loss: -0.0000\n",
            "Epoch [627/1000], Step [1/8], d_loss: 3430.6064, g_loss: -0.0000\n",
            "Epoch [627/1000], Step [2/8], d_loss: 9.0311, g_loss: -0.0000\n",
            "Epoch [627/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [627/1000], Step [4/8], d_loss: 40.7490, g_loss: -0.0000\n",
            "Epoch [627/1000], Step [5/8], d_loss: 6720.1436, g_loss: -0.0004\n",
            "Epoch [627/1000], Step [6/8], d_loss: 146.8085, g_loss: -0.0000\n",
            "Epoch [627/1000], Step [7/8], d_loss: 8.8324, g_loss: -0.0000\n",
            "Epoch [627/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [628/1000], Step [1/8], d_loss: 8.9998, g_loss: -0.0313\n",
            "Epoch [628/1000], Step [2/8], d_loss: 8.7167, g_loss: -0.0000\n",
            "Epoch [628/1000], Step [3/8], d_loss: 3228.3210, g_loss: -0.0000\n",
            "Epoch [628/1000], Step [4/8], d_loss: 9.0002, g_loss: -0.0000\n",
            "Epoch [628/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [628/1000], Step [6/8], d_loss: 585.9370, g_loss: -0.0000\n",
            "Epoch [628/1000], Step [7/8], d_loss: 203.5643, g_loss: -0.0000\n",
            "Epoch [628/1000], Step [8/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [629/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0003\n",
            "Epoch [629/1000], Step [2/8], d_loss: 8.9902, g_loss: -0.0000\n",
            "Epoch [629/1000], Step [3/8], d_loss: 29.7194, g_loss: -0.0000\n",
            "Epoch [629/1000], Step [4/8], d_loss: 1440.1591, g_loss: -0.0000\n",
            "Epoch [629/1000], Step [5/8], d_loss: 301.4250, g_loss: -0.0000\n",
            "Epoch [629/1000], Step [6/8], d_loss: 217.0332, g_loss: -0.0000\n",
            "Epoch [629/1000], Step [7/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [629/1000], Step [8/8], d_loss: 9.0011, g_loss: -0.0000\n",
            "Epoch [630/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [630/1000], Step [2/8], d_loss: 679.1688, g_loss: -0.0000\n",
            "Epoch [630/1000], Step [3/8], d_loss: 11.9720, g_loss: -0.0000\n",
            "Epoch [630/1000], Step [4/8], d_loss: 8.9917, g_loss: -0.0000\n",
            "Epoch [630/1000], Step [5/8], d_loss: 8.9640, g_loss: -0.0000\n",
            "Epoch [630/1000], Step [6/8], d_loss: 5515.7939, g_loss: -0.0002\n",
            "Epoch [630/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [630/1000], Step [8/8], d_loss: 56.4691, g_loss: -0.0000\n",
            "Epoch [631/1000], Step [1/8], d_loss: 7017.5879, g_loss: -0.0000\n",
            "Epoch [631/1000], Step [2/8], d_loss: 430.6765, g_loss: -0.0000\n",
            "Epoch [631/1000], Step [3/8], d_loss: 8.8802, g_loss: -0.0000\n",
            "Epoch [631/1000], Step [4/8], d_loss: 9.0294, g_loss: -0.0000\n",
            "Epoch [631/1000], Step [5/8], d_loss: 9.1162, g_loss: -0.0000\n",
            "Epoch [631/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0322\n",
            "Epoch [631/1000], Step [7/8], d_loss: 8.9863, g_loss: -0.0000\n",
            "Epoch [631/1000], Step [8/8], d_loss: 9.0106, g_loss: -0.0000\n",
            "Epoch [632/1000], Step [1/8], d_loss: 8.9170, g_loss: -0.0315\n",
            "Epoch [632/1000], Step [2/8], d_loss: 8.7210, g_loss: -0.0000\n",
            "Epoch [632/1000], Step [3/8], d_loss: 8.9072, g_loss: -0.0000\n",
            "Epoch [632/1000], Step [4/8], d_loss: 9.0016, g_loss: -0.0000\n",
            "Epoch [632/1000], Step [5/8], d_loss: 5056.8047, g_loss: -0.0000\n",
            "Epoch [632/1000], Step [6/8], d_loss: 85.9134, g_loss: -0.0000\n",
            "Epoch [632/1000], Step [7/8], d_loss: 3427.0381, g_loss: -0.0000\n",
            "Epoch [632/1000], Step [8/8], d_loss: 8.6958, g_loss: -0.0000\n",
            "Epoch [633/1000], Step [1/8], d_loss: 8.9988, g_loss: -0.0624\n",
            "Epoch [633/1000], Step [2/8], d_loss: 526.5494, g_loss: -0.0244\n",
            "Epoch [633/1000], Step [3/8], d_loss: 209.0821, g_loss: -0.0000\n",
            "Epoch [633/1000], Step [4/8], d_loss: 1668.3265, g_loss: -0.0000\n",
            "Epoch [633/1000], Step [5/8], d_loss: 614.6476, g_loss: -0.0000\n",
            "Epoch [633/1000], Step [6/8], d_loss: 8.9792, g_loss: -0.0000\n",
            "Epoch [633/1000], Step [7/8], d_loss: 878.6643, g_loss: -0.0000\n",
            "Epoch [633/1000], Step [8/8], d_loss: 9.0384, g_loss: -0.0000\n",
            "Epoch [634/1000], Step [1/8], d_loss: 9.0280, g_loss: -0.0000\n",
            "Epoch [634/1000], Step [2/8], d_loss: 9940.2295, g_loss: -0.0000\n",
            "Epoch [634/1000], Step [3/8], d_loss: 8.5868, g_loss: -0.0000\n",
            "Epoch [634/1000], Step [4/8], d_loss: 12517.2520, g_loss: -0.0000\n",
            "Epoch [634/1000], Step [5/8], d_loss: 8.6445, g_loss: -0.0311\n",
            "Epoch [634/1000], Step [6/8], d_loss: 602.2549, g_loss: -0.0312\n",
            "Epoch [634/1000], Step [7/8], d_loss: 8.7706, g_loss: -0.0000\n",
            "Epoch [634/1000], Step [8/8], d_loss: 5710.0127, g_loss: -0.0123\n",
            "Epoch [635/1000], Step [1/8], d_loss: 9.0122, g_loss: -0.0000\n",
            "Epoch [635/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [635/1000], Step [3/8], d_loss: 8.9676, g_loss: -0.0000\n",
            "Epoch [635/1000], Step [4/8], d_loss: 10.0641, g_loss: -0.0000\n",
            "Epoch [635/1000], Step [5/8], d_loss: 9.0077, g_loss: -0.0000\n",
            "Epoch [635/1000], Step [6/8], d_loss: 8.8501, g_loss: -0.0000\n",
            "Epoch [635/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [635/1000], Step [8/8], d_loss: 21.3090, g_loss: -0.0215\n",
            "Epoch [636/1000], Step [1/8], d_loss: 8.9459, g_loss: -0.0313\n",
            "Epoch [636/1000], Step [2/8], d_loss: 860.1694, g_loss: -0.0000\n",
            "Epoch [636/1000], Step [3/8], d_loss: 8.7082, g_loss: -0.0000\n",
            "Epoch [636/1000], Step [4/8], d_loss: 1324.2614, g_loss: -0.0000\n",
            "Epoch [636/1000], Step [5/8], d_loss: 572.6828, g_loss: -0.0000\n",
            "Epoch [636/1000], Step [6/8], d_loss: 9.0094, g_loss: -0.0000\n",
            "Epoch [636/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [636/1000], Step [8/8], d_loss: 8.6301, g_loss: -0.0000\n",
            "Epoch [637/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [637/1000], Step [2/8], d_loss: 8.9823, g_loss: -0.0000\n",
            "Epoch [637/1000], Step [3/8], d_loss: 8.7181, g_loss: -0.0000\n",
            "Epoch [637/1000], Step [4/8], d_loss: 8.9326, g_loss: -0.0000\n",
            "Epoch [637/1000], Step [5/8], d_loss: 16.2449, g_loss: -0.0000\n",
            "Epoch [637/1000], Step [6/8], d_loss: 9.0826, g_loss: -0.0000\n",
            "Epoch [637/1000], Step [7/8], d_loss: 9.9851, g_loss: -0.0000\n",
            "Epoch [637/1000], Step [8/8], d_loss: 8.9872, g_loss: -0.0000\n",
            "Epoch [638/1000], Step [1/8], d_loss: 8.7128, g_loss: -0.0000\n",
            "Epoch [638/1000], Step [2/8], d_loss: 8.9972, g_loss: -0.0000\n",
            "Epoch [638/1000], Step [3/8], d_loss: 3714.8586, g_loss: -0.0000\n",
            "Epoch [638/1000], Step [4/8], d_loss: 9.0119, g_loss: -0.0000\n",
            "Epoch [638/1000], Step [5/8], d_loss: 9.0185, g_loss: -0.0000\n",
            "Epoch [638/1000], Step [6/8], d_loss: 8.8499, g_loss: -0.0000\n",
            "Epoch [638/1000], Step [7/8], d_loss: 9.0035, g_loss: -0.0000\n",
            "Epoch [638/1000], Step [8/8], d_loss: 8.5752, g_loss: -0.0000\n",
            "Epoch [639/1000], Step [1/8], d_loss: 8.6955, g_loss: -0.0000\n",
            "Epoch [639/1000], Step [2/8], d_loss: 246.2931, g_loss: -0.0000\n",
            "Epoch [639/1000], Step [3/8], d_loss: 1075.7190, g_loss: -0.0000\n",
            "Epoch [639/1000], Step [4/8], d_loss: 8.8146, g_loss: -0.0000\n",
            "Epoch [639/1000], Step [5/8], d_loss: 5089.4194, g_loss: -0.0000\n",
            "Epoch [639/1000], Step [6/8], d_loss: 9.0311, g_loss: -0.0000\n",
            "Epoch [639/1000], Step [7/8], d_loss: 8.6959, g_loss: -0.0000\n",
            "Epoch [639/1000], Step [8/8], d_loss: 8.9978, g_loss: -0.0000\n",
            "Epoch [640/1000], Step [1/8], d_loss: 2260.3435, g_loss: -0.0000\n",
            "Epoch [640/1000], Step [2/8], d_loss: 53.0032, g_loss: -0.0000\n",
            "Epoch [640/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [640/1000], Step [4/8], d_loss: 9.0168, g_loss: -0.0312\n",
            "Epoch [640/1000], Step [5/8], d_loss: 9.0002, g_loss: -0.0000\n",
            "Epoch [640/1000], Step [6/8], d_loss: 9.0167, g_loss: -0.0000\n",
            "Epoch [640/1000], Step [7/8], d_loss: 9.0313, g_loss: -0.0000\n",
            "Epoch [640/1000], Step [8/8], d_loss: 8.7915, g_loss: -0.0245\n",
            "Epoch [641/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [641/1000], Step [2/8], d_loss: 9.6696, g_loss: -0.0000\n",
            "Epoch [641/1000], Step [3/8], d_loss: 12828.8457, g_loss: -0.0000\n",
            "Epoch [641/1000], Step [4/8], d_loss: 230.4499, g_loss: -0.0000\n",
            "Epoch [641/1000], Step [5/8], d_loss: 8.7662, g_loss: -0.0000\n",
            "Epoch [641/1000], Step [6/8], d_loss: 8.9938, g_loss: -0.0000\n",
            "Epoch [641/1000], Step [7/8], d_loss: 8.9338, g_loss: -0.0000\n",
            "Epoch [641/1000], Step [8/8], d_loss: 8.9990, g_loss: -0.0000\n",
            "Epoch [642/1000], Step [1/8], d_loss: 251.0993, g_loss: -0.0000\n",
            "Epoch [642/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0312\n",
            "Epoch [642/1000], Step [3/8], d_loss: 6595.3032, g_loss: -0.0000\n",
            "Epoch [642/1000], Step [4/8], d_loss: 8.9845, g_loss: -0.0000\n",
            "Epoch [642/1000], Step [5/8], d_loss: 8.8905, g_loss: -0.0000\n",
            "Epoch [642/1000], Step [6/8], d_loss: 9.3187, g_loss: -0.0000\n",
            "Epoch [642/1000], Step [7/8], d_loss: 8.9986, g_loss: -0.0000\n",
            "Epoch [642/1000], Step [8/8], d_loss: 8.7166, g_loss: -0.0000\n",
            "Epoch [643/1000], Step [1/8], d_loss: 8.8326, g_loss: -0.0000\n",
            "Epoch [643/1000], Step [2/8], d_loss: 238.9622, g_loss: -0.0312\n",
            "Epoch [643/1000], Step [3/8], d_loss: 8.6085, g_loss: -0.0000\n",
            "Epoch [643/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0002\n",
            "Epoch [643/1000], Step [5/8], d_loss: 8.1711, g_loss: -0.0311\n",
            "Epoch [643/1000], Step [6/8], d_loss: 549.7592, g_loss: -0.0000\n",
            "Epoch [643/1000], Step [7/8], d_loss: 3382.9451, g_loss: -0.0000\n",
            "Epoch [643/1000], Step [8/8], d_loss: 8.9721, g_loss: -0.0001\n",
            "Epoch [644/1000], Step [1/8], d_loss: 9.7188, g_loss: -0.0000\n",
            "Epoch [644/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [644/1000], Step [3/8], d_loss: 3409.0352, g_loss: -0.0002\n",
            "Epoch [644/1000], Step [4/8], d_loss: 9.0001, g_loss: -0.0306\n",
            "Epoch [644/1000], Step [5/8], d_loss: 8.6969, g_loss: -0.0000\n",
            "Epoch [644/1000], Step [6/8], d_loss: 8.9960, g_loss: -0.0283\n",
            "Epoch [644/1000], Step [7/8], d_loss: 2495.2288, g_loss: -0.0000\n",
            "Epoch [644/1000], Step [8/8], d_loss: 3961.0259, g_loss: -0.0008\n",
            "Epoch [645/1000], Step [1/8], d_loss: 9.0313, g_loss: -0.0000\n",
            "Epoch [645/1000], Step [2/8], d_loss: 11.9437, g_loss: -0.0000\n",
            "Epoch [645/1000], Step [3/8], d_loss: 8.7219, g_loss: -0.0000\n",
            "Epoch [645/1000], Step [4/8], d_loss: 8.9823, g_loss: -0.0001\n",
            "Epoch [645/1000], Step [5/8], d_loss: 2281.9158, g_loss: -0.0000\n",
            "Epoch [645/1000], Step [6/8], d_loss: 8.9466, g_loss: -0.0000\n",
            "Epoch [645/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [645/1000], Step [8/8], d_loss: 3870.2075, g_loss: -0.0066\n",
            "Epoch [646/1000], Step [1/8], d_loss: 8.9621, g_loss: -0.0003\n",
            "Epoch [646/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [646/1000], Step [3/8], d_loss: 8.9801, g_loss: -0.0000\n",
            "Epoch [646/1000], Step [4/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [646/1000], Step [5/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [646/1000], Step [6/8], d_loss: 68.6918, g_loss: -0.0307\n",
            "Epoch [646/1000], Step [7/8], d_loss: 309.9146, g_loss: -0.0008\n",
            "Epoch [646/1000], Step [8/8], d_loss: 8.7129, g_loss: -0.0000\n",
            "Epoch [647/1000], Step [1/8], d_loss: 8.9951, g_loss: -0.0000\n",
            "Epoch [647/1000], Step [2/8], d_loss: 3479.4741, g_loss: -0.0000\n",
            "Epoch [647/1000], Step [3/8], d_loss: 9.0040, g_loss: -0.0312\n",
            "Epoch [647/1000], Step [4/8], d_loss: 8.9990, g_loss: -0.0000\n",
            "Epoch [647/1000], Step [5/8], d_loss: 8.7702, g_loss: -0.0000\n",
            "Epoch [647/1000], Step [6/8], d_loss: 9.0906, g_loss: -0.0000\n",
            "Epoch [647/1000], Step [7/8], d_loss: 8.7569, g_loss: -0.0000\n",
            "Epoch [647/1000], Step [8/8], d_loss: 8.7510, g_loss: -0.0000\n",
            "Epoch [648/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [648/1000], Step [2/8], d_loss: 8.9800, g_loss: -0.0000\n",
            "Epoch [648/1000], Step [3/8], d_loss: 1571.4033, g_loss: -0.0000\n",
            "Epoch [648/1000], Step [4/8], d_loss: 8.9990, g_loss: -0.0000\n",
            "Epoch [648/1000], Step [5/8], d_loss: 9.0222, g_loss: -0.0276\n",
            "Epoch [648/1000], Step [6/8], d_loss: 8.6932, g_loss: -0.0001\n",
            "Epoch [648/1000], Step [7/8], d_loss: 203.4788, g_loss: -0.0000\n",
            "Epoch [648/1000], Step [8/8], d_loss: 2593.4915, g_loss: -0.0000\n",
            "Epoch [649/1000], Step [1/8], d_loss: 8.9770, g_loss: -0.0000\n",
            "Epoch [649/1000], Step [2/8], d_loss: 448.4550, g_loss: -0.0000\n",
            "Epoch [649/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0312\n",
            "Epoch [649/1000], Step [4/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [649/1000], Step [5/8], d_loss: 843.8211, g_loss: -0.0000\n",
            "Epoch [649/1000], Step [6/8], d_loss: 11.0398, g_loss: -0.0000\n",
            "Epoch [649/1000], Step [7/8], d_loss: 495.9424, g_loss: -0.0312\n",
            "Epoch [649/1000], Step [8/8], d_loss: 8.7777, g_loss: -0.0006\n",
            "Epoch [650/1000], Step [1/8], d_loss: 1303.9847, g_loss: -0.0000\n",
            "Epoch [650/1000], Step [2/8], d_loss: 9.0071, g_loss: -0.0000\n",
            "Epoch [650/1000], Step [3/8], d_loss: 8.8792, g_loss: -0.0000\n",
            "Epoch [650/1000], Step [4/8], d_loss: 8.9854, g_loss: -0.0046\n",
            "Epoch [650/1000], Step [5/8], d_loss: 4453.3940, g_loss: -0.0015\n",
            "Epoch [650/1000], Step [6/8], d_loss: 6393.9136, g_loss: -0.0000\n",
            "Epoch [650/1000], Step [7/8], d_loss: 8.9720, g_loss: -0.0000\n",
            "Epoch [650/1000], Step [8/8], d_loss: 8.9959, g_loss: -0.0000\n",
            "Epoch [651/1000], Step [1/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [651/1000], Step [2/8], d_loss: 9.6266, g_loss: -0.0000\n",
            "Epoch [651/1000], Step [3/8], d_loss: 8.9878, g_loss: -0.0000\n",
            "Epoch [651/1000], Step [4/8], d_loss: 8.5455, g_loss: -0.0000\n",
            "Epoch [651/1000], Step [5/8], d_loss: 12700.5488, g_loss: -0.0000\n",
            "Epoch [651/1000], Step [6/8], d_loss: 738.1068, g_loss: -0.0000\n",
            "Epoch [651/1000], Step [7/8], d_loss: 2130.7922, g_loss: -0.0000\n",
            "Epoch [651/1000], Step [8/8], d_loss: 140.5220, g_loss: -0.0000\n",
            "Epoch [652/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [652/1000], Step [2/8], d_loss: 1982.9932, g_loss: -0.0000\n",
            "Epoch [652/1000], Step [3/8], d_loss: 14.0371, g_loss: -0.0000\n",
            "Epoch [652/1000], Step [4/8], d_loss: 8.8573, g_loss: -0.0000\n",
            "Epoch [652/1000], Step [5/8], d_loss: 8.9973, g_loss: -0.0000\n",
            "Epoch [652/1000], Step [6/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [652/1000], Step [7/8], d_loss: 2831.7039, g_loss: -0.0000\n",
            "Epoch [652/1000], Step [8/8], d_loss: 10.1398, g_loss: -0.0029\n",
            "Epoch [653/1000], Step [1/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [653/1000], Step [2/8], d_loss: 8.9874, g_loss: -0.0000\n",
            "Epoch [653/1000], Step [3/8], d_loss: 8.9640, g_loss: -0.0000\n",
            "Epoch [653/1000], Step [4/8], d_loss: 9.0159, g_loss: -0.0000\n",
            "Epoch [653/1000], Step [5/8], d_loss: 8.9546, g_loss: -0.0043\n",
            "Epoch [653/1000], Step [6/8], d_loss: 8.9949, g_loss: -0.0000\n",
            "Epoch [653/1000], Step [7/8], d_loss: 8.9028, g_loss: -0.0000\n",
            "Epoch [653/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [654/1000], Step [1/8], d_loss: 8.5347, g_loss: -0.0000\n",
            "Epoch [654/1000], Step [2/8], d_loss: 8.8466, g_loss: -0.0000\n",
            "Epoch [654/1000], Step [3/8], d_loss: 8.9991, g_loss: -0.0758\n",
            "Epoch [654/1000], Step [4/8], d_loss: 973.7052, g_loss: -0.0312\n",
            "Epoch [654/1000], Step [5/8], d_loss: 528.3575, g_loss: -0.0000\n",
            "Epoch [654/1000], Step [6/8], d_loss: 1850.3334, g_loss: -0.0000\n",
            "Epoch [654/1000], Step [7/8], d_loss: 8.7955, g_loss: -0.0000\n",
            "Epoch [654/1000], Step [8/8], d_loss: 8.6299, g_loss: -0.0000\n",
            "Epoch [655/1000], Step [1/8], d_loss: 593.7753, g_loss: -0.0000\n",
            "Epoch [655/1000], Step [2/8], d_loss: 8.7385, g_loss: -0.0000\n",
            "Epoch [655/1000], Step [3/8], d_loss: 8.9879, g_loss: -0.0307\n",
            "Epoch [655/1000], Step [4/8], d_loss: 1380.4292, g_loss: -0.0000\n",
            "Epoch [655/1000], Step [5/8], d_loss: 5256.8999, g_loss: -0.0234\n",
            "Epoch [655/1000], Step [6/8], d_loss: 149.5833, g_loss: -0.0000\n",
            "Epoch [655/1000], Step [7/8], d_loss: 9.0119, g_loss: -0.0000\n",
            "Epoch [655/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0241\n",
            "Epoch [656/1000], Step [1/8], d_loss: 6380.8696, g_loss: -0.0000\n",
            "Epoch [656/1000], Step [2/8], d_loss: 3721.1709, g_loss: -0.0000\n",
            "Epoch [656/1000], Step [3/8], d_loss: 8.9583, g_loss: -0.0001\n",
            "Epoch [656/1000], Step [4/8], d_loss: 8.9987, g_loss: -0.0000\n",
            "Epoch [656/1000], Step [5/8], d_loss: 9.0179, g_loss: -0.0000\n",
            "Epoch [656/1000], Step [6/8], d_loss: 9.0027, g_loss: -0.0000\n",
            "Epoch [656/1000], Step [7/8], d_loss: 11886.8984, g_loss: -0.0000\n",
            "Epoch [656/1000], Step [8/8], d_loss: 8.9906, g_loss: -0.0047\n",
            "Epoch [657/1000], Step [1/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [657/1000], Step [2/8], d_loss: 9285.2168, g_loss: -0.0000\n",
            "Epoch [657/1000], Step [3/8], d_loss: 853.1466, g_loss: -0.0000\n",
            "Epoch [657/1000], Step [4/8], d_loss: 3291.3003, g_loss: -0.0000\n",
            "Epoch [657/1000], Step [5/8], d_loss: 2512.9658, g_loss: -0.0000\n",
            "Epoch [657/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [657/1000], Step [7/8], d_loss: 410.1575, g_loss: -0.0309\n",
            "Epoch [657/1000], Step [8/8], d_loss: 8.9889, g_loss: -0.0000\n",
            "Epoch [658/1000], Step [1/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [658/1000], Step [2/8], d_loss: 8.9169, g_loss: -0.0000\n",
            "Epoch [658/1000], Step [3/8], d_loss: 1781.6228, g_loss: -0.0001\n",
            "Epoch [658/1000], Step [4/8], d_loss: 12.5866, g_loss: -0.0000\n",
            "Epoch [658/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [658/1000], Step [6/8], d_loss: 3795.9316, g_loss: -0.0000\n",
            "Epoch [658/1000], Step [7/8], d_loss: 9.0009, g_loss: -0.0000\n",
            "Epoch [658/1000], Step [8/8], d_loss: 9.0062, g_loss: -0.0000\n",
            "Epoch [659/1000], Step [1/8], d_loss: 8.9872, g_loss: -0.0006\n",
            "Epoch [659/1000], Step [2/8], d_loss: 1049.8137, g_loss: -0.0000\n",
            "Epoch [659/1000], Step [3/8], d_loss: 210.7551, g_loss: -0.0000\n",
            "Epoch [659/1000], Step [4/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [659/1000], Step [5/8], d_loss: 307.4715, g_loss: -0.0000\n",
            "Epoch [659/1000], Step [6/8], d_loss: 2322.4868, g_loss: -0.0000\n",
            "Epoch [659/1000], Step [7/8], d_loss: 8.6908, g_loss: -0.0025\n",
            "Epoch [659/1000], Step [8/8], d_loss: 8.9999, g_loss: -0.0009\n",
            "Epoch [660/1000], Step [1/8], d_loss: 8.9209, g_loss: -0.0002\n",
            "Epoch [660/1000], Step [2/8], d_loss: 9.0312, g_loss: -0.0002\n",
            "Epoch [660/1000], Step [3/8], d_loss: 4351.4434, g_loss: -0.0000\n",
            "Epoch [660/1000], Step [4/8], d_loss: 12645.3174, g_loss: -0.0000\n",
            "Epoch [660/1000], Step [5/8], d_loss: 577.8108, g_loss: -0.0001\n",
            "Epoch [660/1000], Step [6/8], d_loss: 3602.9988, g_loss: -0.0000\n",
            "Epoch [660/1000], Step [7/8], d_loss: 8.6985, g_loss: -0.0000\n",
            "Epoch [660/1000], Step [8/8], d_loss: 19.9253, g_loss: -0.0000\n",
            "Epoch [661/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [661/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [661/1000], Step [3/8], d_loss: 267.3803, g_loss: -0.0313\n",
            "Epoch [661/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [661/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [661/1000], Step [6/8], d_loss: 8.8153, g_loss: -0.0189\n",
            "Epoch [661/1000], Step [7/8], d_loss: 685.2280, g_loss: -0.0001\n",
            "Epoch [661/1000], Step [8/8], d_loss: 1982.1934, g_loss: -0.0000\n",
            "Epoch [662/1000], Step [1/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [662/1000], Step [2/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [662/1000], Step [3/8], d_loss: 9.3901, g_loss: -0.0001\n",
            "Epoch [662/1000], Step [4/8], d_loss: 10.3019, g_loss: -0.0000\n",
            "Epoch [662/1000], Step [5/8], d_loss: 1796.8013, g_loss: -0.0000\n",
            "Epoch [662/1000], Step [6/8], d_loss: 8.9829, g_loss: -0.0000\n",
            "Epoch [662/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [662/1000], Step [8/8], d_loss: 1102.6862, g_loss: -0.0000\n",
            "Epoch [663/1000], Step [1/8], d_loss: 12.3903, g_loss: -0.0000\n",
            "Epoch [663/1000], Step [2/8], d_loss: 1697.6862, g_loss: -0.0000\n",
            "Epoch [663/1000], Step [3/8], d_loss: 8.7280, g_loss: -0.0000\n",
            "Epoch [663/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [663/1000], Step [5/8], d_loss: 8.9701, g_loss: -0.0000\n",
            "Epoch [663/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [663/1000], Step [7/8], d_loss: 549.5099, g_loss: -0.0000\n",
            "Epoch [663/1000], Step [8/8], d_loss: 8.9955, g_loss: -0.0000\n",
            "Epoch [664/1000], Step [1/8], d_loss: 535.3134, g_loss: -0.0000\n",
            "Epoch [664/1000], Step [2/8], d_loss: 4680.9395, g_loss: -0.0000\n",
            "Epoch [664/1000], Step [3/8], d_loss: 737.1642, g_loss: -0.0000\n",
            "Epoch [664/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [664/1000], Step [5/8], d_loss: 8.5659, g_loss: -0.0000\n",
            "Epoch [664/1000], Step [6/8], d_loss: 981.7382, g_loss: -0.0000\n",
            "Epoch [664/1000], Step [7/8], d_loss: 17.7913, g_loss: -0.0000\n",
            "Epoch [664/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [665/1000], Step [1/8], d_loss: 12.4955, g_loss: -0.0000\n",
            "Epoch [665/1000], Step [2/8], d_loss: 199.9250, g_loss: -0.0000\n",
            "Epoch [665/1000], Step [3/8], d_loss: 2377.4861, g_loss: -0.0000\n",
            "Epoch [665/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [665/1000], Step [5/8], d_loss: 8.8657, g_loss: -0.0000\n",
            "Epoch [665/1000], Step [6/8], d_loss: 25.9629, g_loss: -0.0000\n",
            "Epoch [665/1000], Step [7/8], d_loss: 756.5504, g_loss: -0.0000\n",
            "Epoch [665/1000], Step [8/8], d_loss: 5624.1851, g_loss: -0.0000\n",
            "Epoch [666/1000], Step [1/8], d_loss: 11.0231, g_loss: -0.0000\n",
            "Epoch [666/1000], Step [2/8], d_loss: 22.0832, g_loss: -0.0000\n",
            "Epoch [666/1000], Step [3/8], d_loss: 8.9889, g_loss: -0.0000\n",
            "Epoch [666/1000], Step [4/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [666/1000], Step [5/8], d_loss: 8.8149, g_loss: -0.0000\n",
            "Epoch [666/1000], Step [6/8], d_loss: 7358.9336, g_loss: -0.0000\n",
            "Epoch [666/1000], Step [7/8], d_loss: 285.5500, g_loss: -0.0303\n",
            "Epoch [666/1000], Step [8/8], d_loss: 1319.1830, g_loss: -0.0000\n",
            "Epoch [667/1000], Step [1/8], d_loss: 8.8563, g_loss: -0.0000\n",
            "Epoch [667/1000], Step [2/8], d_loss: 8.8291, g_loss: -0.0000\n",
            "Epoch [667/1000], Step [3/8], d_loss: 512.0672, g_loss: -0.0000\n",
            "Epoch [667/1000], Step [4/8], d_loss: 84.9071, g_loss: -0.0000\n",
            "Epoch [667/1000], Step [5/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [667/1000], Step [6/8], d_loss: 1037.9462, g_loss: -0.0168\n",
            "Epoch [667/1000], Step [7/8], d_loss: 9.0088, g_loss: -0.0000\n",
            "Epoch [667/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [668/1000], Step [1/8], d_loss: 2874.7349, g_loss: -0.0000\n",
            "Epoch [668/1000], Step [2/8], d_loss: 4569.0737, g_loss: -0.0000\n",
            "Epoch [668/1000], Step [3/8], d_loss: 10.2417, g_loss: -0.0000\n",
            "Epoch [668/1000], Step [4/8], d_loss: 99.3834, g_loss: -0.0000\n",
            "Epoch [668/1000], Step [5/8], d_loss: 7285.5430, g_loss: -0.0000\n",
            "Epoch [668/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [668/1000], Step [7/8], d_loss: 9.0308, g_loss: -0.0000\n",
            "Epoch [668/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [669/1000], Step [1/8], d_loss: 13110.2842, g_loss: -0.0000\n",
            "Epoch [669/1000], Step [2/8], d_loss: 587.0592, g_loss: -0.0131\n",
            "Epoch [669/1000], Step [3/8], d_loss: 9.0667, g_loss: -0.0000\n",
            "Epoch [669/1000], Step [4/8], d_loss: 428.4074, g_loss: -0.0000\n",
            "Epoch [669/1000], Step [5/8], d_loss: 1690.3207, g_loss: -0.0000\n",
            "Epoch [669/1000], Step [6/8], d_loss: 3644.2495, g_loss: -0.0000\n",
            "Epoch [669/1000], Step [7/8], d_loss: 2215.9082, g_loss: -0.0000\n",
            "Epoch [669/1000], Step [8/8], d_loss: 8.9732, g_loss: -0.0000\n",
            "Epoch [670/1000], Step [1/8], d_loss: 8.7539, g_loss: -0.0000\n",
            "Epoch [670/1000], Step [2/8], d_loss: 9.8305, g_loss: -0.0000\n",
            "Epoch [670/1000], Step [3/8], d_loss: 9714.1416, g_loss: -0.0000\n",
            "Epoch [670/1000], Step [4/8], d_loss: 3516.7981, g_loss: -0.0000\n",
            "Epoch [670/1000], Step [5/8], d_loss: 8.9927, g_loss: -0.0002\n",
            "Epoch [670/1000], Step [6/8], d_loss: 8.8662, g_loss: -0.0000\n",
            "Epoch [670/1000], Step [7/8], d_loss: 8.7545, g_loss: -0.0000\n",
            "Epoch [670/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [671/1000], Step [1/8], d_loss: 227.9694, g_loss: -0.0000\n",
            "Epoch [671/1000], Step [2/8], d_loss: 9.7467, g_loss: -0.0000\n",
            "Epoch [671/1000], Step [3/8], d_loss: 265.8461, g_loss: -0.0000\n",
            "Epoch [671/1000], Step [4/8], d_loss: 12.5886, g_loss: -0.0000\n",
            "Epoch [671/1000], Step [5/8], d_loss: 313.7997, g_loss: -0.0002\n",
            "Epoch [671/1000], Step [6/8], d_loss: 4737.8442, g_loss: -0.0000\n",
            "Epoch [671/1000], Step [7/8], d_loss: 625.1172, g_loss: -0.0000\n",
            "Epoch [671/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [672/1000], Step [1/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [672/1000], Step [2/8], d_loss: 8.9184, g_loss: -0.0000\n",
            "Epoch [672/1000], Step [3/8], d_loss: 572.4702, g_loss: -0.0000\n",
            "Epoch [672/1000], Step [4/8], d_loss: 9032.6172, g_loss: -0.0000\n",
            "Epoch [672/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [672/1000], Step [6/8], d_loss: 8.7505, g_loss: -0.0000\n",
            "Epoch [672/1000], Step [7/8], d_loss: 3720.6638, g_loss: -0.0000\n",
            "Epoch [672/1000], Step [8/8], d_loss: 3725.1443, g_loss: -0.0056\n",
            "Epoch [673/1000], Step [1/8], d_loss: 8.7351, g_loss: -0.0051\n",
            "Epoch [673/1000], Step [2/8], d_loss: 9.0623, g_loss: -0.0000\n",
            "Epoch [673/1000], Step [3/8], d_loss: 36.7896, g_loss: -0.0000\n",
            "Epoch [673/1000], Step [4/8], d_loss: 7366.1152, g_loss: -0.0000\n",
            "Epoch [673/1000], Step [5/8], d_loss: 907.5903, g_loss: -0.0000\n",
            "Epoch [673/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [673/1000], Step [7/8], d_loss: 3327.9597, g_loss: -0.0000\n",
            "Epoch [673/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0434\n",
            "Epoch [674/1000], Step [1/8], d_loss: 9.0011, g_loss: -0.0000\n",
            "Epoch [674/1000], Step [2/8], d_loss: 9.0006, g_loss: -0.0000\n",
            "Epoch [674/1000], Step [3/8], d_loss: 8.5964, g_loss: -0.0000\n",
            "Epoch [674/1000], Step [4/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [674/1000], Step [5/8], d_loss: 8.9963, g_loss: -0.0000\n",
            "Epoch [674/1000], Step [6/8], d_loss: 9.0046, g_loss: -0.0000\n",
            "Epoch [674/1000], Step [7/8], d_loss: 8.7366, g_loss: -0.0312\n",
            "Epoch [674/1000], Step [8/8], d_loss: 8.0882, g_loss: -0.0054\n",
            "Epoch [675/1000], Step [1/8], d_loss: 3551.0928, g_loss: -0.0000\n",
            "Epoch [675/1000], Step [2/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [675/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [675/1000], Step [4/8], d_loss: 8.7403, g_loss: -0.0000\n",
            "Epoch [675/1000], Step [5/8], d_loss: 1327.3002, g_loss: -0.0000\n",
            "Epoch [675/1000], Step [6/8], d_loss: 8.9467, g_loss: -0.0000\n",
            "Epoch [675/1000], Step [7/8], d_loss: 2792.4644, g_loss: -0.0000\n",
            "Epoch [675/1000], Step [8/8], d_loss: 8.9979, g_loss: -0.0000\n",
            "Epoch [676/1000], Step [1/8], d_loss: 8.9905, g_loss: -0.0000\n",
            "Epoch [676/1000], Step [2/8], d_loss: 8.7019, g_loss: -0.0000\n",
            "Epoch [676/1000], Step [3/8], d_loss: 8.9852, g_loss: -0.0000\n",
            "Epoch [676/1000], Step [4/8], d_loss: 561.2881, g_loss: -0.0000\n",
            "Epoch [676/1000], Step [5/8], d_loss: 32.7036, g_loss: -0.0000\n",
            "Epoch [676/1000], Step [6/8], d_loss: 8.9508, g_loss: -0.0000\n",
            "Epoch [676/1000], Step [7/8], d_loss: 8.9632, g_loss: -0.0000\n",
            "Epoch [676/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [677/1000], Step [1/8], d_loss: 40.7686, g_loss: -0.0000\n",
            "Epoch [677/1000], Step [2/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [677/1000], Step [3/8], d_loss: 8.9893, g_loss: -0.0000\n",
            "Epoch [677/1000], Step [4/8], d_loss: 3825.1665, g_loss: -0.0000\n",
            "Epoch [677/1000], Step [5/8], d_loss: 14.2353, g_loss: -0.0000\n",
            "Epoch [677/1000], Step [6/8], d_loss: 8.9604, g_loss: -0.0000\n",
            "Epoch [677/1000], Step [7/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [677/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [678/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [678/1000], Step [2/8], d_loss: 131.0391, g_loss: -0.0000\n",
            "Epoch [678/1000], Step [3/8], d_loss: 230.3940, g_loss: -0.0000\n",
            "Epoch [678/1000], Step [4/8], d_loss: 8.9768, g_loss: -0.0111\n",
            "Epoch [678/1000], Step [5/8], d_loss: 8.9034, g_loss: -0.0000\n",
            "Epoch [678/1000], Step [6/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [678/1000], Step [7/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [678/1000], Step [8/8], d_loss: 9.2256, g_loss: -0.0000\n",
            "Epoch [679/1000], Step [1/8], d_loss: 5776.0234, g_loss: -0.0003\n",
            "Epoch [679/1000], Step [2/8], d_loss: 4221.1475, g_loss: -0.0000\n",
            "Epoch [679/1000], Step [3/8], d_loss: 1446.3936, g_loss: -0.0000\n",
            "Epoch [679/1000], Step [4/8], d_loss: 2835.9370, g_loss: -0.0000\n",
            "Epoch [679/1000], Step [5/8], d_loss: 8.9989, g_loss: -0.0130\n",
            "Epoch [679/1000], Step [6/8], d_loss: 772.3816, g_loss: -0.0000\n",
            "Epoch [679/1000], Step [7/8], d_loss: 4028.7109, g_loss: -0.0000\n",
            "Epoch [679/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [680/1000], Step [1/8], d_loss: 10.0724, g_loss: -0.0000\n",
            "Epoch [680/1000], Step [2/8], d_loss: 81.7545, g_loss: -0.0000\n",
            "Epoch [680/1000], Step [3/8], d_loss: 17.9574, g_loss: -0.0000\n",
            "Epoch [680/1000], Step [4/8], d_loss: 787.5605, g_loss: -0.0000\n",
            "Epoch [680/1000], Step [5/8], d_loss: 15.4686, g_loss: -0.0002\n",
            "Epoch [680/1000], Step [6/8], d_loss: 3799.7766, g_loss: -0.0000\n",
            "Epoch [680/1000], Step [7/8], d_loss: 8.9915, g_loss: -0.0000\n",
            "Epoch [680/1000], Step [8/8], d_loss: 27.4440, g_loss: -0.0000\n",
            "Epoch [681/1000], Step [1/8], d_loss: 9.0071, g_loss: -0.0000\n",
            "Epoch [681/1000], Step [2/8], d_loss: 4705.3945, g_loss: -0.0312\n",
            "Epoch [681/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [681/1000], Step [4/8], d_loss: 8.9553, g_loss: -0.0000\n",
            "Epoch [681/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [681/1000], Step [6/8], d_loss: 8.8377, g_loss: -0.0000\n",
            "Epoch [681/1000], Step [7/8], d_loss: 13.3647, g_loss: -0.0000\n",
            "Epoch [681/1000], Step [8/8], d_loss: 8.6732, g_loss: -0.0000\n",
            "Epoch [682/1000], Step [1/8], d_loss: 54.0561, g_loss: -0.0000\n",
            "Epoch [682/1000], Step [2/8], d_loss: 11535.6064, g_loss: -0.0000\n",
            "Epoch [682/1000], Step [3/8], d_loss: 9.0275, g_loss: -0.0000\n",
            "Epoch [682/1000], Step [4/8], d_loss: 6096.5220, g_loss: -0.0000\n",
            "Epoch [682/1000], Step [5/8], d_loss: 8.6989, g_loss: -0.0000\n",
            "Epoch [682/1000], Step [6/8], d_loss: 230.5754, g_loss: -0.0000\n",
            "Epoch [682/1000], Step [7/8], d_loss: 8.8873, g_loss: -0.0000\n",
            "Epoch [682/1000], Step [8/8], d_loss: 13816.2715, g_loss: -0.0000\n",
            "Epoch [683/1000], Step [1/8], d_loss: 10.0655, g_loss: -0.0000\n",
            "Epoch [683/1000], Step [2/8], d_loss: 2764.1133, g_loss: -0.0000\n",
            "Epoch [683/1000], Step [3/8], d_loss: 594.5466, g_loss: -0.0000\n",
            "Epoch [683/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [683/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [683/1000], Step [6/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [683/1000], Step [7/8], d_loss: 8.8358, g_loss: -0.0000\n",
            "Epoch [683/1000], Step [8/8], d_loss: 452.5277, g_loss: -0.0000\n",
            "Epoch [684/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [684/1000], Step [2/8], d_loss: 1984.2415, g_loss: -0.0000\n",
            "Epoch [684/1000], Step [3/8], d_loss: 8.9959, g_loss: -0.0000\n",
            "Epoch [684/1000], Step [4/8], d_loss: 203.6554, g_loss: -0.0000\n",
            "Epoch [684/1000], Step [5/8], d_loss: 3427.7090, g_loss: -0.0313\n",
            "Epoch [684/1000], Step [6/8], d_loss: 8.9985, g_loss: -0.0624\n",
            "Epoch [684/1000], Step [7/8], d_loss: 8.9852, g_loss: -0.0000\n",
            "Epoch [684/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [685/1000], Step [1/8], d_loss: 2556.4990, g_loss: -0.0000\n",
            "Epoch [685/1000], Step [2/8], d_loss: 8.9917, g_loss: -0.0000\n",
            "Epoch [685/1000], Step [3/8], d_loss: 9.0295, g_loss: -0.0000\n",
            "Epoch [685/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [685/1000], Step [5/8], d_loss: 8.9912, g_loss: -0.0000\n",
            "Epoch [685/1000], Step [6/8], d_loss: 9.6072, g_loss: -0.0000\n",
            "Epoch [685/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [685/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0435\n",
            "Epoch [686/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [686/1000], Step [2/8], d_loss: 9.6916, g_loss: -0.0012\n",
            "Epoch [686/1000], Step [3/8], d_loss: 8.4373, g_loss: -0.0000\n",
            "Epoch [686/1000], Step [4/8], d_loss: 1282.8071, g_loss: -0.0000\n",
            "Epoch [686/1000], Step [5/8], d_loss: 8.8768, g_loss: -0.0000\n",
            "Epoch [686/1000], Step [6/8], d_loss: 8.8735, g_loss: -0.0000\n",
            "Epoch [686/1000], Step [7/8], d_loss: 6099.3584, g_loss: -0.0000\n",
            "Epoch [686/1000], Step [8/8], d_loss: 9.0044, g_loss: -0.0000\n",
            "Epoch [687/1000], Step [1/8], d_loss: 9.0308, g_loss: -0.0312\n",
            "Epoch [687/1000], Step [2/8], d_loss: 8.9984, g_loss: -0.0000\n",
            "Epoch [687/1000], Step [3/8], d_loss: 8.7963, g_loss: -0.0000\n",
            "Epoch [687/1000], Step [4/8], d_loss: 15.8103, g_loss: -0.0000\n",
            "Epoch [687/1000], Step [5/8], d_loss: 8.9954, g_loss: -0.0000\n",
            "Epoch [687/1000], Step [6/8], d_loss: 1816.5679, g_loss: -0.0000\n",
            "Epoch [687/1000], Step [7/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [687/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [688/1000], Step [1/8], d_loss: 8.9928, g_loss: -0.0000\n",
            "Epoch [688/1000], Step [2/8], d_loss: 76.7325, g_loss: -0.0000\n",
            "Epoch [688/1000], Step [3/8], d_loss: 2535.5486, g_loss: -0.0000\n",
            "Epoch [688/1000], Step [4/8], d_loss: 8.7197, g_loss: -0.0000\n",
            "Epoch [688/1000], Step [5/8], d_loss: 176.8660, g_loss: -0.0000\n",
            "Epoch [688/1000], Step [6/8], d_loss: 8.8083, g_loss: -0.0000\n",
            "Epoch [688/1000], Step [7/8], d_loss: 8.9983, g_loss: -0.0000\n",
            "Epoch [688/1000], Step [8/8], d_loss: 8.9986, g_loss: -0.0001\n",
            "Epoch [689/1000], Step [1/8], d_loss: 732.8885, g_loss: -0.0000\n",
            "Epoch [689/1000], Step [2/8], d_loss: 9.0204, g_loss: -0.0000\n",
            "Epoch [689/1000], Step [3/8], d_loss: 245.2083, g_loss: -0.0000\n",
            "Epoch [689/1000], Step [4/8], d_loss: 8.9754, g_loss: -0.0000\n",
            "Epoch [689/1000], Step [5/8], d_loss: 151.1283, g_loss: -0.0000\n",
            "Epoch [689/1000], Step [6/8], d_loss: 1374.2007, g_loss: -0.0000\n",
            "Epoch [689/1000], Step [7/8], d_loss: 30.1487, g_loss: -0.0000\n",
            "Epoch [689/1000], Step [8/8], d_loss: 2789.3699, g_loss: -0.0000\n",
            "Epoch [690/1000], Step [1/8], d_loss: 8.8341, g_loss: -0.0000\n",
            "Epoch [690/1000], Step [2/8], d_loss: 9.0608, g_loss: -0.0000\n",
            "Epoch [690/1000], Step [3/8], d_loss: 18.5082, g_loss: -0.0137\n",
            "Epoch [690/1000], Step [4/8], d_loss: 9.0937, g_loss: -0.0000\n",
            "Epoch [690/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [690/1000], Step [6/8], d_loss: 8.7048, g_loss: -0.0000\n",
            "Epoch [690/1000], Step [7/8], d_loss: 9.0312, g_loss: -0.0038\n",
            "Epoch [690/1000], Step [8/8], d_loss: 9.0429, g_loss: -0.0435\n",
            "Epoch [691/1000], Step [1/8], d_loss: 8.9889, g_loss: -0.0000\n",
            "Epoch [691/1000], Step [2/8], d_loss: 8.9694, g_loss: -0.0000\n",
            "Epoch [691/1000], Step [3/8], d_loss: 8.6901, g_loss: -0.0000\n",
            "Epoch [691/1000], Step [4/8], d_loss: 8.9802, g_loss: -0.0000\n",
            "Epoch [691/1000], Step [5/8], d_loss: 277.1287, g_loss: -0.0000\n",
            "Epoch [691/1000], Step [6/8], d_loss: 334.5167, g_loss: -0.0000\n",
            "Epoch [691/1000], Step [7/8], d_loss: 417.6530, g_loss: -0.0000\n",
            "Epoch [691/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [692/1000], Step [1/8], d_loss: 8.9876, g_loss: -0.0000\n",
            "Epoch [692/1000], Step [2/8], d_loss: 8.9881, g_loss: -0.0001\n",
            "Epoch [692/1000], Step [3/8], d_loss: 9.0435, g_loss: -0.0000\n",
            "Epoch [692/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [692/1000], Step [5/8], d_loss: 8.9683, g_loss: -0.0000\n",
            "Epoch [692/1000], Step [6/8], d_loss: 93.0915, g_loss: -0.0000\n",
            "Epoch [692/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [692/1000], Step [8/8], d_loss: 4470.4746, g_loss: -0.0000\n",
            "Epoch [693/1000], Step [1/8], d_loss: 8.8748, g_loss: -0.0000\n",
            "Epoch [693/1000], Step [2/8], d_loss: 15800.3389, g_loss: -0.0001\n",
            "Epoch [693/1000], Step [3/8], d_loss: 1022.0840, g_loss: -0.0000\n",
            "Epoch [693/1000], Step [4/8], d_loss: 8.9638, g_loss: -0.0000\n",
            "Epoch [693/1000], Step [5/8], d_loss: 9.0311, g_loss: -0.0000\n",
            "Epoch [693/1000], Step [6/8], d_loss: 649.1674, g_loss: -0.0000\n",
            "Epoch [693/1000], Step [7/8], d_loss: 696.2016, g_loss: -0.0000\n",
            "Epoch [693/1000], Step [8/8], d_loss: 1116.3907, g_loss: -0.0000\n",
            "Epoch [694/1000], Step [1/8], d_loss: 529.1263, g_loss: -0.0000\n",
            "Epoch [694/1000], Step [2/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [694/1000], Step [3/8], d_loss: 9.0424, g_loss: -0.0000\n",
            "Epoch [694/1000], Step [4/8], d_loss: 9.0268, g_loss: -0.0000\n",
            "Epoch [694/1000], Step [5/8], d_loss: 1051.8621, g_loss: -0.0000\n",
            "Epoch [694/1000], Step [6/8], d_loss: 8.6734, g_loss: -0.0365\n",
            "Epoch [694/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0312\n",
            "Epoch [694/1000], Step [8/8], d_loss: 9.0868, g_loss: -0.0004\n",
            "Epoch [695/1000], Step [1/8], d_loss: 6440.5156, g_loss: -0.0000\n",
            "Epoch [695/1000], Step [2/8], d_loss: 12.8465, g_loss: -0.0000\n",
            "Epoch [695/1000], Step [3/8], d_loss: 8.9945, g_loss: -0.0000\n",
            "Epoch [695/1000], Step [4/8], d_loss: 8.7600, g_loss: -0.0000\n",
            "Epoch [695/1000], Step [5/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [695/1000], Step [6/8], d_loss: 8.6875, g_loss: -0.0000\n",
            "Epoch [695/1000], Step [7/8], d_loss: 243.3813, g_loss: -0.0000\n",
            "Epoch [695/1000], Step [8/8], d_loss: 8.8802, g_loss: -0.0000\n",
            "Epoch [696/1000], Step [1/8], d_loss: 3273.4617, g_loss: -0.0000\n",
            "Epoch [696/1000], Step [2/8], d_loss: 1962.9011, g_loss: -0.0000\n",
            "Epoch [696/1000], Step [3/8], d_loss: 76.6362, g_loss: -0.0000\n",
            "Epoch [696/1000], Step [4/8], d_loss: 8.8387, g_loss: -0.0000\n",
            "Epoch [696/1000], Step [5/8], d_loss: 532.8154, g_loss: -0.0000\n",
            "Epoch [696/1000], Step [6/8], d_loss: 351.9740, g_loss: -0.0001\n",
            "Epoch [696/1000], Step [7/8], d_loss: 16.5354, g_loss: -0.0000\n",
            "Epoch [696/1000], Step [8/8], d_loss: 8.5686, g_loss: -0.0000\n",
            "Epoch [697/1000], Step [1/8], d_loss: 18.3666, g_loss: -0.0003\n",
            "Epoch [697/1000], Step [2/8], d_loss: 12271.7324, g_loss: -0.0000\n",
            "Epoch [697/1000], Step [3/8], d_loss: 8.9744, g_loss: -0.0000\n",
            "Epoch [697/1000], Step [4/8], d_loss: 508.4988, g_loss: -0.0000\n",
            "Epoch [697/1000], Step [5/8], d_loss: 2159.3396, g_loss: -0.0007\n",
            "Epoch [697/1000], Step [6/8], d_loss: 8.9004, g_loss: -0.0312\n",
            "Epoch [697/1000], Step [7/8], d_loss: 9.0251, g_loss: -0.0000\n",
            "Epoch [697/1000], Step [8/8], d_loss: 9.0435, g_loss: -0.0000\n",
            "Epoch [698/1000], Step [1/8], d_loss: 8.6126, g_loss: -0.0000\n",
            "Epoch [698/1000], Step [2/8], d_loss: 8.5285, g_loss: -0.0000\n",
            "Epoch [698/1000], Step [3/8], d_loss: 1329.6329, g_loss: -0.0312\n",
            "Epoch [698/1000], Step [4/8], d_loss: 8.9959, g_loss: -0.0000\n",
            "Epoch [698/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [698/1000], Step [6/8], d_loss: 1310.0455, g_loss: -0.0001\n",
            "Epoch [698/1000], Step [7/8], d_loss: 2671.8809, g_loss: -0.0002\n",
            "Epoch [698/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [699/1000], Step [1/8], d_loss: 8.8701, g_loss: -0.0000\n",
            "Epoch [699/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0313\n",
            "Epoch [699/1000], Step [3/8], d_loss: 9.0313, g_loss: -0.0213\n",
            "Epoch [699/1000], Step [4/8], d_loss: 8.7074, g_loss: -0.0000\n",
            "Epoch [699/1000], Step [5/8], d_loss: 475.8972, g_loss: -0.0000\n",
            "Epoch [699/1000], Step [6/8], d_loss: 9.0263, g_loss: -0.0000\n",
            "Epoch [699/1000], Step [7/8], d_loss: 8.7116, g_loss: -0.0000\n",
            "Epoch [699/1000], Step [8/8], d_loss: 2415.2344, g_loss: -0.0000\n",
            "Epoch [700/1000], Step [1/8], d_loss: 8.7660, g_loss: -0.0317\n",
            "Epoch [700/1000], Step [2/8], d_loss: 166.7012, g_loss: -0.0000\n",
            "Epoch [700/1000], Step [3/8], d_loss: 8.7478, g_loss: -0.0000\n",
            "Epoch [700/1000], Step [4/8], d_loss: 316.7800, g_loss: -0.0204\n",
            "Epoch [700/1000], Step [5/8], d_loss: 9.0436, g_loss: -0.0000\n",
            "Epoch [700/1000], Step [6/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [700/1000], Step [7/8], d_loss: 8.9354, g_loss: -0.0000\n",
            "Epoch [700/1000], Step [8/8], d_loss: 8.6015, g_loss: -0.0000\n",
            "Epoch [701/1000], Step [1/8], d_loss: 9.0624, g_loss: -0.0000\n",
            "Epoch [701/1000], Step [2/8], d_loss: 8.9851, g_loss: -0.0000\n",
            "Epoch [701/1000], Step [3/8], d_loss: 8.9938, g_loss: -0.0000\n",
            "Epoch [701/1000], Step [4/8], d_loss: 10.1104, g_loss: -0.0000\n",
            "Epoch [701/1000], Step [5/8], d_loss: 3774.9236, g_loss: -0.0000\n",
            "Epoch [701/1000], Step [6/8], d_loss: 8.9832, g_loss: -0.0308\n",
            "Epoch [701/1000], Step [7/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [701/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [702/1000], Step [1/8], d_loss: 12.6484, g_loss: -0.0000\n",
            "Epoch [702/1000], Step [2/8], d_loss: 86.8060, g_loss: -0.0025\n",
            "Epoch [702/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [702/1000], Step [4/8], d_loss: 4996.6440, g_loss: -0.0938\n",
            "Epoch [702/1000], Step [5/8], d_loss: 9.0312, g_loss: -0.0005\n",
            "Epoch [702/1000], Step [6/8], d_loss: 8.7286, g_loss: -0.0000\n",
            "Epoch [702/1000], Step [7/8], d_loss: 22.4553, g_loss: -0.0001\n",
            "Epoch [702/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [703/1000], Step [1/8], d_loss: 13060.3438, g_loss: -0.0000\n",
            "Epoch [703/1000], Step [2/8], d_loss: 8.9613, g_loss: -0.0000\n",
            "Epoch [703/1000], Step [3/8], d_loss: 316.7067, g_loss: -0.0000\n",
            "Epoch [703/1000], Step [4/8], d_loss: 17.4049, g_loss: -0.0000\n",
            "Epoch [703/1000], Step [5/8], d_loss: 2828.3691, g_loss: -0.0000\n",
            "Epoch [703/1000], Step [6/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [703/1000], Step [7/8], d_loss: 9.0007, g_loss: -0.0000\n",
            "Epoch [703/1000], Step [8/8], d_loss: 8.9991, g_loss: -0.0001\n",
            "Epoch [704/1000], Step [1/8], d_loss: 9.0264, g_loss: -0.0000\n",
            "Epoch [704/1000], Step [2/8], d_loss: 8.7111, g_loss: -0.0000\n",
            "Epoch [704/1000], Step [3/8], d_loss: 8.9873, g_loss: -0.0000\n",
            "Epoch [704/1000], Step [4/8], d_loss: 62.3363, g_loss: -0.0000\n",
            "Epoch [704/1000], Step [5/8], d_loss: 9.0068, g_loss: -0.0000\n",
            "Epoch [704/1000], Step [6/8], d_loss: 215.1318, g_loss: -0.0000\n",
            "Epoch [704/1000], Step [7/8], d_loss: 8.6923, g_loss: -0.0000\n",
            "Epoch [704/1000], Step [8/8], d_loss: 8.6367, g_loss: -0.0000\n",
            "Epoch [705/1000], Step [1/8], d_loss: 9.3327, g_loss: -0.0000\n",
            "Epoch [705/1000], Step [2/8], d_loss: 11.1888, g_loss: -0.0000\n",
            "Epoch [705/1000], Step [3/8], d_loss: 1936.5951, g_loss: -0.0000\n",
            "Epoch [705/1000], Step [4/8], d_loss: 8.9973, g_loss: -0.0000\n",
            "Epoch [705/1000], Step [5/8], d_loss: 9.5884, g_loss: -0.0000\n",
            "Epoch [705/1000], Step [6/8], d_loss: 9.0295, g_loss: -0.0304\n",
            "Epoch [705/1000], Step [7/8], d_loss: 1176.9036, g_loss: -0.0909\n",
            "Epoch [705/1000], Step [8/8], d_loss: 8.9995, g_loss: -0.0000\n",
            "Epoch [706/1000], Step [1/8], d_loss: 520.0372, g_loss: -0.0000\n",
            "Epoch [706/1000], Step [2/8], d_loss: 155.1118, g_loss: -0.0000\n",
            "Epoch [706/1000], Step [3/8], d_loss: 9.3351, g_loss: -0.0000\n",
            "Epoch [706/1000], Step [4/8], d_loss: 3569.3977, g_loss: -0.0019\n",
            "Epoch [706/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [706/1000], Step [6/8], d_loss: 8.9345, g_loss: -0.0005\n",
            "Epoch [706/1000], Step [7/8], d_loss: 2577.5259, g_loss: -0.0000\n",
            "Epoch [706/1000], Step [8/8], d_loss: 8.9971, g_loss: -0.0000\n",
            "Epoch [707/1000], Step [1/8], d_loss: 8127.6646, g_loss: -0.0000\n",
            "Epoch [707/1000], Step [2/8], d_loss: 9.8546, g_loss: -0.0000\n",
            "Epoch [707/1000], Step [3/8], d_loss: 8.8413, g_loss: -0.0001\n",
            "Epoch [707/1000], Step [4/8], d_loss: 155.9830, g_loss: -0.0000\n",
            "Epoch [707/1000], Step [5/8], d_loss: 1165.9948, g_loss: -0.0000\n",
            "Epoch [707/1000], Step [6/8], d_loss: 4730.7876, g_loss: -0.0000\n",
            "Epoch [707/1000], Step [7/8], d_loss: 8.7512, g_loss: -0.0000\n",
            "Epoch [707/1000], Step [8/8], d_loss: 8.7310, g_loss: -0.0000\n",
            "Epoch [708/1000], Step [1/8], d_loss: 8.8976, g_loss: -0.0299\n",
            "Epoch [708/1000], Step [2/8], d_loss: 8.8331, g_loss: -0.0000\n",
            "Epoch [708/1000], Step [3/8], d_loss: 603.3191, g_loss: -0.0000\n",
            "Epoch [708/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0306\n",
            "Epoch [708/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0313\n",
            "Epoch [708/1000], Step [6/8], d_loss: 8.5590, g_loss: -0.0000\n",
            "Epoch [708/1000], Step [7/8], d_loss: 7139.1855, g_loss: -0.0121\n",
            "Epoch [708/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0365\n",
            "Epoch [709/1000], Step [1/8], d_loss: 8.9858, g_loss: -0.0000\n",
            "Epoch [709/1000], Step [2/8], d_loss: 8.7557, g_loss: -0.0000\n",
            "Epoch [709/1000], Step [3/8], d_loss: 41.2299, g_loss: -0.0000\n",
            "Epoch [709/1000], Step [4/8], d_loss: 2473.5054, g_loss: -0.0000\n",
            "Epoch [709/1000], Step [5/8], d_loss: 50.9192, g_loss: -0.0313\n",
            "Epoch [709/1000], Step [6/8], d_loss: 8.4928, g_loss: -0.0319\n",
            "Epoch [709/1000], Step [7/8], d_loss: 4508.9473, g_loss: -0.0312\n",
            "Epoch [709/1000], Step [8/8], d_loss: 9.0015, g_loss: -0.0000\n",
            "Epoch [710/1000], Step [1/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [710/1000], Step [2/8], d_loss: 1749.2615, g_loss: -0.0000\n",
            "Epoch [710/1000], Step [3/8], d_loss: 1235.8911, g_loss: -0.0000\n",
            "Epoch [710/1000], Step [4/8], d_loss: 7026.7773, g_loss: -0.0000\n",
            "Epoch [710/1000], Step [5/8], d_loss: 6374.6094, g_loss: -0.0000\n",
            "Epoch [710/1000], Step [6/8], d_loss: 9.0620, g_loss: -0.0000\n",
            "Epoch [710/1000], Step [7/8], d_loss: 52.4273, g_loss: -0.0000\n",
            "Epoch [710/1000], Step [8/8], d_loss: 8.6117, g_loss: -0.0000\n",
            "Epoch [711/1000], Step [1/8], d_loss: 5299.8262, g_loss: -0.0000\n",
            "Epoch [711/1000], Step [2/8], d_loss: 8.9973, g_loss: -0.0008\n",
            "Epoch [711/1000], Step [3/8], d_loss: 26.8075, g_loss: -0.0000\n",
            "Epoch [711/1000], Step [4/8], d_loss: 940.3796, g_loss: -0.0000\n",
            "Epoch [711/1000], Step [5/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [711/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [711/1000], Step [7/8], d_loss: 2057.7485, g_loss: -0.0000\n",
            "Epoch [711/1000], Step [8/8], d_loss: 8.9508, g_loss: -0.0000\n",
            "Epoch [712/1000], Step [1/8], d_loss: 3218.3896, g_loss: -0.0000\n",
            "Epoch [712/1000], Step [2/8], d_loss: 51.7631, g_loss: -0.0000\n",
            "Epoch [712/1000], Step [3/8], d_loss: 440.9792, g_loss: -0.0000\n",
            "Epoch [712/1000], Step [4/8], d_loss: 627.3476, g_loss: -0.0268\n",
            "Epoch [712/1000], Step [5/8], d_loss: 30.2567, g_loss: -0.0000\n",
            "Epoch [712/1000], Step [6/8], d_loss: 8618.4014, g_loss: -0.0312\n",
            "Epoch [712/1000], Step [7/8], d_loss: 8.9778, g_loss: -0.0000\n",
            "Epoch [712/1000], Step [8/8], d_loss: 9.0433, g_loss: -0.0000\n",
            "Epoch [713/1000], Step [1/8], d_loss: 8.9949, g_loss: -0.0002\n",
            "Epoch [713/1000], Step [2/8], d_loss: 8.9884, g_loss: -0.0000\n",
            "Epoch [713/1000], Step [3/8], d_loss: 571.7028, g_loss: -0.0312\n",
            "Epoch [713/1000], Step [4/8], d_loss: 8.8704, g_loss: -0.0312\n",
            "Epoch [713/1000], Step [5/8], d_loss: 3306.0002, g_loss: -0.0000\n",
            "Epoch [713/1000], Step [6/8], d_loss: 9.0012, g_loss: -0.0313\n",
            "Epoch [713/1000], Step [7/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [713/1000], Step [8/8], d_loss: 157.2176, g_loss: -0.0117\n",
            "Epoch [714/1000], Step [1/8], d_loss: 12.5141, g_loss: -0.0248\n",
            "Epoch [714/1000], Step [2/8], d_loss: 9.0287, g_loss: -0.0000\n",
            "Epoch [714/1000], Step [3/8], d_loss: 3846.8794, g_loss: -0.0000\n",
            "Epoch [714/1000], Step [4/8], d_loss: 8.8113, g_loss: -0.0000\n",
            "Epoch [714/1000], Step [5/8], d_loss: 8.9550, g_loss: -0.0000\n",
            "Epoch [714/1000], Step [6/8], d_loss: 1403.9417, g_loss: -0.0000\n",
            "Epoch [714/1000], Step [7/8], d_loss: 9.0314, g_loss: -0.0000\n",
            "Epoch [714/1000], Step [8/8], d_loss: 9.0861, g_loss: -0.0000\n",
            "Epoch [715/1000], Step [1/8], d_loss: 112.4350, g_loss: -0.0000\n",
            "Epoch [715/1000], Step [2/8], d_loss: 8470.1689, g_loss: -0.0000\n",
            "Epoch [715/1000], Step [3/8], d_loss: 8.9807, g_loss: -0.0000\n",
            "Epoch [715/1000], Step [4/8], d_loss: 8.9992, g_loss: -0.0000\n",
            "Epoch [715/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [715/1000], Step [6/8], d_loss: 8.7728, g_loss: -0.0002\n",
            "Epoch [715/1000], Step [7/8], d_loss: 9.0015, g_loss: -0.0002\n",
            "Epoch [715/1000], Step [8/8], d_loss: 28473.6680, g_loss: -0.0000\n",
            "Epoch [716/1000], Step [1/8], d_loss: 2436.3562, g_loss: -0.0000\n",
            "Epoch [716/1000], Step [2/8], d_loss: 8.9632, g_loss: -0.0000\n",
            "Epoch [716/1000], Step [3/8], d_loss: 9.0416, g_loss: -0.0000\n",
            "Epoch [716/1000], Step [4/8], d_loss: 9.0307, g_loss: -0.0000\n",
            "Epoch [716/1000], Step [5/8], d_loss: 1778.5179, g_loss: -0.0000\n",
            "Epoch [716/1000], Step [6/8], d_loss: 91.3269, g_loss: -0.0161\n",
            "Epoch [716/1000], Step [7/8], d_loss: 1208.1685, g_loss: -0.0000\n",
            "Epoch [716/1000], Step [8/8], d_loss: 1148.0522, g_loss: -0.0000\n",
            "Epoch [717/1000], Step [1/8], d_loss: 8.9989, g_loss: -0.0000\n",
            "Epoch [717/1000], Step [2/8], d_loss: 8.9995, g_loss: -0.0000\n",
            "Epoch [717/1000], Step [3/8], d_loss: 12.9451, g_loss: -0.0312\n",
            "Epoch [717/1000], Step [4/8], d_loss: 11.3653, g_loss: -0.0000\n",
            "Epoch [717/1000], Step [5/8], d_loss: 8.9374, g_loss: -0.0000\n",
            "Epoch [717/1000], Step [6/8], d_loss: 8710.2432, g_loss: -0.0000\n",
            "Epoch [717/1000], Step [7/8], d_loss: 9.3557, g_loss: -0.0000\n",
            "Epoch [717/1000], Step [8/8], d_loss: 296.8643, g_loss: -0.0000\n",
            "Epoch [718/1000], Step [1/8], d_loss: 8.7246, g_loss: -0.0005\n",
            "Epoch [718/1000], Step [2/8], d_loss: 9.0308, g_loss: -0.0000\n",
            "Epoch [718/1000], Step [3/8], d_loss: 8.7030, g_loss: -0.0000\n",
            "Epoch [718/1000], Step [4/8], d_loss: 48.6378, g_loss: -0.0000\n",
            "Epoch [718/1000], Step [5/8], d_loss: 8.9290, g_loss: -0.0000\n",
            "Epoch [718/1000], Step [6/8], d_loss: 9.0620, g_loss: -0.0000\n",
            "Epoch [718/1000], Step [7/8], d_loss: 6891.5044, g_loss: -0.0001\n",
            "Epoch [718/1000], Step [8/8], d_loss: 8.9883, g_loss: -0.0000\n",
            "Epoch [719/1000], Step [1/8], d_loss: 8.8567, g_loss: -0.0000\n",
            "Epoch [719/1000], Step [2/8], d_loss: 8.9589, g_loss: -0.0008\n",
            "Epoch [719/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [719/1000], Step [4/8], d_loss: 9.0307, g_loss: -0.0313\n",
            "Epoch [719/1000], Step [5/8], d_loss: 3366.9753, g_loss: -0.0000\n",
            "Epoch [719/1000], Step [6/8], d_loss: 8.6879, g_loss: -0.0313\n",
            "Epoch [719/1000], Step [7/8], d_loss: 17.0267, g_loss: -0.0000\n",
            "Epoch [719/1000], Step [8/8], d_loss: 8.5680, g_loss: -0.0000\n",
            "Epoch [720/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [720/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0238\n",
            "Epoch [720/1000], Step [3/8], d_loss: 8.9967, g_loss: -0.0001\n",
            "Epoch [720/1000], Step [4/8], d_loss: 1815.4766, g_loss: -0.0000\n",
            "Epoch [720/1000], Step [5/8], d_loss: 518.3253, g_loss: -0.0000\n",
            "Epoch [720/1000], Step [6/8], d_loss: 8.9489, g_loss: -0.0000\n",
            "Epoch [720/1000], Step [7/8], d_loss: 9.0595, g_loss: -0.0000\n",
            "Epoch [720/1000], Step [8/8], d_loss: 8.7888, g_loss: -0.0000\n",
            "Epoch [721/1000], Step [1/8], d_loss: 8.9394, g_loss: -0.0107\n",
            "Epoch [721/1000], Step [2/8], d_loss: 8.8961, g_loss: -0.0000\n",
            "Epoch [721/1000], Step [3/8], d_loss: 8.9990, g_loss: -0.0000\n",
            "Epoch [721/1000], Step [4/8], d_loss: 3016.8455, g_loss: -0.0000\n",
            "Epoch [721/1000], Step [5/8], d_loss: 21550.2148, g_loss: -0.0338\n",
            "Epoch [721/1000], Step [6/8], d_loss: 8.8514, g_loss: -0.0000\n",
            "Epoch [721/1000], Step [7/8], d_loss: 22.0097, g_loss: -0.0000\n",
            "Epoch [721/1000], Step [8/8], d_loss: 10200.3516, g_loss: -0.0000\n",
            "Epoch [722/1000], Step [1/8], d_loss: 519.1642, g_loss: -0.0000\n",
            "Epoch [722/1000], Step [2/8], d_loss: 8.7134, g_loss: -0.0000\n",
            "Epoch [722/1000], Step [3/8], d_loss: 8.9488, g_loss: -0.0000\n",
            "Epoch [722/1000], Step [4/8], d_loss: 6208.9224, g_loss: -0.0000\n",
            "Epoch [722/1000], Step [5/8], d_loss: 11.8166, g_loss: -0.0009\n",
            "Epoch [722/1000], Step [6/8], d_loss: 9.0582, g_loss: -0.0629\n",
            "Epoch [722/1000], Step [7/8], d_loss: 2119.5503, g_loss: -0.0000\n",
            "Epoch [722/1000], Step [8/8], d_loss: 8.8164, g_loss: -0.0000\n",
            "Epoch [723/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [723/1000], Step [2/8], d_loss: 61.9425, g_loss: -0.0000\n",
            "Epoch [723/1000], Step [3/8], d_loss: 1524.7782, g_loss: -0.0000\n",
            "Epoch [723/1000], Step [4/8], d_loss: 9.0008, g_loss: -0.0000\n",
            "Epoch [723/1000], Step [5/8], d_loss: 8.7319, g_loss: -0.0000\n",
            "Epoch [723/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [723/1000], Step [7/8], d_loss: 8.7613, g_loss: -0.0000\n",
            "Epoch [723/1000], Step [8/8], d_loss: 193.8413, g_loss: -0.0000\n",
            "Epoch [724/1000], Step [1/8], d_loss: 8.9493, g_loss: -0.0000\n",
            "Epoch [724/1000], Step [2/8], d_loss: 24.5254, g_loss: -0.0000\n",
            "Epoch [724/1000], Step [3/8], d_loss: 1549.9458, g_loss: -0.0312\n",
            "Epoch [724/1000], Step [4/8], d_loss: 8.9796, g_loss: -0.0000\n",
            "Epoch [724/1000], Step [5/8], d_loss: 10.6545, g_loss: -0.0000\n",
            "Epoch [724/1000], Step [6/8], d_loss: 13035.9258, g_loss: -0.0000\n",
            "Epoch [724/1000], Step [7/8], d_loss: 511.0297, g_loss: -0.0000\n",
            "Epoch [724/1000], Step [8/8], d_loss: 15565.6240, g_loss: -0.0435\n",
            "Epoch [725/1000], Step [1/8], d_loss: 8.9142, g_loss: -0.0009\n",
            "Epoch [725/1000], Step [2/8], d_loss: 8.8347, g_loss: -0.0002\n",
            "Epoch [725/1000], Step [3/8], d_loss: 59.3645, g_loss: -0.0000\n",
            "Epoch [725/1000], Step [4/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [725/1000], Step [5/8], d_loss: 3499.6033, g_loss: -0.0000\n",
            "Epoch [725/1000], Step [6/8], d_loss: 8.9452, g_loss: -0.0000\n",
            "Epoch [725/1000], Step [7/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [725/1000], Step [8/8], d_loss: 394.2788, g_loss: -0.0000\n",
            "Epoch [726/1000], Step [1/8], d_loss: 113.6547, g_loss: -0.0000\n",
            "Epoch [726/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [726/1000], Step [3/8], d_loss: 78.7872, g_loss: -0.0000\n",
            "Epoch [726/1000], Step [4/8], d_loss: 8.8053, g_loss: -0.0000\n",
            "Epoch [726/1000], Step [5/8], d_loss: 8.9961, g_loss: -0.0306\n",
            "Epoch [726/1000], Step [6/8], d_loss: 566.1916, g_loss: -0.0009\n",
            "Epoch [726/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0321\n",
            "Epoch [726/1000], Step [8/8], d_loss: 8.7751, g_loss: -0.0000\n",
            "Epoch [727/1000], Step [1/8], d_loss: 9.3397, g_loss: -0.0000\n",
            "Epoch [727/1000], Step [2/8], d_loss: 380.8638, g_loss: -0.0256\n",
            "Epoch [727/1000], Step [3/8], d_loss: 6648.5264, g_loss: -0.0600\n",
            "Epoch [727/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [727/1000], Step [5/8], d_loss: 4413.0957, g_loss: -0.0000\n",
            "Epoch [727/1000], Step [6/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [727/1000], Step [7/8], d_loss: 4723.5098, g_loss: -0.0000\n",
            "Epoch [727/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [728/1000], Step [1/8], d_loss: 8.6605, g_loss: -0.0000\n",
            "Epoch [728/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0192\n",
            "Epoch [728/1000], Step [3/8], d_loss: 545.1818, g_loss: -0.0000\n",
            "Epoch [728/1000], Step [4/8], d_loss: 8.9077, g_loss: -0.0000\n",
            "Epoch [728/1000], Step [5/8], d_loss: 10.6898, g_loss: -0.0000\n",
            "Epoch [728/1000], Step [6/8], d_loss: 8.9998, g_loss: -0.0468\n",
            "Epoch [728/1000], Step [7/8], d_loss: 8.4744, g_loss: -0.0000\n",
            "Epoch [728/1000], Step [8/8], d_loss: 8.5709, g_loss: -0.0000\n",
            "Epoch [729/1000], Step [1/8], d_loss: 8.9930, g_loss: -0.0000\n",
            "Epoch [729/1000], Step [2/8], d_loss: 1304.5884, g_loss: -0.0000\n",
            "Epoch [729/1000], Step [3/8], d_loss: 2974.8098, g_loss: -0.0003\n",
            "Epoch [729/1000], Step [4/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [729/1000], Step [5/8], d_loss: 11.6091, g_loss: -0.0000\n",
            "Epoch [729/1000], Step [6/8], d_loss: 2150.0859, g_loss: -0.0000\n",
            "Epoch [729/1000], Step [7/8], d_loss: 9.0309, g_loss: -0.0000\n",
            "Epoch [729/1000], Step [8/8], d_loss: 8.9094, g_loss: -0.0000\n",
            "Epoch [730/1000], Step [1/8], d_loss: 8.9987, g_loss: -0.0000\n",
            "Epoch [730/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [730/1000], Step [3/8], d_loss: 1653.3933, g_loss: -0.0000\n",
            "Epoch [730/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [730/1000], Step [5/8], d_loss: 6279.5366, g_loss: -0.0312\n",
            "Epoch [730/1000], Step [6/8], d_loss: 9.0027, g_loss: -0.0000\n",
            "Epoch [730/1000], Step [7/8], d_loss: 290.3759, g_loss: -0.0000\n",
            "Epoch [730/1000], Step [8/8], d_loss: 8.6079, g_loss: -0.0019\n",
            "Epoch [731/1000], Step [1/8], d_loss: 36.7967, g_loss: -0.0211\n",
            "Epoch [731/1000], Step [2/8], d_loss: 8.9855, g_loss: -0.0000\n",
            "Epoch [731/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [731/1000], Step [4/8], d_loss: 404.0232, g_loss: -0.0000\n",
            "Epoch [731/1000], Step [5/8], d_loss: 8.9648, g_loss: -0.0000\n",
            "Epoch [731/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [731/1000], Step [7/8], d_loss: 8.9938, g_loss: -0.0000\n",
            "Epoch [731/1000], Step [8/8], d_loss: 8.9809, g_loss: -0.0000\n",
            "Epoch [732/1000], Step [1/8], d_loss: 9.0222, g_loss: -0.0000\n",
            "Epoch [732/1000], Step [2/8], d_loss: 9.0031, g_loss: -0.0000\n",
            "Epoch [732/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [732/1000], Step [4/8], d_loss: 8.9028, g_loss: -0.0000\n",
            "Epoch [732/1000], Step [5/8], d_loss: 8.5707, g_loss: -0.0000\n",
            "Epoch [732/1000], Step [6/8], d_loss: 4705.3760, g_loss: -0.0000\n",
            "Epoch [732/1000], Step [7/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [732/1000], Step [8/8], d_loss: 15024.2539, g_loss: -0.0000\n",
            "Epoch [733/1000], Step [1/8], d_loss: 9.0188, g_loss: -0.0051\n",
            "Epoch [733/1000], Step [2/8], d_loss: 19.0698, g_loss: -0.0000\n",
            "Epoch [733/1000], Step [3/8], d_loss: 6969.5547, g_loss: -0.0000\n",
            "Epoch [733/1000], Step [4/8], d_loss: 7143.7490, g_loss: -0.0208\n",
            "Epoch [733/1000], Step [5/8], d_loss: 8.7455, g_loss: -0.0000\n",
            "Epoch [733/1000], Step [6/8], d_loss: 9.0236, g_loss: -0.0000\n",
            "Epoch [733/1000], Step [7/8], d_loss: 9.6332, g_loss: -0.0000\n",
            "Epoch [733/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [734/1000], Step [1/8], d_loss: 5400.3428, g_loss: -0.0001\n",
            "Epoch [734/1000], Step [2/8], d_loss: 10.0076, g_loss: -0.0001\n",
            "Epoch [734/1000], Step [3/8], d_loss: 2171.1111, g_loss: -0.0000\n",
            "Epoch [734/1000], Step [4/8], d_loss: 8.9479, g_loss: -0.0000\n",
            "Epoch [734/1000], Step [5/8], d_loss: 8.6946, g_loss: -0.0000\n",
            "Epoch [734/1000], Step [6/8], d_loss: 113.7990, g_loss: -0.0000\n",
            "Epoch [734/1000], Step [7/8], d_loss: 8.9525, g_loss: -0.0000\n",
            "Epoch [734/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [735/1000], Step [1/8], d_loss: 13.9837, g_loss: -0.0000\n",
            "Epoch [735/1000], Step [2/8], d_loss: 91.2307, g_loss: -0.0000\n",
            "Epoch [735/1000], Step [3/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [735/1000], Step [4/8], d_loss: 4061.6780, g_loss: -0.0000\n",
            "Epoch [735/1000], Step [5/8], d_loss: 1495.1455, g_loss: -0.0000\n",
            "Epoch [735/1000], Step [6/8], d_loss: 8.9070, g_loss: -0.0000\n",
            "Epoch [735/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [735/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [736/1000], Step [1/8], d_loss: 1050.1134, g_loss: -0.0000\n",
            "Epoch [736/1000], Step [2/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [736/1000], Step [3/8], d_loss: 8.7893, g_loss: -0.0144\n",
            "Epoch [736/1000], Step [4/8], d_loss: 8.9763, g_loss: -0.0000\n",
            "Epoch [736/1000], Step [5/8], d_loss: 8.9833, g_loss: -0.0000\n",
            "Epoch [736/1000], Step [6/8], d_loss: 6004.2729, g_loss: -0.0000\n",
            "Epoch [736/1000], Step [7/8], d_loss: 8.6861, g_loss: -0.0000\n",
            "Epoch [736/1000], Step [8/8], d_loss: 4251.3784, g_loss: -0.0431\n",
            "Epoch [737/1000], Step [1/8], d_loss: 9053.2109, g_loss: -0.0000\n",
            "Epoch [737/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [737/1000], Step [3/8], d_loss: 9.0310, g_loss: -0.0000\n",
            "Epoch [737/1000], Step [4/8], d_loss: 31.0720, g_loss: -0.0000\n",
            "Epoch [737/1000], Step [5/8], d_loss: 5520.9995, g_loss: -0.0000\n",
            "Epoch [737/1000], Step [6/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [737/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [737/1000], Step [8/8], d_loss: 478.7437, g_loss: -0.0000\n",
            "Epoch [738/1000], Step [1/8], d_loss: 8.9955, g_loss: -0.0000\n",
            "Epoch [738/1000], Step [2/8], d_loss: 8.9816, g_loss: -0.0000\n",
            "Epoch [738/1000], Step [3/8], d_loss: 1090.7666, g_loss: -0.0000\n",
            "Epoch [738/1000], Step [4/8], d_loss: 9.0213, g_loss: -0.0000\n",
            "Epoch [738/1000], Step [5/8], d_loss: 605.9001, g_loss: -0.0000\n",
            "Epoch [738/1000], Step [6/8], d_loss: 8.7199, g_loss: -0.0000\n",
            "Epoch [738/1000], Step [7/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [738/1000], Step [8/8], d_loss: 3616.8542, g_loss: -0.0000\n",
            "Epoch [739/1000], Step [1/8], d_loss: 8.9983, g_loss: -0.0000\n",
            "Epoch [739/1000], Step [2/8], d_loss: 9.0287, g_loss: -0.0005\n",
            "Epoch [739/1000], Step [3/8], d_loss: 8.9932, g_loss: -0.0312\n",
            "Epoch [739/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [739/1000], Step [5/8], d_loss: 9.0247, g_loss: -0.0328\n",
            "Epoch [739/1000], Step [6/8], d_loss: 25.8039, g_loss: -0.0013\n",
            "Epoch [739/1000], Step [7/8], d_loss: 9.8519, g_loss: -0.0000\n",
            "Epoch [739/1000], Step [8/8], d_loss: 8.9984, g_loss: -0.0000\n",
            "Epoch [740/1000], Step [1/8], d_loss: 13568.7275, g_loss: -0.0000\n",
            "Epoch [740/1000], Step [2/8], d_loss: 8.9993, g_loss: -0.0000\n",
            "Epoch [740/1000], Step [3/8], d_loss: 8.9629, g_loss: -0.0000\n",
            "Epoch [740/1000], Step [4/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [740/1000], Step [5/8], d_loss: 9.0625, g_loss: -0.0000\n",
            "Epoch [740/1000], Step [6/8], d_loss: 9.0279, g_loss: -0.0000\n",
            "Epoch [740/1000], Step [7/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [740/1000], Step [8/8], d_loss: 9.0866, g_loss: -0.0000\n",
            "Epoch [741/1000], Step [1/8], d_loss: 9.0309, g_loss: -0.0000\n",
            "Epoch [741/1000], Step [2/8], d_loss: 434.6287, g_loss: -0.0000\n",
            "Epoch [741/1000], Step [3/8], d_loss: 8.7776, g_loss: -0.0000\n",
            "Epoch [741/1000], Step [4/8], d_loss: 9.0289, g_loss: -0.0000\n",
            "Epoch [741/1000], Step [5/8], d_loss: 8.8507, g_loss: -0.0000\n",
            "Epoch [741/1000], Step [6/8], d_loss: 14.2749, g_loss: -0.0000\n",
            "Epoch [741/1000], Step [7/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [741/1000], Step [8/8], d_loss: 9.0434, g_loss: -0.0000\n",
            "Epoch [742/1000], Step [1/8], d_loss: 9.5505, g_loss: -0.0000\n",
            "Epoch [742/1000], Step [2/8], d_loss: 187.7444, g_loss: -0.0000\n",
            "Epoch [742/1000], Step [3/8], d_loss: 15322.1885, g_loss: -0.0001\n",
            "Epoch [742/1000], Step [4/8], d_loss: 663.8364, g_loss: -0.0625\n",
            "Epoch [742/1000], Step [5/8], d_loss: 91.1399, g_loss: -0.0317\n",
            "Epoch [742/1000], Step [6/8], d_loss: 461.5846, g_loss: -0.0000\n",
            "Epoch [742/1000], Step [7/8], d_loss: 9.0259, g_loss: -0.0000\n",
            "Epoch [742/1000], Step [8/8], d_loss: 8.9940, g_loss: -0.0158\n",
            "Epoch [743/1000], Step [1/8], d_loss: 312.5397, g_loss: -0.0000\n",
            "Epoch [743/1000], Step [2/8], d_loss: 8.7185, g_loss: -0.0000\n",
            "Epoch [743/1000], Step [3/8], d_loss: 9.0556, g_loss: -0.0313\n",
            "Epoch [743/1000], Step [4/8], d_loss: 9.0896, g_loss: -0.0000\n",
            "Epoch [743/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0313\n",
            "Epoch [743/1000], Step [6/8], d_loss: 8.7588, g_loss: -0.0000\n",
            "Epoch [743/1000], Step [7/8], d_loss: 20.0493, g_loss: -0.0003\n",
            "Epoch [743/1000], Step [8/8], d_loss: 167.9158, g_loss: -0.0000\n",
            "Epoch [744/1000], Step [1/8], d_loss: 8.7340, g_loss: -0.0000\n",
            "Epoch [744/1000], Step [2/8], d_loss: 9.0057, g_loss: -0.0000\n",
            "Epoch [744/1000], Step [3/8], d_loss: 8.9036, g_loss: -0.0000\n",
            "Epoch [744/1000], Step [4/8], d_loss: 553.3071, g_loss: -0.0000\n",
            "Epoch [744/1000], Step [5/8], d_loss: 15.0308, g_loss: -0.0313\n",
            "Epoch [744/1000], Step [6/8], d_loss: 63.3457, g_loss: -0.0000\n",
            "Epoch [744/1000], Step [7/8], d_loss: 9.0009, g_loss: -0.0312\n",
            "Epoch [744/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [745/1000], Step [1/8], d_loss: 9.0002, g_loss: -0.0000\n",
            "Epoch [745/1000], Step [2/8], d_loss: 1083.2142, g_loss: -0.0000\n",
            "Epoch [745/1000], Step [3/8], d_loss: 221.0521, g_loss: -0.0000\n",
            "Epoch [745/1000], Step [4/8], d_loss: 3619.6470, g_loss: -0.0000\n",
            "Epoch [745/1000], Step [5/8], d_loss: 8.9764, g_loss: -0.0000\n",
            "Epoch [745/1000], Step [6/8], d_loss: 9.0279, g_loss: -0.0000\n",
            "Epoch [745/1000], Step [7/8], d_loss: 14.1549, g_loss: -0.0000\n",
            "Epoch [745/1000], Step [8/8], d_loss: 8.6291, g_loss: -0.0000\n",
            "Epoch [746/1000], Step [1/8], d_loss: 9.0010, g_loss: -0.0000\n",
            "Epoch [746/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [746/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [746/1000], Step [4/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [746/1000], Step [5/8], d_loss: 8.9474, g_loss: -0.0002\n",
            "Epoch [746/1000], Step [6/8], d_loss: 8.6910, g_loss: -0.0000\n",
            "Epoch [746/1000], Step [7/8], d_loss: 8.9259, g_loss: -0.0000\n",
            "Epoch [746/1000], Step [8/8], d_loss: 263.2824, g_loss: -0.0004\n",
            "Epoch [747/1000], Step [1/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [747/1000], Step [2/8], d_loss: 153.6829, g_loss: -0.0186\n",
            "Epoch [747/1000], Step [3/8], d_loss: 8.9391, g_loss: -0.0069\n",
            "Epoch [747/1000], Step [4/8], d_loss: 50.7318, g_loss: -0.0000\n",
            "Epoch [747/1000], Step [5/8], d_loss: 8.9653, g_loss: -0.0003\n",
            "Epoch [747/1000], Step [6/8], d_loss: 6385.7446, g_loss: -0.0000\n",
            "Epoch [747/1000], Step [7/8], d_loss: 8.9716, g_loss: -0.0000\n",
            "Epoch [747/1000], Step [8/8], d_loss: 8.9194, g_loss: -0.0000\n",
            "Epoch [748/1000], Step [1/8], d_loss: 8653.8867, g_loss: -0.0000\n",
            "Epoch [748/1000], Step [2/8], d_loss: 3812.1924, g_loss: -0.0000\n",
            "Epoch [748/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [748/1000], Step [4/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [748/1000], Step [5/8], d_loss: 1801.7911, g_loss: -0.0000\n",
            "Epoch [748/1000], Step [6/8], d_loss: 9.0223, g_loss: -0.0000\n",
            "Epoch [748/1000], Step [7/8], d_loss: 8.7704, g_loss: -0.0000\n",
            "Epoch [748/1000], Step [8/8], d_loss: 287.6167, g_loss: -0.0193\n",
            "Epoch [749/1000], Step [1/8], d_loss: 287.0085, g_loss: -0.0000\n",
            "Epoch [749/1000], Step [2/8], d_loss: 8.8297, g_loss: -0.0000\n",
            "Epoch [749/1000], Step [3/8], d_loss: 8.9940, g_loss: -0.0000\n",
            "Epoch [749/1000], Step [4/8], d_loss: 9531.9014, g_loss: -0.0000\n",
            "Epoch [749/1000], Step [5/8], d_loss: 9.0049, g_loss: -0.0000\n",
            "Epoch [749/1000], Step [6/8], d_loss: 5646.6470, g_loss: -0.0000\n",
            "Epoch [749/1000], Step [7/8], d_loss: 9.0092, g_loss: -0.0000\n",
            "Epoch [749/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [750/1000], Step [1/8], d_loss: 6838.7046, g_loss: -0.0000\n",
            "Epoch [750/1000], Step [2/8], d_loss: 8.9432, g_loss: -0.0000\n",
            "Epoch [750/1000], Step [3/8], d_loss: 8.9419, g_loss: -0.0000\n",
            "Epoch [750/1000], Step [4/8], d_loss: 8.9933, g_loss: -0.0300\n",
            "Epoch [750/1000], Step [5/8], d_loss: 9.5786, g_loss: -0.0000\n",
            "Epoch [750/1000], Step [6/8], d_loss: 14387.2529, g_loss: -0.0000\n",
            "Epoch [750/1000], Step [7/8], d_loss: 8.9813, g_loss: -0.0312\n",
            "Epoch [750/1000], Step [8/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [751/1000], Step [1/8], d_loss: 8.9919, g_loss: -0.0000\n",
            "Epoch [751/1000], Step [2/8], d_loss: 31.8286, g_loss: -0.0000\n",
            "Epoch [751/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [751/1000], Step [4/8], d_loss: 8.8290, g_loss: -0.0000\n",
            "Epoch [751/1000], Step [5/8], d_loss: 46.4610, g_loss: -0.0000\n",
            "Epoch [751/1000], Step [6/8], d_loss: 8.5620, g_loss: -0.0000\n",
            "Epoch [751/1000], Step [7/8], d_loss: 1265.8828, g_loss: -0.0366\n",
            "Epoch [751/1000], Step [8/8], d_loss: 786.9504, g_loss: -0.0000\n",
            "Epoch [752/1000], Step [1/8], d_loss: 1784.2831, g_loss: -0.0000\n",
            "Epoch [752/1000], Step [2/8], d_loss: 9.0070, g_loss: -0.0745\n",
            "Epoch [752/1000], Step [3/8], d_loss: 8.7524, g_loss: -0.0000\n",
            "Epoch [752/1000], Step [4/8], d_loss: 15569.0020, g_loss: -0.0000\n",
            "Epoch [752/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [752/1000], Step [6/8], d_loss: 8.9507, g_loss: -0.0000\n",
            "Epoch [752/1000], Step [7/8], d_loss: 8.6553, g_loss: -0.0000\n",
            "Epoch [752/1000], Step [8/8], d_loss: 2819.7336, g_loss: -0.0000\n",
            "Epoch [753/1000], Step [1/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [753/1000], Step [2/8], d_loss: 375.4144, g_loss: -0.0000\n",
            "Epoch [753/1000], Step [3/8], d_loss: 78.0750, g_loss: -0.0000\n",
            "Epoch [753/1000], Step [4/8], d_loss: 8.7092, g_loss: -0.0000\n",
            "Epoch [753/1000], Step [5/8], d_loss: 8.9920, g_loss: -0.0000\n",
            "Epoch [753/1000], Step [6/8], d_loss: 8.8687, g_loss: -0.0000\n",
            "Epoch [753/1000], Step [7/8], d_loss: 8.8603, g_loss: -0.0313\n",
            "Epoch [753/1000], Step [8/8], d_loss: 41.0874, g_loss: -0.0434\n",
            "Epoch [754/1000], Step [1/8], d_loss: 8.8765, g_loss: -0.0000\n",
            "Epoch [754/1000], Step [2/8], d_loss: 12.8790, g_loss: -0.0000\n",
            "Epoch [754/1000], Step [3/8], d_loss: 8.7842, g_loss: -0.0000\n",
            "Epoch [754/1000], Step [4/8], d_loss: 8.9129, g_loss: -0.0000\n",
            "Epoch [754/1000], Step [5/8], d_loss: 50.1097, g_loss: -0.0000\n",
            "Epoch [754/1000], Step [6/8], d_loss: 8.9970, g_loss: -0.0000\n",
            "Epoch [754/1000], Step [7/8], d_loss: 8.8718, g_loss: -0.0000\n",
            "Epoch [754/1000], Step [8/8], d_loss: 12.0375, g_loss: -0.0000\n",
            "Epoch [755/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0034\n",
            "Epoch [755/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [755/1000], Step [3/8], d_loss: 65.5921, g_loss: -0.0000\n",
            "Epoch [755/1000], Step [4/8], d_loss: 224.0459, g_loss: -0.0621\n",
            "Epoch [755/1000], Step [5/8], d_loss: 9.0003, g_loss: -0.0005\n",
            "Epoch [755/1000], Step [6/8], d_loss: 10196.6973, g_loss: -0.0000\n",
            "Epoch [755/1000], Step [7/8], d_loss: 10.9825, g_loss: -0.0000\n",
            "Epoch [755/1000], Step [8/8], d_loss: 9.0017, g_loss: -0.0000\n",
            "Epoch [756/1000], Step [1/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [756/1000], Step [2/8], d_loss: 788.1590, g_loss: -0.0000\n",
            "Epoch [756/1000], Step [3/8], d_loss: 541.3187, g_loss: -0.0000\n",
            "Epoch [756/1000], Step [4/8], d_loss: 8592.7754, g_loss: -0.0312\n",
            "Epoch [756/1000], Step [5/8], d_loss: 8.9971, g_loss: -0.0000\n",
            "Epoch [756/1000], Step [6/8], d_loss: 51620.2891, g_loss: -0.0000\n",
            "Epoch [756/1000], Step [7/8], d_loss: 8.9981, g_loss: -0.0000\n",
            "Epoch [756/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0186\n",
            "Epoch [757/1000], Step [1/8], d_loss: 8.9842, g_loss: -0.0286\n",
            "Epoch [757/1000], Step [2/8], d_loss: 13505.0303, g_loss: -0.0000\n",
            "Epoch [757/1000], Step [3/8], d_loss: 8.9649, g_loss: -0.0313\n",
            "Epoch [757/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [757/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [757/1000], Step [6/8], d_loss: 8.9822, g_loss: -0.0000\n",
            "Epoch [757/1000], Step [7/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [757/1000], Step [8/8], d_loss: 8.7225, g_loss: -0.0000\n",
            "Epoch [758/1000], Step [1/8], d_loss: 11.1521, g_loss: -0.0000\n",
            "Epoch [758/1000], Step [2/8], d_loss: 8.6880, g_loss: -0.0000\n",
            "Epoch [758/1000], Step [3/8], d_loss: 8.9991, g_loss: -0.0004\n",
            "Epoch [758/1000], Step [4/8], d_loss: 2899.3069, g_loss: -0.0000\n",
            "Epoch [758/1000], Step [5/8], d_loss: 17.2453, g_loss: -0.0757\n",
            "Epoch [758/1000], Step [6/8], d_loss: 8.6145, g_loss: -0.0000\n",
            "Epoch [758/1000], Step [7/8], d_loss: 8.8675, g_loss: -0.0000\n",
            "Epoch [758/1000], Step [8/8], d_loss: 8.9787, g_loss: -0.0000\n",
            "Epoch [759/1000], Step [1/8], d_loss: 8.9991, g_loss: -0.0000\n",
            "Epoch [759/1000], Step [2/8], d_loss: 1489.4210, g_loss: -0.0625\n",
            "Epoch [759/1000], Step [3/8], d_loss: 44.9855, g_loss: -0.0102\n",
            "Epoch [759/1000], Step [4/8], d_loss: 8.9919, g_loss: -0.0000\n",
            "Epoch [759/1000], Step [5/8], d_loss: 2916.6345, g_loss: -0.0050\n",
            "Epoch [759/1000], Step [6/8], d_loss: 8.7427, g_loss: -0.0000\n",
            "Epoch [759/1000], Step [7/8], d_loss: 3064.3955, g_loss: -0.0000\n",
            "Epoch [759/1000], Step [8/8], d_loss: 269.1129, g_loss: -0.0000\n",
            "Epoch [760/1000], Step [1/8], d_loss: 8.7097, g_loss: -0.0000\n",
            "Epoch [760/1000], Step [2/8], d_loss: 9.0625, g_loss: -0.0000\n",
            "Epoch [760/1000], Step [3/8], d_loss: 17.0412, g_loss: -0.0000\n",
            "Epoch [760/1000], Step [4/8], d_loss: 10.1044, g_loss: -0.0002\n",
            "Epoch [760/1000], Step [5/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [760/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [760/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [760/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [761/1000], Step [1/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [761/1000], Step [2/8], d_loss: 9.3279, g_loss: -0.0000\n",
            "Epoch [761/1000], Step [3/8], d_loss: 8.7776, g_loss: -0.0000\n",
            "Epoch [761/1000], Step [4/8], d_loss: 8.9252, g_loss: -0.0000\n",
            "Epoch [761/1000], Step [5/8], d_loss: 9.0625, g_loss: -0.0000\n",
            "Epoch [761/1000], Step [6/8], d_loss: 8.9720, g_loss: -0.0000\n",
            "Epoch [761/1000], Step [7/8], d_loss: 9.0310, g_loss: -0.0000\n",
            "Epoch [761/1000], Step [8/8], d_loss: 5696.5591, g_loss: -0.0000\n",
            "Epoch [762/1000], Step [1/8], d_loss: 9.0110, g_loss: -0.0598\n",
            "Epoch [762/1000], Step [2/8], d_loss: 21525.2324, g_loss: -0.0000\n",
            "Epoch [762/1000], Step [3/8], d_loss: 18.8486, g_loss: -0.0000\n",
            "Epoch [762/1000], Step [4/8], d_loss: 589.1986, g_loss: -0.0000\n",
            "Epoch [762/1000], Step [5/8], d_loss: 16.7735, g_loss: -0.0000\n",
            "Epoch [762/1000], Step [6/8], d_loss: 5256.0215, g_loss: -0.0000\n",
            "Epoch [762/1000], Step [7/8], d_loss: 37.0480, g_loss: -0.0000\n",
            "Epoch [762/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [763/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [763/1000], Step [2/8], d_loss: 233.7472, g_loss: -0.0000\n",
            "Epoch [763/1000], Step [3/8], d_loss: 1094.3209, g_loss: -0.0000\n",
            "Epoch [763/1000], Step [4/8], d_loss: 4552.2402, g_loss: -0.0000\n",
            "Epoch [763/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [763/1000], Step [6/8], d_loss: 189.6057, g_loss: -0.0001\n",
            "Epoch [763/1000], Step [7/8], d_loss: 8.6882, g_loss: -0.0000\n",
            "Epoch [763/1000], Step [8/8], d_loss: 8.9848, g_loss: -0.0000\n",
            "Epoch [764/1000], Step [1/8], d_loss: 8.6885, g_loss: -0.0004\n",
            "Epoch [764/1000], Step [2/8], d_loss: 7836.1025, g_loss: -0.0000\n",
            "Epoch [764/1000], Step [3/8], d_loss: 1891.9259, g_loss: -0.0000\n",
            "Epoch [764/1000], Step [4/8], d_loss: 8.9667, g_loss: -0.0000\n",
            "Epoch [764/1000], Step [5/8], d_loss: 362.7456, g_loss: -0.0312\n",
            "Epoch [764/1000], Step [6/8], d_loss: 8.9798, g_loss: -0.0001\n",
            "Epoch [764/1000], Step [7/8], d_loss: 8.6976, g_loss: -0.0000\n",
            "Epoch [764/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [765/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [765/1000], Step [2/8], d_loss: 8.9995, g_loss: -0.0000\n",
            "Epoch [765/1000], Step [3/8], d_loss: 2276.0737, g_loss: -0.0000\n",
            "Epoch [765/1000], Step [4/8], d_loss: 29.9566, g_loss: -0.0000\n",
            "Epoch [765/1000], Step [5/8], d_loss: 1365.1082, g_loss: -0.0000\n",
            "Epoch [765/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0302\n",
            "Epoch [765/1000], Step [7/8], d_loss: 8.9970, g_loss: -0.0000\n",
            "Epoch [765/1000], Step [8/8], d_loss: 13.9720, g_loss: -0.0000\n",
            "Epoch [766/1000], Step [1/8], d_loss: 4510.8003, g_loss: -0.0000\n",
            "Epoch [766/1000], Step [2/8], d_loss: 93.9659, g_loss: -0.0000\n",
            "Epoch [766/1000], Step [3/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [766/1000], Step [4/8], d_loss: 9.0093, g_loss: -0.0000\n",
            "Epoch [766/1000], Step [5/8], d_loss: 8.9823, g_loss: -0.0000\n",
            "Epoch [766/1000], Step [6/8], d_loss: 4008.4390, g_loss: -0.0000\n",
            "Epoch [766/1000], Step [7/8], d_loss: 8.9992, g_loss: -0.0310\n",
            "Epoch [766/1000], Step [8/8], d_loss: 9.0002, g_loss: -0.0000\n",
            "Epoch [767/1000], Step [1/8], d_loss: 25.7559, g_loss: -0.0000\n",
            "Epoch [767/1000], Step [2/8], d_loss: 9563.3574, g_loss: -0.0000\n",
            "Epoch [767/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [767/1000], Step [4/8], d_loss: 8.8299, g_loss: -0.0000\n",
            "Epoch [767/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [767/1000], Step [6/8], d_loss: 254.4666, g_loss: -0.0000\n",
            "Epoch [767/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [767/1000], Step [8/8], d_loss: 8.9874, g_loss: -0.0000\n",
            "Epoch [768/1000], Step [1/8], d_loss: 428.0592, g_loss: -0.0000\n",
            "Epoch [768/1000], Step [2/8], d_loss: 8.6875, g_loss: -0.0000\n",
            "Epoch [768/1000], Step [3/8], d_loss: 8.9987, g_loss: -0.0000\n",
            "Epoch [768/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0287\n",
            "Epoch [768/1000], Step [5/8], d_loss: 8.9980, g_loss: -0.0313\n",
            "Epoch [768/1000], Step [6/8], d_loss: 5957.8335, g_loss: -0.0000\n",
            "Epoch [768/1000], Step [7/8], d_loss: 8.9278, g_loss: -0.0000\n",
            "Epoch [768/1000], Step [8/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [769/1000], Step [1/8], d_loss: 248.4414, g_loss: -0.0000\n",
            "Epoch [769/1000], Step [2/8], d_loss: 8.9612, g_loss: -0.0000\n",
            "Epoch [769/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [769/1000], Step [4/8], d_loss: 8.7284, g_loss: -0.0000\n",
            "Epoch [769/1000], Step [5/8], d_loss: 15.3247, g_loss: -0.0000\n",
            "Epoch [769/1000], Step [6/8], d_loss: 174.3116, g_loss: -0.0000\n",
            "Epoch [769/1000], Step [7/8], d_loss: 8.7808, g_loss: -0.0000\n",
            "Epoch [769/1000], Step [8/8], d_loss: 8.5891, g_loss: -0.0000\n",
            "Epoch [770/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [770/1000], Step [2/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [770/1000], Step [3/8], d_loss: 8.9999, g_loss: -0.0312\n",
            "Epoch [770/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [770/1000], Step [5/8], d_loss: 5510.9316, g_loss: -0.0000\n",
            "Epoch [770/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [770/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [770/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [771/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [771/1000], Step [2/8], d_loss: 1618.4968, g_loss: -0.0000\n",
            "Epoch [771/1000], Step [3/8], d_loss: 4611.7109, g_loss: -0.0000\n",
            "Epoch [771/1000], Step [4/8], d_loss: 860.6757, g_loss: -0.0000\n",
            "Epoch [771/1000], Step [5/8], d_loss: 25.1111, g_loss: -0.0000\n",
            "Epoch [771/1000], Step [6/8], d_loss: 552.6376, g_loss: -0.0000\n",
            "Epoch [771/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [771/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [772/1000], Step [1/8], d_loss: 9.4970, g_loss: -0.0000\n",
            "Epoch [772/1000], Step [2/8], d_loss: 8.9738, g_loss: -0.0000\n",
            "Epoch [772/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [772/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [772/1000], Step [5/8], d_loss: 13.5936, g_loss: -0.0000\n",
            "Epoch [772/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0001\n",
            "Epoch [772/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [772/1000], Step [8/8], d_loss: 8.9965, g_loss: -0.0000\n",
            "Epoch [773/1000], Step [1/8], d_loss: 17.4726, g_loss: -0.0000\n",
            "Epoch [773/1000], Step [2/8], d_loss: 8.9950, g_loss: -0.0000\n",
            "Epoch [773/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [773/1000], Step [4/8], d_loss: 34.3285, g_loss: -0.0000\n",
            "Epoch [773/1000], Step [5/8], d_loss: 8.7480, g_loss: -0.0000\n",
            "Epoch [773/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [773/1000], Step [7/8], d_loss: 8.9969, g_loss: -0.0000\n",
            "Epoch [773/1000], Step [8/8], d_loss: 8.8106, g_loss: -0.0000\n",
            "Epoch [774/1000], Step [1/8], d_loss: 1180.5128, g_loss: -0.0000\n",
            "Epoch [774/1000], Step [2/8], d_loss: 246.0690, g_loss: -0.0000\n",
            "Epoch [774/1000], Step [3/8], d_loss: 8.9940, g_loss: -0.0000\n",
            "Epoch [774/1000], Step [4/8], d_loss: 2087.5679, g_loss: -0.0000\n",
            "Epoch [774/1000], Step [5/8], d_loss: 8.9461, g_loss: -0.0000\n",
            "Epoch [774/1000], Step [6/8], d_loss: 8.9959, g_loss: -0.0000\n",
            "Epoch [774/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [774/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [775/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [775/1000], Step [2/8], d_loss: 8.9983, g_loss: -0.0000\n",
            "Epoch [775/1000], Step [3/8], d_loss: 4574.6831, g_loss: -0.0000\n",
            "Epoch [775/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [775/1000], Step [5/8], d_loss: 8.8393, g_loss: -0.0000\n",
            "Epoch [775/1000], Step [6/8], d_loss: 8.9452, g_loss: -0.0000\n",
            "Epoch [775/1000], Step [7/8], d_loss: 23445.0254, g_loss: -0.0000\n",
            "Epoch [775/1000], Step [8/8], d_loss: 8.9779, g_loss: -0.0000\n",
            "Epoch [776/1000], Step [1/8], d_loss: 8.9775, g_loss: -0.0000\n",
            "Epoch [776/1000], Step [2/8], d_loss: 8.8920, g_loss: -0.0000\n",
            "Epoch [776/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0312\n",
            "Epoch [776/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [776/1000], Step [5/8], d_loss: 8.8014, g_loss: -0.0312\n",
            "Epoch [776/1000], Step [6/8], d_loss: 43.3639, g_loss: -0.0000\n",
            "Epoch [776/1000], Step [7/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [776/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [777/1000], Step [1/8], d_loss: 8.9894, g_loss: -0.0000\n",
            "Epoch [777/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [777/1000], Step [3/8], d_loss: 8.7604, g_loss: -0.0000\n",
            "Epoch [777/1000], Step [4/8], d_loss: 2804.5796, g_loss: -0.0000\n",
            "Epoch [777/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0312\n",
            "Epoch [777/1000], Step [6/8], d_loss: 12.4954, g_loss: -0.0000\n",
            "Epoch [777/1000], Step [7/8], d_loss: 388.6355, g_loss: -0.0000\n",
            "Epoch [777/1000], Step [8/8], d_loss: 8.6391, g_loss: -0.0000\n",
            "Epoch [778/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [778/1000], Step [2/8], d_loss: 1633.8005, g_loss: -0.0000\n",
            "Epoch [778/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [778/1000], Step [4/8], d_loss: 8423.1680, g_loss: -0.0000\n",
            "Epoch [778/1000], Step [5/8], d_loss: 15766.8574, g_loss: -0.0000\n",
            "Epoch [778/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [778/1000], Step [7/8], d_loss: 7958.5596, g_loss: -0.0000\n",
            "Epoch [778/1000], Step [8/8], d_loss: 8.9954, g_loss: -0.0000\n",
            "Epoch [779/1000], Step [1/8], d_loss: 1749.5442, g_loss: -0.0000\n",
            "Epoch [779/1000], Step [2/8], d_loss: 35639.5352, g_loss: -0.0000\n",
            "Epoch [779/1000], Step [3/8], d_loss: 1196.3472, g_loss: -0.0000\n",
            "Epoch [779/1000], Step [4/8], d_loss: 8.9771, g_loss: -0.0000\n",
            "Epoch [779/1000], Step [5/8], d_loss: 8.9864, g_loss: -0.0000\n",
            "Epoch [779/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [779/1000], Step [7/8], d_loss: 7578.8027, g_loss: -0.0000\n",
            "Epoch [779/1000], Step [8/8], d_loss: 8.9958, g_loss: -0.0000\n",
            "Epoch [780/1000], Step [1/8], d_loss: 68.4430, g_loss: -0.0000\n",
            "Epoch [780/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [780/1000], Step [3/8], d_loss: 13.9469, g_loss: -0.0000\n",
            "Epoch [780/1000], Step [4/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [780/1000], Step [5/8], d_loss: 8.9638, g_loss: -0.0000\n",
            "Epoch [780/1000], Step [6/8], d_loss: 534.8722, g_loss: -0.0000\n",
            "Epoch [780/1000], Step [7/8], d_loss: 4222.1846, g_loss: -0.0000\n",
            "Epoch [780/1000], Step [8/8], d_loss: 8.6506, g_loss: -0.0000\n",
            "Epoch [781/1000], Step [1/8], d_loss: 109.7711, g_loss: -0.0000\n",
            "Epoch [781/1000], Step [2/8], d_loss: 43.5523, g_loss: -0.0000\n",
            "Epoch [781/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [781/1000], Step [4/8], d_loss: 3347.9976, g_loss: -0.0000\n",
            "Epoch [781/1000], Step [5/8], d_loss: 8.8711, g_loss: -0.0000\n",
            "Epoch [781/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [781/1000], Step [7/8], d_loss: 8.9653, g_loss: -0.0000\n",
            "Epoch [781/1000], Step [8/8], d_loss: 393.5992, g_loss: -0.0000\n",
            "Epoch [782/1000], Step [1/8], d_loss: 11.2085, g_loss: -0.0000\n",
            "Epoch [782/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [782/1000], Step [3/8], d_loss: 2691.6289, g_loss: -0.0000\n",
            "Epoch [782/1000], Step [4/8], d_loss: 8.9613, g_loss: -0.0000\n",
            "Epoch [782/1000], Step [5/8], d_loss: 8.9948, g_loss: -0.0000\n",
            "Epoch [782/1000], Step [6/8], d_loss: 77.5060, g_loss: -0.0000\n",
            "Epoch [782/1000], Step [7/8], d_loss: 8.7905, g_loss: -0.0000\n",
            "Epoch [782/1000], Step [8/8], d_loss: 8.6755, g_loss: -0.0000\n",
            "Epoch [783/1000], Step [1/8], d_loss: 5391.7446, g_loss: -0.0000\n",
            "Epoch [783/1000], Step [2/8], d_loss: 349.1031, g_loss: -0.0000\n",
            "Epoch [783/1000], Step [3/8], d_loss: 4755.3164, g_loss: -0.0000\n",
            "Epoch [783/1000], Step [4/8], d_loss: 9.8727, g_loss: -0.0000\n",
            "Epoch [783/1000], Step [5/8], d_loss: 10113.9180, g_loss: -0.0000\n",
            "Epoch [783/1000], Step [6/8], d_loss: 10420.5420, g_loss: -0.0000\n",
            "Epoch [783/1000], Step [7/8], d_loss: 4352.0415, g_loss: -0.0000\n",
            "Epoch [783/1000], Step [8/8], d_loss: 8.8777, g_loss: -0.0000\n",
            "Epoch [784/1000], Step [1/8], d_loss: 8.6912, g_loss: -0.0000\n",
            "Epoch [784/1000], Step [2/8], d_loss: 8.9647, g_loss: -0.0000\n",
            "Epoch [784/1000], Step [3/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [784/1000], Step [4/8], d_loss: 8.9993, g_loss: -0.0000\n",
            "Epoch [784/1000], Step [5/8], d_loss: 195.1750, g_loss: -0.0000\n",
            "Epoch [784/1000], Step [6/8], d_loss: 630.6245, g_loss: -0.0000\n",
            "Epoch [784/1000], Step [7/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [784/1000], Step [8/8], d_loss: 3496.3818, g_loss: -0.0000\n",
            "Epoch [785/1000], Step [1/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [785/1000], Step [2/8], d_loss: 8.9704, g_loss: -0.0000\n",
            "Epoch [785/1000], Step [3/8], d_loss: 5852.7017, g_loss: -0.0000\n",
            "Epoch [785/1000], Step [4/8], d_loss: 8.9970, g_loss: -0.0000\n",
            "Epoch [785/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [785/1000], Step [6/8], d_loss: 8.9902, g_loss: -0.0000\n",
            "Epoch [785/1000], Step [7/8], d_loss: 8.9890, g_loss: -0.0000\n",
            "Epoch [785/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [786/1000], Step [1/8], d_loss: 8.8000, g_loss: -0.0000\n",
            "Epoch [786/1000], Step [2/8], d_loss: 8.9965, g_loss: -0.0000\n",
            "Epoch [786/1000], Step [3/8], d_loss: 114.4895, g_loss: -0.0000\n",
            "Epoch [786/1000], Step [4/8], d_loss: 8.9934, g_loss: -0.0000\n",
            "Epoch [786/1000], Step [5/8], d_loss: 869.4198, g_loss: -0.0000\n",
            "Epoch [786/1000], Step [6/8], d_loss: 5614.5508, g_loss: -0.0000\n",
            "Epoch [786/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [786/1000], Step [8/8], d_loss: 12.6077, g_loss: -0.0000\n",
            "Epoch [787/1000], Step [1/8], d_loss: 141.3397, g_loss: -0.0000\n",
            "Epoch [787/1000], Step [2/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [787/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [787/1000], Step [4/8], d_loss: 438.4074, g_loss: -0.0000\n",
            "Epoch [787/1000], Step [5/8], d_loss: 31.0521, g_loss: -0.0000\n",
            "Epoch [787/1000], Step [6/8], d_loss: 8.9826, g_loss: -0.0000\n",
            "Epoch [787/1000], Step [7/8], d_loss: 136.7765, g_loss: -0.0000\n",
            "Epoch [787/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [788/1000], Step [1/8], d_loss: 357.4908, g_loss: -0.0000\n",
            "Epoch [788/1000], Step [2/8], d_loss: 8.9973, g_loss: -0.0000\n",
            "Epoch [788/1000], Step [3/8], d_loss: 3627.8865, g_loss: -0.0000\n",
            "Epoch [788/1000], Step [4/8], d_loss: 2354.5293, g_loss: -0.0000\n",
            "Epoch [788/1000], Step [5/8], d_loss: 4053.5771, g_loss: -0.0000\n",
            "Epoch [788/1000], Step [6/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [788/1000], Step [7/8], d_loss: 8.9721, g_loss: -0.0000\n",
            "Epoch [788/1000], Step [8/8], d_loss: 8.5452, g_loss: -0.0000\n",
            "Epoch [789/1000], Step [1/8], d_loss: 8.5089, g_loss: -0.0000\n",
            "Epoch [789/1000], Step [2/8], d_loss: 3189.8376, g_loss: -0.0000\n",
            "Epoch [789/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [789/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [789/1000], Step [5/8], d_loss: 430.0649, g_loss: -0.0000\n",
            "Epoch [789/1000], Step [6/8], d_loss: 8.6931, g_loss: -0.0000\n",
            "Epoch [789/1000], Step [7/8], d_loss: 8.8199, g_loss: -0.0000\n",
            "Epoch [789/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [790/1000], Step [1/8], d_loss: 8.9910, g_loss: -0.0000\n",
            "Epoch [790/1000], Step [2/8], d_loss: 72.0503, g_loss: -0.0000\n",
            "Epoch [790/1000], Step [3/8], d_loss: 13.5692, g_loss: -0.0000\n",
            "Epoch [790/1000], Step [4/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [790/1000], Step [5/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [790/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [790/1000], Step [7/8], d_loss: 1095.9600, g_loss: -0.0000\n",
            "Epoch [790/1000], Step [8/8], d_loss: 551.9104, g_loss: -0.0000\n",
            "Epoch [791/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [791/1000], Step [2/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [791/1000], Step [3/8], d_loss: 8.9294, g_loss: -0.0000\n",
            "Epoch [791/1000], Step [4/8], d_loss: 4655.3794, g_loss: -0.0000\n",
            "Epoch [791/1000], Step [5/8], d_loss: 8.9991, g_loss: -0.0000\n",
            "Epoch [791/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [791/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [791/1000], Step [8/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [792/1000], Step [1/8], d_loss: 9.6397, g_loss: -0.0000\n",
            "Epoch [792/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [792/1000], Step [3/8], d_loss: 8.9800, g_loss: -0.0000\n",
            "Epoch [792/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [792/1000], Step [5/8], d_loss: 11724.8486, g_loss: -0.0000\n",
            "Epoch [792/1000], Step [6/8], d_loss: 8.9981, g_loss: -0.0000\n",
            "Epoch [792/1000], Step [7/8], d_loss: 9.0290, g_loss: -0.0000\n",
            "Epoch [792/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [793/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [793/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [793/1000], Step [3/8], d_loss: 22203.8340, g_loss: -0.0000\n",
            "Epoch [793/1000], Step [4/8], d_loss: 8.8677, g_loss: -0.0000\n",
            "Epoch [793/1000], Step [5/8], d_loss: 1519.1625, g_loss: -0.0000\n",
            "Epoch [793/1000], Step [6/8], d_loss: 2371.0098, g_loss: -0.0000\n",
            "Epoch [793/1000], Step [7/8], d_loss: 345.1722, g_loss: -0.0000\n",
            "Epoch [793/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [794/1000], Step [1/8], d_loss: 8.9873, g_loss: -0.0000\n",
            "Epoch [794/1000], Step [2/8], d_loss: 8.9259, g_loss: -0.0000\n",
            "Epoch [794/1000], Step [3/8], d_loss: 39612.2344, g_loss: -0.0000\n",
            "Epoch [794/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [794/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [794/1000], Step [6/8], d_loss: 17344.5449, g_loss: -0.0000\n",
            "Epoch [794/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [794/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [795/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [795/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [795/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [795/1000], Step [4/8], d_loss: 12.7896, g_loss: -0.0000\n",
            "Epoch [795/1000], Step [5/8], d_loss: 8.9867, g_loss: -0.0000\n",
            "Epoch [795/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [795/1000], Step [7/8], d_loss: 8.9670, g_loss: -0.0000\n",
            "Epoch [795/1000], Step [8/8], d_loss: 12.7509, g_loss: -0.0000\n",
            "Epoch [796/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [796/1000], Step [2/8], d_loss: 318.1897, g_loss: -0.0000\n",
            "Epoch [796/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [796/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [796/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [796/1000], Step [6/8], d_loss: 8.8412, g_loss: -0.0000\n",
            "Epoch [796/1000], Step [7/8], d_loss: 8.9993, g_loss: -0.0000\n",
            "Epoch [796/1000], Step [8/8], d_loss: 8.9108, g_loss: -0.0000\n",
            "Epoch [797/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [797/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [797/1000], Step [3/8], d_loss: 14790.0781, g_loss: -0.0000\n",
            "Epoch [797/1000], Step [4/8], d_loss: 8.9993, g_loss: -0.0000\n",
            "Epoch [797/1000], Step [5/8], d_loss: 211.2213, g_loss: -0.0000\n",
            "Epoch [797/1000], Step [6/8], d_loss: 2322.7351, g_loss: -0.0000\n",
            "Epoch [797/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [797/1000], Step [8/8], d_loss: 34.7921, g_loss: -0.0000\n",
            "Epoch [798/1000], Step [1/8], d_loss: 4271.9170, g_loss: -0.0000\n",
            "Epoch [798/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [798/1000], Step [3/8], d_loss: 187.7826, g_loss: -0.0000\n",
            "Epoch [798/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [798/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [798/1000], Step [6/8], d_loss: 291.3775, g_loss: -0.0000\n",
            "Epoch [798/1000], Step [7/8], d_loss: 8.9809, g_loss: -0.0000\n",
            "Epoch [798/1000], Step [8/8], d_loss: 1460.0692, g_loss: -0.0000\n",
            "Epoch [799/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [799/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [799/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [799/1000], Step [4/8], d_loss: 8.6906, g_loss: -0.0000\n",
            "Epoch [799/1000], Step [5/8], d_loss: 1914.4917, g_loss: -0.0000\n",
            "Epoch [799/1000], Step [6/8], d_loss: 10.5975, g_loss: -0.0000\n",
            "Epoch [799/1000], Step [7/8], d_loss: 5322.5381, g_loss: -0.0000\n",
            "Epoch [799/1000], Step [8/8], d_loss: 36422.2266, g_loss: -0.0000\n",
            "Epoch [800/1000], Step [1/8], d_loss: 12.0167, g_loss: -0.0000\n",
            "Epoch [800/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [800/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [800/1000], Step [4/8], d_loss: 8.5115, g_loss: -0.0000\n",
            "Epoch [800/1000], Step [5/8], d_loss: 8.7402, g_loss: -0.0000\n",
            "Epoch [800/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [800/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [800/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [801/1000], Step [1/8], d_loss: 17009.6094, g_loss: -0.0000\n",
            "Epoch [801/1000], Step [2/8], d_loss: 2383.5769, g_loss: -0.0000\n",
            "Epoch [801/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [801/1000], Step [4/8], d_loss: 10.2306, g_loss: -0.0000\n",
            "Epoch [801/1000], Step [5/8], d_loss: 8.9802, g_loss: -0.0000\n",
            "Epoch [801/1000], Step [6/8], d_loss: 456.2882, g_loss: -0.0000\n",
            "Epoch [801/1000], Step [7/8], d_loss: 9.1286, g_loss: -0.0000\n",
            "Epoch [801/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [802/1000], Step [1/8], d_loss: 588.2145, g_loss: -0.0000\n",
            "Epoch [802/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [802/1000], Step [3/8], d_loss: 8.9749, g_loss: -0.0000\n",
            "Epoch [802/1000], Step [4/8], d_loss: 8.9920, g_loss: -0.0000\n",
            "Epoch [802/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [802/1000], Step [6/8], d_loss: 8.6890, g_loss: -0.0000\n",
            "Epoch [802/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [802/1000], Step [8/8], d_loss: 16.3816, g_loss: -0.0000\n",
            "Epoch [803/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [803/1000], Step [2/8], d_loss: 54.9568, g_loss: -0.0000\n",
            "Epoch [803/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [803/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [803/1000], Step [5/8], d_loss: 8.7729, g_loss: -0.0000\n",
            "Epoch [803/1000], Step [6/8], d_loss: 8.9899, g_loss: -0.0000\n",
            "Epoch [803/1000], Step [7/8], d_loss: 24.0568, g_loss: -0.0000\n",
            "Epoch [803/1000], Step [8/8], d_loss: 8.9974, g_loss: -0.0000\n",
            "Epoch [804/1000], Step [1/8], d_loss: 8.8058, g_loss: -0.0000\n",
            "Epoch [804/1000], Step [2/8], d_loss: 8.9949, g_loss: -0.0000\n",
            "Epoch [804/1000], Step [3/8], d_loss: 10.7702, g_loss: -0.0000\n",
            "Epoch [804/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [804/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [804/1000], Step [6/8], d_loss: 380.9836, g_loss: -0.0000\n",
            "Epoch [804/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [804/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [805/1000], Step [1/8], d_loss: 8.9556, g_loss: -0.0000\n",
            "Epoch [805/1000], Step [2/8], d_loss: 8.7960, g_loss: -0.0000\n",
            "Epoch [805/1000], Step [3/8], d_loss: 8.6874, g_loss: -0.0000\n",
            "Epoch [805/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [805/1000], Step [5/8], d_loss: 8.9993, g_loss: -0.0000\n",
            "Epoch [805/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [805/1000], Step [7/8], d_loss: 8.7758, g_loss: -0.0000\n",
            "Epoch [805/1000], Step [8/8], d_loss: 8.9977, g_loss: -0.0000\n",
            "Epoch [806/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0148\n",
            "Epoch [806/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [806/1000], Step [3/8], d_loss: 2447.4438, g_loss: -0.0000\n",
            "Epoch [806/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [806/1000], Step [5/8], d_loss: 115.2515, g_loss: -0.0000\n",
            "Epoch [806/1000], Step [6/8], d_loss: 8.8946, g_loss: -0.0000\n",
            "Epoch [806/1000], Step [7/8], d_loss: 1473.9153, g_loss: -0.0000\n",
            "Epoch [806/1000], Step [8/8], d_loss: 9.0433, g_loss: -0.0000\n",
            "Epoch [807/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [807/1000], Step [2/8], d_loss: 1396.9027, g_loss: -0.0000\n",
            "Epoch [807/1000], Step [3/8], d_loss: 3193.3877, g_loss: -0.0000\n",
            "Epoch [807/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [807/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [807/1000], Step [6/8], d_loss: 796.1945, g_loss: -0.0000\n",
            "Epoch [807/1000], Step [7/8], d_loss: 53.5582, g_loss: -0.0000\n",
            "Epoch [807/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [808/1000], Step [1/8], d_loss: 8.9883, g_loss: -0.0000\n",
            "Epoch [808/1000], Step [2/8], d_loss: 16.2737, g_loss: -0.0000\n",
            "Epoch [808/1000], Step [3/8], d_loss: 2357.7122, g_loss: -0.0000\n",
            "Epoch [808/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [808/1000], Step [5/8], d_loss: 8.9393, g_loss: -0.0000\n",
            "Epoch [808/1000], Step [6/8], d_loss: 15.1339, g_loss: -0.0000\n",
            "Epoch [808/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [808/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [809/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [809/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [809/1000], Step [3/8], d_loss: 8.8893, g_loss: -0.0312\n",
            "Epoch [809/1000], Step [4/8], d_loss: 8.9974, g_loss: -0.0000\n",
            "Epoch [809/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [809/1000], Step [6/8], d_loss: 11.9450, g_loss: -0.0001\n",
            "Epoch [809/1000], Step [7/8], d_loss: 2172.0044, g_loss: -0.0000\n",
            "Epoch [809/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [810/1000], Step [1/8], d_loss: 9719.2676, g_loss: -0.0000\n",
            "Epoch [810/1000], Step [2/8], d_loss: 9.8221, g_loss: -0.0000\n",
            "Epoch [810/1000], Step [3/8], d_loss: 8.6927, g_loss: -0.0000\n",
            "Epoch [810/1000], Step [4/8], d_loss: 5984.0566, g_loss: -0.0000\n",
            "Epoch [810/1000], Step [5/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [810/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [810/1000], Step [7/8], d_loss: 272.4056, g_loss: -0.0000\n",
            "Epoch [810/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [811/1000], Step [1/8], d_loss: 9.0311, g_loss: -0.0000\n",
            "Epoch [811/1000], Step [2/8], d_loss: 672.6139, g_loss: -0.0312\n",
            "Epoch [811/1000], Step [3/8], d_loss: 8.9947, g_loss: -0.0000\n",
            "Epoch [811/1000], Step [4/8], d_loss: 6853.9756, g_loss: -0.0000\n",
            "Epoch [811/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0312\n",
            "Epoch [811/1000], Step [6/8], d_loss: 197.1593, g_loss: -0.0000\n",
            "Epoch [811/1000], Step [7/8], d_loss: 13.3288, g_loss: -0.0000\n",
            "Epoch [811/1000], Step [8/8], d_loss: 10.1546, g_loss: -0.0000\n",
            "Epoch [812/1000], Step [1/8], d_loss: 1546.8733, g_loss: -0.0000\n",
            "Epoch [812/1000], Step [2/8], d_loss: 365.7488, g_loss: -0.0000\n",
            "Epoch [812/1000], Step [3/8], d_loss: 19182.3320, g_loss: -0.0000\n",
            "Epoch [812/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [812/1000], Step [5/8], d_loss: 8.9986, g_loss: -0.0000\n",
            "Epoch [812/1000], Step [6/8], d_loss: 3185.0779, g_loss: -0.0000\n",
            "Epoch [812/1000], Step [7/8], d_loss: 77.9720, g_loss: -0.0000\n",
            "Epoch [812/1000], Step [8/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [813/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [813/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [813/1000], Step [3/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [813/1000], Step [4/8], d_loss: 158.6766, g_loss: -0.0000\n",
            "Epoch [813/1000], Step [5/8], d_loss: 3953.8970, g_loss: -0.0000\n",
            "Epoch [813/1000], Step [6/8], d_loss: 8.9982, g_loss: -0.0000\n",
            "Epoch [813/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [813/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [814/1000], Step [1/8], d_loss: 9.0288, g_loss: -0.0000\n",
            "Epoch [814/1000], Step [2/8], d_loss: 9.0312, g_loss: -0.0312\n",
            "Epoch [814/1000], Step [3/8], d_loss: 5135.6406, g_loss: -0.0000\n",
            "Epoch [814/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [814/1000], Step [5/8], d_loss: 976.7127, g_loss: -0.0000\n",
            "Epoch [814/1000], Step [6/8], d_loss: 8.9953, g_loss: -0.0000\n",
            "Epoch [814/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [814/1000], Step [8/8], d_loss: 10114.6504, g_loss: -0.0000\n",
            "Epoch [815/1000], Step [1/8], d_loss: 106.3086, g_loss: -0.0000\n",
            "Epoch [815/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [815/1000], Step [3/8], d_loss: 8.9986, g_loss: -0.0000\n",
            "Epoch [815/1000], Step [4/8], d_loss: 3540.6489, g_loss: -0.0000\n",
            "Epoch [815/1000], Step [5/8], d_loss: 8473.6768, g_loss: -0.0000\n",
            "Epoch [815/1000], Step [6/8], d_loss: 8.7281, g_loss: -0.0308\n",
            "Epoch [815/1000], Step [7/8], d_loss: 6150.9233, g_loss: -0.0000\n",
            "Epoch [815/1000], Step [8/8], d_loss: 8.9898, g_loss: -0.0000\n",
            "Epoch [816/1000], Step [1/8], d_loss: 8.9924, g_loss: -0.0000\n",
            "Epoch [816/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [816/1000], Step [3/8], d_loss: 8.9991, g_loss: -0.0000\n",
            "Epoch [816/1000], Step [4/8], d_loss: 9.5624, g_loss: -0.0000\n",
            "Epoch [816/1000], Step [5/8], d_loss: 8.8411, g_loss: -0.0000\n",
            "Epoch [816/1000], Step [6/8], d_loss: 2322.6418, g_loss: -0.0000\n",
            "Epoch [816/1000], Step [7/8], d_loss: 8.9379, g_loss: -0.0000\n",
            "Epoch [816/1000], Step [8/8], d_loss: 10.9055, g_loss: -0.0000\n",
            "Epoch [817/1000], Step [1/8], d_loss: 684.1167, g_loss: -0.0000\n",
            "Epoch [817/1000], Step [2/8], d_loss: 9.2767, g_loss: -0.0000\n",
            "Epoch [817/1000], Step [3/8], d_loss: 20.6100, g_loss: -0.0000\n",
            "Epoch [817/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [817/1000], Step [5/8], d_loss: 8.9995, g_loss: -0.0000\n",
            "Epoch [817/1000], Step [6/8], d_loss: 8.9993, g_loss: -0.0000\n",
            "Epoch [817/1000], Step [7/8], d_loss: 12287.3066, g_loss: -0.0000\n",
            "Epoch [817/1000], Step [8/8], d_loss: 9.0145, g_loss: -0.0000\n",
            "Epoch [818/1000], Step [1/8], d_loss: 8.7230, g_loss: -0.0000\n",
            "Epoch [818/1000], Step [2/8], d_loss: 9.0029, g_loss: -0.0000\n",
            "Epoch [818/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [818/1000], Step [4/8], d_loss: 520.0284, g_loss: -0.0000\n",
            "Epoch [818/1000], Step [5/8], d_loss: 1375.4143, g_loss: -0.0000\n",
            "Epoch [818/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [818/1000], Step [7/8], d_loss: 8.9993, g_loss: -0.0000\n",
            "Epoch [818/1000], Step [8/8], d_loss: 8.9314, g_loss: -0.0000\n",
            "Epoch [819/1000], Step [1/8], d_loss: 10.9359, g_loss: -0.0000\n",
            "Epoch [819/1000], Step [2/8], d_loss: 243.5103, g_loss: -0.0000\n",
            "Epoch [819/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [819/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [819/1000], Step [5/8], d_loss: 26.7051, g_loss: -0.0000\n",
            "Epoch [819/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [819/1000], Step [7/8], d_loss: 1611.3340, g_loss: -0.0000\n",
            "Epoch [819/1000], Step [8/8], d_loss: 8.9924, g_loss: -0.0000\n",
            "Epoch [820/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [820/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [820/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [820/1000], Step [4/8], d_loss: 8.9621, g_loss: -0.0000\n",
            "Epoch [820/1000], Step [5/8], d_loss: 8.9993, g_loss: -0.0000\n",
            "Epoch [820/1000], Step [6/8], d_loss: 8.8846, g_loss: -0.0000\n",
            "Epoch [820/1000], Step [7/8], d_loss: 9.2898, g_loss: -0.0000\n",
            "Epoch [820/1000], Step [8/8], d_loss: 946.4481, g_loss: -0.0000\n",
            "Epoch [821/1000], Step [1/8], d_loss: 8.9973, g_loss: -0.0000\n",
            "Epoch [821/1000], Step [2/8], d_loss: 498.2300, g_loss: -0.0000\n",
            "Epoch [821/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [821/1000], Step [4/8], d_loss: 8.9825, g_loss: -0.0000\n",
            "Epoch [821/1000], Step [5/8], d_loss: 27.1295, g_loss: -0.0000\n",
            "Epoch [821/1000], Step [6/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [821/1000], Step [7/8], d_loss: 76.2927, g_loss: -0.0000\n",
            "Epoch [821/1000], Step [8/8], d_loss: 8.9973, g_loss: -0.0000\n",
            "Epoch [822/1000], Step [1/8], d_loss: 8.9963, g_loss: -0.0000\n",
            "Epoch [822/1000], Step [2/8], d_loss: 8.9984, g_loss: -0.0000\n",
            "Epoch [822/1000], Step [3/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [822/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [822/1000], Step [5/8], d_loss: 8.6867, g_loss: -0.0000\n",
            "Epoch [822/1000], Step [6/8], d_loss: 7861.4458, g_loss: -0.0000\n",
            "Epoch [822/1000], Step [7/8], d_loss: 22742.8984, g_loss: -0.0000\n",
            "Epoch [822/1000], Step [8/8], d_loss: 8.6351, g_loss: -0.0000\n",
            "Epoch [823/1000], Step [1/8], d_loss: 8.9782, g_loss: -0.0000\n",
            "Epoch [823/1000], Step [2/8], d_loss: 8.9926, g_loss: -0.0000\n",
            "Epoch [823/1000], Step [3/8], d_loss: 8.6895, g_loss: -0.0000\n",
            "Epoch [823/1000], Step [4/8], d_loss: 8.9962, g_loss: -0.0000\n",
            "Epoch [823/1000], Step [5/8], d_loss: 8.9842, g_loss: -0.0000\n",
            "Epoch [823/1000], Step [6/8], d_loss: 8.4622, g_loss: -0.0000\n",
            "Epoch [823/1000], Step [7/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [823/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [824/1000], Step [1/8], d_loss: 12772.6631, g_loss: -0.0000\n",
            "Epoch [824/1000], Step [2/8], d_loss: 8.9993, g_loss: -0.0000\n",
            "Epoch [824/1000], Step [3/8], d_loss: 8.9988, g_loss: -0.0000\n",
            "Epoch [824/1000], Step [4/8], d_loss: 41.5613, g_loss: -0.0000\n",
            "Epoch [824/1000], Step [5/8], d_loss: 3717.4712, g_loss: -0.0000\n",
            "Epoch [824/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [824/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [824/1000], Step [8/8], d_loss: 1901.5599, g_loss: -0.0000\n",
            "Epoch [825/1000], Step [1/8], d_loss: 16301.0996, g_loss: -0.0000\n",
            "Epoch [825/1000], Step [2/8], d_loss: 3663.1538, g_loss: -0.0000\n",
            "Epoch [825/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [825/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [825/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0004\n",
            "Epoch [825/1000], Step [6/8], d_loss: 432.7173, g_loss: -0.0000\n",
            "Epoch [825/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [825/1000], Step [8/8], d_loss: 8.9920, g_loss: -0.0007\n",
            "Epoch [826/1000], Step [1/8], d_loss: 40.1278, g_loss: -0.0000\n",
            "Epoch [826/1000], Step [2/8], d_loss: 8.9369, g_loss: -0.0000\n",
            "Epoch [826/1000], Step [3/8], d_loss: 46.4693, g_loss: -0.0000\n",
            "Epoch [826/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [826/1000], Step [5/8], d_loss: 2486.3398, g_loss: -0.0000\n",
            "Epoch [826/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [826/1000], Step [7/8], d_loss: 314.0258, g_loss: -0.0000\n",
            "Epoch [826/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [827/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0312\n",
            "Epoch [827/1000], Step [2/8], d_loss: 45.7650, g_loss: -0.0000\n",
            "Epoch [827/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [827/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [827/1000], Step [5/8], d_loss: 6931.9126, g_loss: -0.0000\n",
            "Epoch [827/1000], Step [6/8], d_loss: 8.9962, g_loss: -0.0000\n",
            "Epoch [827/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [827/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [828/1000], Step [1/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [828/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [828/1000], Step [3/8], d_loss: 9618.7295, g_loss: -0.0000\n",
            "Epoch [828/1000], Step [4/8], d_loss: 8.6397, g_loss: -0.0000\n",
            "Epoch [828/1000], Step [5/8], d_loss: 8.9976, g_loss: -0.0000\n",
            "Epoch [828/1000], Step [6/8], d_loss: 27512.1875, g_loss: -0.0000\n",
            "Epoch [828/1000], Step [7/8], d_loss: 8.9825, g_loss: -0.0000\n",
            "Epoch [828/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [829/1000], Step [1/8], d_loss: 892.3590, g_loss: -0.0000\n",
            "Epoch [829/1000], Step [2/8], d_loss: 8.8033, g_loss: -0.0000\n",
            "Epoch [829/1000], Step [3/8], d_loss: 87.0442, g_loss: -0.0000\n",
            "Epoch [829/1000], Step [4/8], d_loss: 8.6996, g_loss: -0.0000\n",
            "Epoch [829/1000], Step [5/8], d_loss: 45.8923, g_loss: -0.0000\n",
            "Epoch [829/1000], Step [6/8], d_loss: 6407.0098, g_loss: -0.0000\n",
            "Epoch [829/1000], Step [7/8], d_loss: 55.6757, g_loss: -0.0000\n",
            "Epoch [829/1000], Step [8/8], d_loss: 8.5806, g_loss: -0.0000\n",
            "Epoch [830/1000], Step [1/8], d_loss: 24.2081, g_loss: -0.0000\n",
            "Epoch [830/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [830/1000], Step [3/8], d_loss: 5782.6289, g_loss: -0.0000\n",
            "Epoch [830/1000], Step [4/8], d_loss: 8.9874, g_loss: -0.0000\n",
            "Epoch [830/1000], Step [5/8], d_loss: 1216.8303, g_loss: -0.0000\n",
            "Epoch [830/1000], Step [6/8], d_loss: 6608.1035, g_loss: -0.0000\n",
            "Epoch [830/1000], Step [7/8], d_loss: 8.6833, g_loss: -0.0000\n",
            "Epoch [830/1000], Step [8/8], d_loss: 8.5672, g_loss: -0.0000\n",
            "Epoch [831/1000], Step [1/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [831/1000], Step [2/8], d_loss: 32144.8516, g_loss: -0.0000\n",
            "Epoch [831/1000], Step [3/8], d_loss: 16027.6953, g_loss: -0.0000\n",
            "Epoch [831/1000], Step [4/8], d_loss: 8.9989, g_loss: -0.0000\n",
            "Epoch [831/1000], Step [5/8], d_loss: 9.7096, g_loss: -0.0000\n",
            "Epoch [831/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [831/1000], Step [7/8], d_loss: 8.9937, g_loss: -0.0000\n",
            "Epoch [831/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [832/1000], Step [1/8], d_loss: 1007.8335, g_loss: -0.0000\n",
            "Epoch [832/1000], Step [2/8], d_loss: 8.8379, g_loss: -0.0000\n",
            "Epoch [832/1000], Step [3/8], d_loss: 8.9754, g_loss: -0.0000\n",
            "Epoch [832/1000], Step [4/8], d_loss: 4376.5933, g_loss: -0.0000\n",
            "Epoch [832/1000], Step [5/8], d_loss: 8.9967, g_loss: -0.0000\n",
            "Epoch [832/1000], Step [6/8], d_loss: 8.9740, g_loss: -0.0000\n",
            "Epoch [832/1000], Step [7/8], d_loss: 246.1533, g_loss: -0.0000\n",
            "Epoch [832/1000], Step [8/8], d_loss: 58.7381, g_loss: -0.0000\n",
            "Epoch [833/1000], Step [1/8], d_loss: 8.9982, g_loss: -0.0000\n",
            "Epoch [833/1000], Step [2/8], d_loss: 58408.1992, g_loss: -0.0000\n",
            "Epoch [833/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [833/1000], Step [4/8], d_loss: 5152.5688, g_loss: -0.0000\n",
            "Epoch [833/1000], Step [5/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [833/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [833/1000], Step [7/8], d_loss: 8.9946, g_loss: -0.0000\n",
            "Epoch [833/1000], Step [8/8], d_loss: 5977.5542, g_loss: -0.0000\n",
            "Epoch [834/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [834/1000], Step [2/8], d_loss: 2363.0444, g_loss: -0.0000\n",
            "Epoch [834/1000], Step [3/8], d_loss: 8.8639, g_loss: -0.0000\n",
            "Epoch [834/1000], Step [4/8], d_loss: 2299.0996, g_loss: -0.0000\n",
            "Epoch [834/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [834/1000], Step [6/8], d_loss: 8.6878, g_loss: -0.0000\n",
            "Epoch [834/1000], Step [7/8], d_loss: 227.0582, g_loss: -0.0000\n",
            "Epoch [834/1000], Step [8/8], d_loss: 12965.9727, g_loss: -0.0000\n",
            "Epoch [835/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [835/1000], Step [2/8], d_loss: 40.2566, g_loss: -0.0000\n",
            "Epoch [835/1000], Step [3/8], d_loss: 8.9979, g_loss: -0.0000\n",
            "Epoch [835/1000], Step [4/8], d_loss: 8.8285, g_loss: -0.0000\n",
            "Epoch [835/1000], Step [5/8], d_loss: 41.4281, g_loss: -0.0000\n",
            "Epoch [835/1000], Step [6/8], d_loss: 14950.1631, g_loss: -0.0000\n",
            "Epoch [835/1000], Step [7/8], d_loss: 1420.8658, g_loss: -0.0000\n",
            "Epoch [835/1000], Step [8/8], d_loss: 9.8653, g_loss: -0.0000\n",
            "Epoch [836/1000], Step [1/8], d_loss: 8.8569, g_loss: -0.0000\n",
            "Epoch [836/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [836/1000], Step [3/8], d_loss: 1931.7700, g_loss: -0.0000\n",
            "Epoch [836/1000], Step [4/8], d_loss: 311.4304, g_loss: -0.0000\n",
            "Epoch [836/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [836/1000], Step [6/8], d_loss: 8.6888, g_loss: -0.0000\n",
            "Epoch [836/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [836/1000], Step [8/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [837/1000], Step [1/8], d_loss: 10096.8643, g_loss: -0.0000\n",
            "Epoch [837/1000], Step [2/8], d_loss: 8.9986, g_loss: -0.0000\n",
            "Epoch [837/1000], Step [3/8], d_loss: 8.9806, g_loss: -0.0000\n",
            "Epoch [837/1000], Step [4/8], d_loss: 3088.2036, g_loss: -0.0000\n",
            "Epoch [837/1000], Step [5/8], d_loss: 16947.2266, g_loss: -0.0000\n",
            "Epoch [837/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [837/1000], Step [7/8], d_loss: 131.3495, g_loss: -0.0000\n",
            "Epoch [837/1000], Step [8/8], d_loss: 9.8430, g_loss: -0.0000\n",
            "Epoch [838/1000], Step [1/8], d_loss: 10.6062, g_loss: -0.0000\n",
            "Epoch [838/1000], Step [2/8], d_loss: 3975.4673, g_loss: -0.0000\n",
            "Epoch [838/1000], Step [3/8], d_loss: 9.3298, g_loss: -0.0000\n",
            "Epoch [838/1000], Step [4/8], d_loss: 8.8696, g_loss: -0.0000\n",
            "Epoch [838/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [838/1000], Step [6/8], d_loss: 8.9980, g_loss: -0.0000\n",
            "Epoch [838/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [838/1000], Step [8/8], d_loss: 8.9882, g_loss: -0.0000\n",
            "Epoch [839/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [839/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [839/1000], Step [3/8], d_loss: 13904.3369, g_loss: -0.0000\n",
            "Epoch [839/1000], Step [4/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [839/1000], Step [5/8], d_loss: 8.8902, g_loss: -0.0000\n",
            "Epoch [839/1000], Step [6/8], d_loss: 8.9906, g_loss: -0.0000\n",
            "Epoch [839/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [839/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [840/1000], Step [1/8], d_loss: 8.7035, g_loss: -0.0000\n",
            "Epoch [840/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [840/1000], Step [3/8], d_loss: 12730.3711, g_loss: -0.0000\n",
            "Epoch [840/1000], Step [4/8], d_loss: 8.9943, g_loss: -0.0000\n",
            "Epoch [840/1000], Step [5/8], d_loss: 8.9851, g_loss: -0.0000\n",
            "Epoch [840/1000], Step [6/8], d_loss: 3964.3452, g_loss: -0.0000\n",
            "Epoch [840/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [840/1000], Step [8/8], d_loss: 8.9990, g_loss: -0.0000\n",
            "Epoch [841/1000], Step [1/8], d_loss: 10584.3223, g_loss: -0.0000\n",
            "Epoch [841/1000], Step [2/8], d_loss: 3016.3093, g_loss: -0.0000\n",
            "Epoch [841/1000], Step [3/8], d_loss: 10.3393, g_loss: -0.0000\n",
            "Epoch [841/1000], Step [4/8], d_loss: 13280.9131, g_loss: -0.0000\n",
            "Epoch [841/1000], Step [5/8], d_loss: 20692.3242, g_loss: -0.0000\n",
            "Epoch [841/1000], Step [6/8], d_loss: 823.7286, g_loss: -0.0000\n",
            "Epoch [841/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [841/1000], Step [8/8], d_loss: 3067.2131, g_loss: -0.0000\n",
            "Epoch [842/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [842/1000], Step [2/8], d_loss: 8.9958, g_loss: -0.0000\n",
            "Epoch [842/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [842/1000], Step [4/8], d_loss: 52.5376, g_loss: -0.0000\n",
            "Epoch [842/1000], Step [5/8], d_loss: 8.9704, g_loss: -0.0000\n",
            "Epoch [842/1000], Step [6/8], d_loss: 49.5813, g_loss: -0.0000\n",
            "Epoch [842/1000], Step [7/8], d_loss: 8.9030, g_loss: -0.0000\n",
            "Epoch [842/1000], Step [8/8], d_loss: 2021.7712, g_loss: -0.0000\n",
            "Epoch [843/1000], Step [1/8], d_loss: 2397.4629, g_loss: -0.0000\n",
            "Epoch [843/1000], Step [2/8], d_loss: 4550.4131, g_loss: -0.0000\n",
            "Epoch [843/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [843/1000], Step [4/8], d_loss: 8.9984, g_loss: -0.0000\n",
            "Epoch [843/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [843/1000], Step [6/8], d_loss: 8.9805, g_loss: -0.0000\n",
            "Epoch [843/1000], Step [7/8], d_loss: 7206.9746, g_loss: -0.0000\n",
            "Epoch [843/1000], Step [8/8], d_loss: 316.3118, g_loss: -0.0000\n",
            "Epoch [844/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [844/1000], Step [2/8], d_loss: 8.8133, g_loss: -0.0000\n",
            "Epoch [844/1000], Step [3/8], d_loss: 9.9994, g_loss: -0.0000\n",
            "Epoch [844/1000], Step [4/8], d_loss: 8.9986, g_loss: -0.0000\n",
            "Epoch [844/1000], Step [5/8], d_loss: 13.3802, g_loss: -0.0000\n",
            "Epoch [844/1000], Step [6/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [844/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [844/1000], Step [8/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [845/1000], Step [1/8], d_loss: 9924.7588, g_loss: -0.0000\n",
            "Epoch [845/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [845/1000], Step [3/8], d_loss: 10095.5166, g_loss: -0.0000\n",
            "Epoch [845/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [845/1000], Step [5/8], d_loss: 8.4946, g_loss: -0.0000\n",
            "Epoch [845/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [845/1000], Step [7/8], d_loss: 29.8897, g_loss: -0.0000\n",
            "Epoch [845/1000], Step [8/8], d_loss: 2884.1072, g_loss: -0.0000\n",
            "Epoch [846/1000], Step [1/8], d_loss: 2616.0310, g_loss: -0.0000\n",
            "Epoch [846/1000], Step [2/8], d_loss: 22.2075, g_loss: -0.0000\n",
            "Epoch [846/1000], Step [3/8], d_loss: 6862.0254, g_loss: -0.0000\n",
            "Epoch [846/1000], Step [4/8], d_loss: 8.9730, g_loss: -0.0000\n",
            "Epoch [846/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [846/1000], Step [6/8], d_loss: 23.7110, g_loss: -0.0000\n",
            "Epoch [846/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [846/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [847/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [847/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [847/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [847/1000], Step [4/8], d_loss: 8.9456, g_loss: -0.0000\n",
            "Epoch [847/1000], Step [5/8], d_loss: 8.9938, g_loss: -0.0000\n",
            "Epoch [847/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [847/1000], Step [7/8], d_loss: 14.9464, g_loss: -0.0000\n",
            "Epoch [847/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [848/1000], Step [1/8], d_loss: 776.6245, g_loss: -0.0000\n",
            "Epoch [848/1000], Step [2/8], d_loss: 8.9822, g_loss: -0.0000\n",
            "Epoch [848/1000], Step [3/8], d_loss: 46.5436, g_loss: -0.0000\n",
            "Epoch [848/1000], Step [4/8], d_loss: 8.7352, g_loss: -0.0000\n",
            "Epoch [848/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [848/1000], Step [6/8], d_loss: 18085.9004, g_loss: -0.0000\n",
            "Epoch [848/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [848/1000], Step [8/8], d_loss: 18.0002, g_loss: -0.0000\n",
            "Epoch [849/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [849/1000], Step [2/8], d_loss: 12987.4727, g_loss: -0.0000\n",
            "Epoch [849/1000], Step [3/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [849/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [849/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [849/1000], Step [6/8], d_loss: 8.9989, g_loss: -0.0000\n",
            "Epoch [849/1000], Step [7/8], d_loss: 622.5336, g_loss: -0.0000\n",
            "Epoch [849/1000], Step [8/8], d_loss: 29573.3750, g_loss: -0.0000\n",
            "Epoch [850/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [850/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [850/1000], Step [3/8], d_loss: 9.0119, g_loss: -0.0000\n",
            "Epoch [850/1000], Step [4/8], d_loss: 26.4621, g_loss: -0.0000\n",
            "Epoch [850/1000], Step [5/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [850/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [850/1000], Step [7/8], d_loss: 8.7454, g_loss: -0.0000\n",
            "Epoch [850/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [851/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [851/1000], Step [2/8], d_loss: 9.1877, g_loss: -0.0000\n",
            "Epoch [851/1000], Step [3/8], d_loss: 8.9995, g_loss: -0.0000\n",
            "Epoch [851/1000], Step [4/8], d_loss: 8.9958, g_loss: -0.0000\n",
            "Epoch [851/1000], Step [5/8], d_loss: 10568.3115, g_loss: -0.0000\n",
            "Epoch [851/1000], Step [6/8], d_loss: 33.8481, g_loss: -0.0000\n",
            "Epoch [851/1000], Step [7/8], d_loss: 66.6059, g_loss: -0.0000\n",
            "Epoch [851/1000], Step [8/8], d_loss: 8.9887, g_loss: -0.0000\n",
            "Epoch [852/1000], Step [1/8], d_loss: 9.5101, g_loss: -0.0000\n",
            "Epoch [852/1000], Step [2/8], d_loss: 44648.3906, g_loss: -0.0000\n",
            "Epoch [852/1000], Step [3/8], d_loss: 601.2972, g_loss: -0.0000\n",
            "Epoch [852/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [852/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [852/1000], Step [6/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [852/1000], Step [7/8], d_loss: 8.8500, g_loss: -0.0000\n",
            "Epoch [852/1000], Step [8/8], d_loss: 8.9982, g_loss: -0.0000\n",
            "Epoch [853/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [853/1000], Step [2/8], d_loss: 8.9876, g_loss: -0.0000\n",
            "Epoch [853/1000], Step [3/8], d_loss: 8.9894, g_loss: -0.0000\n",
            "Epoch [853/1000], Step [4/8], d_loss: 359.1086, g_loss: -0.0000\n",
            "Epoch [853/1000], Step [5/8], d_loss: 8.8086, g_loss: -0.0000\n",
            "Epoch [853/1000], Step [6/8], d_loss: 8.9981, g_loss: -0.0000\n",
            "Epoch [853/1000], Step [7/8], d_loss: 8.9908, g_loss: -0.0000\n",
            "Epoch [853/1000], Step [8/8], d_loss: 8.9286, g_loss: -0.0000\n",
            "Epoch [854/1000], Step [1/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [854/1000], Step [2/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [854/1000], Step [3/8], d_loss: 8.9226, g_loss: -0.0000\n",
            "Epoch [854/1000], Step [4/8], d_loss: 929.4078, g_loss: -0.0000\n",
            "Epoch [854/1000], Step [5/8], d_loss: 4699.8438, g_loss: -0.0000\n",
            "Epoch [854/1000], Step [6/8], d_loss: 12.6655, g_loss: -0.0000\n",
            "Epoch [854/1000], Step [7/8], d_loss: 12115.6396, g_loss: -0.0000\n",
            "Epoch [854/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [855/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [855/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [855/1000], Step [3/8], d_loss: 23.2798, g_loss: -0.0000\n",
            "Epoch [855/1000], Step [4/8], d_loss: 1106.3074, g_loss: -0.0000\n",
            "Epoch [855/1000], Step [5/8], d_loss: 8.9190, g_loss: -0.0000\n",
            "Epoch [855/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [855/1000], Step [7/8], d_loss: 2071.6033, g_loss: -0.0000\n",
            "Epoch [855/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [856/1000], Step [1/8], d_loss: 8.7411, g_loss: -0.0000\n",
            "Epoch [856/1000], Step [2/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [856/1000], Step [3/8], d_loss: 58.3396, g_loss: -0.0000\n",
            "Epoch [856/1000], Step [4/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [856/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [856/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [856/1000], Step [7/8], d_loss: 40.8731, g_loss: -0.0000\n",
            "Epoch [856/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [857/1000], Step [1/8], d_loss: 5061.6406, g_loss: -0.0000\n",
            "Epoch [857/1000], Step [2/8], d_loss: 8.9839, g_loss: -0.0000\n",
            "Epoch [857/1000], Step [3/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [857/1000], Step [4/8], d_loss: 15.1041, g_loss: -0.0000\n",
            "Epoch [857/1000], Step [5/8], d_loss: 3827.7732, g_loss: -0.0000\n",
            "Epoch [857/1000], Step [6/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [857/1000], Step [7/8], d_loss: 345.1011, g_loss: -0.0000\n",
            "Epoch [857/1000], Step [8/8], d_loss: 8.9743, g_loss: -0.0000\n",
            "Epoch [858/1000], Step [1/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [858/1000], Step [2/8], d_loss: 1756.3827, g_loss: -0.0000\n",
            "Epoch [858/1000], Step [3/8], d_loss: 44567.3516, g_loss: -0.0000\n",
            "Epoch [858/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [858/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [858/1000], Step [6/8], d_loss: 8.8921, g_loss: -0.0000\n",
            "Epoch [858/1000], Step [7/8], d_loss: 8.9748, g_loss: -0.0000\n",
            "Epoch [858/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [859/1000], Step [1/8], d_loss: 94.5259, g_loss: -0.0000\n",
            "Epoch [859/1000], Step [2/8], d_loss: 8.7632, g_loss: -0.0000\n",
            "Epoch [859/1000], Step [3/8], d_loss: 20977.8516, g_loss: -0.0000\n",
            "Epoch [859/1000], Step [4/8], d_loss: 8.9265, g_loss: -0.0000\n",
            "Epoch [859/1000], Step [5/8], d_loss: 8.9461, g_loss: -0.0000\n",
            "Epoch [859/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [859/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [859/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [860/1000], Step [1/8], d_loss: 8.9952, g_loss: -0.0000\n",
            "Epoch [860/1000], Step [2/8], d_loss: 163.9227, g_loss: -0.0000\n",
            "Epoch [860/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [860/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [860/1000], Step [5/8], d_loss: 8.9613, g_loss: -0.0000\n",
            "Epoch [860/1000], Step [6/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [860/1000], Step [7/8], d_loss: 8.9984, g_loss: -0.0000\n",
            "Epoch [860/1000], Step [8/8], d_loss: 8.9979, g_loss: -0.0000\n",
            "Epoch [861/1000], Step [1/8], d_loss: 365.0826, g_loss: -0.0000\n",
            "Epoch [861/1000], Step [2/8], d_loss: 8.8645, g_loss: -0.0000\n",
            "Epoch [861/1000], Step [3/8], d_loss: 208.3844, g_loss: -0.0000\n",
            "Epoch [861/1000], Step [4/8], d_loss: 8.9990, g_loss: -0.0000\n",
            "Epoch [861/1000], Step [5/8], d_loss: 8.6888, g_loss: -0.0000\n",
            "Epoch [861/1000], Step [6/8], d_loss: 112.5698, g_loss: -0.0000\n",
            "Epoch [861/1000], Step [7/8], d_loss: 8.9933, g_loss: -0.0000\n",
            "Epoch [861/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [862/1000], Step [1/8], d_loss: 8.6948, g_loss: -0.0000\n",
            "Epoch [862/1000], Step [2/8], d_loss: 32.3625, g_loss: -0.0000\n",
            "Epoch [862/1000], Step [3/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [862/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [862/1000], Step [5/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [862/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [862/1000], Step [7/8], d_loss: 22.4807, g_loss: -0.0000\n",
            "Epoch [862/1000], Step [8/8], d_loss: 14.3367, g_loss: -0.0000\n",
            "Epoch [863/1000], Step [1/8], d_loss: 66.1167, g_loss: -0.0000\n",
            "Epoch [863/1000], Step [2/8], d_loss: 8.9931, g_loss: -0.0000\n",
            "Epoch [863/1000], Step [3/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [863/1000], Step [4/8], d_loss: 11.5309, g_loss: -0.0000\n",
            "Epoch [863/1000], Step [5/8], d_loss: 3163.2434, g_loss: -0.0000\n",
            "Epoch [863/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [863/1000], Step [7/8], d_loss: 10079.3506, g_loss: -0.0000\n",
            "Epoch [863/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [864/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [864/1000], Step [2/8], d_loss: 20095.5469, g_loss: -0.0000\n",
            "Epoch [864/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [864/1000], Step [4/8], d_loss: 1506.7260, g_loss: -0.0000\n",
            "Epoch [864/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [864/1000], Step [6/8], d_loss: 8.9976, g_loss: -0.0000\n",
            "Epoch [864/1000], Step [7/8], d_loss: 8.9991, g_loss: -0.0000\n",
            "Epoch [864/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [865/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [865/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [865/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [865/1000], Step [4/8], d_loss: 8.9976, g_loss: -0.0000\n",
            "Epoch [865/1000], Step [5/8], d_loss: 8.8344, g_loss: -0.0000\n",
            "Epoch [865/1000], Step [6/8], d_loss: 30.1873, g_loss: -0.0000\n",
            "Epoch [865/1000], Step [7/8], d_loss: 8.9992, g_loss: -0.0000\n",
            "Epoch [865/1000], Step [8/8], d_loss: 8.9890, g_loss: -0.0000\n",
            "Epoch [866/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [866/1000], Step [2/8], d_loss: 6611.0127, g_loss: -0.0000\n",
            "Epoch [866/1000], Step [3/8], d_loss: 22113.1895, g_loss: -0.0000\n",
            "Epoch [866/1000], Step [4/8], d_loss: 122.8683, g_loss: -0.0000\n",
            "Epoch [866/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [866/1000], Step [6/8], d_loss: 1354.5432, g_loss: -0.0000\n",
            "Epoch [866/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [866/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [867/1000], Step [1/8], d_loss: 8.5273, g_loss: -0.0000\n",
            "Epoch [867/1000], Step [2/8], d_loss: 9383.8398, g_loss: -0.0000\n",
            "Epoch [867/1000], Step [3/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [867/1000], Step [4/8], d_loss: 8.9922, g_loss: -0.0000\n",
            "Epoch [867/1000], Step [5/8], d_loss: 8.9909, g_loss: -0.0000\n",
            "Epoch [867/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [867/1000], Step [7/8], d_loss: 8.9932, g_loss: -0.0000\n",
            "Epoch [867/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [868/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [868/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [868/1000], Step [3/8], d_loss: 8.8216, g_loss: -0.0000\n",
            "Epoch [868/1000], Step [4/8], d_loss: 9.8482, g_loss: -0.0000\n",
            "Epoch [868/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [868/1000], Step [6/8], d_loss: 77.7823, g_loss: -0.0000\n",
            "Epoch [868/1000], Step [7/8], d_loss: 3224.5083, g_loss: -0.0000\n",
            "Epoch [868/1000], Step [8/8], d_loss: 95455.8438, g_loss: -0.0000\n",
            "Epoch [869/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [869/1000], Step [2/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [869/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [869/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [869/1000], Step [5/8], d_loss: 476.4267, g_loss: -0.0000\n",
            "Epoch [869/1000], Step [6/8], d_loss: 8.9907, g_loss: -0.0000\n",
            "Epoch [869/1000], Step [7/8], d_loss: 142.7472, g_loss: -0.0000\n",
            "Epoch [869/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [870/1000], Step [1/8], d_loss: 8.9924, g_loss: -0.0004\n",
            "Epoch [870/1000], Step [2/8], d_loss: 32.0609, g_loss: -0.0000\n",
            "Epoch [870/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0005\n",
            "Epoch [870/1000], Step [4/8], d_loss: 8.9821, g_loss: -0.0000\n",
            "Epoch [870/1000], Step [5/8], d_loss: 112.9723, g_loss: -0.0000\n",
            "Epoch [870/1000], Step [6/8], d_loss: 2897.1699, g_loss: -0.0000\n",
            "Epoch [870/1000], Step [7/8], d_loss: 8.6875, g_loss: -0.0000\n",
            "Epoch [870/1000], Step [8/8], d_loss: 424.3920, g_loss: -0.0000\n",
            "Epoch [871/1000], Step [1/8], d_loss: 8.9993, g_loss: -0.0000\n",
            "Epoch [871/1000], Step [2/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [871/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [871/1000], Step [4/8], d_loss: 9557.3965, g_loss: -0.0000\n",
            "Epoch [871/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [871/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [871/1000], Step [7/8], d_loss: 9.0238, g_loss: -0.0000\n",
            "Epoch [871/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [872/1000], Step [1/8], d_loss: 12543.0762, g_loss: -0.0000\n",
            "Epoch [872/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [872/1000], Step [3/8], d_loss: 10.2169, g_loss: -0.0000\n",
            "Epoch [872/1000], Step [4/8], d_loss: 8.9396, g_loss: -0.0000\n",
            "Epoch [872/1000], Step [5/8], d_loss: 8.8163, g_loss: -0.0000\n",
            "Epoch [872/1000], Step [6/8], d_loss: 8.9948, g_loss: -0.0000\n",
            "Epoch [872/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [872/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [873/1000], Step [1/8], d_loss: 18174.5742, g_loss: -0.0000\n",
            "Epoch [873/1000], Step [2/8], d_loss: 807.6889, g_loss: -0.0000\n",
            "Epoch [873/1000], Step [3/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [873/1000], Step [4/8], d_loss: 8.9953, g_loss: -0.0000\n",
            "Epoch [873/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [873/1000], Step [6/8], d_loss: 16.2374, g_loss: -0.0000\n",
            "Epoch [873/1000], Step [7/8], d_loss: 1468.7148, g_loss: -0.0000\n",
            "Epoch [873/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [874/1000], Step [1/8], d_loss: 1733.0118, g_loss: -0.0000\n",
            "Epoch [874/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [874/1000], Step [3/8], d_loss: 8.6893, g_loss: -0.0000\n",
            "Epoch [874/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [874/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [874/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [874/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [874/1000], Step [8/8], d_loss: 8930.0586, g_loss: -0.0000\n",
            "Epoch [875/1000], Step [1/8], d_loss: 10.1733, g_loss: -0.0000\n",
            "Epoch [875/1000], Step [2/8], d_loss: 8.7749, g_loss: -0.0000\n",
            "Epoch [875/1000], Step [3/8], d_loss: 61.0935, g_loss: -0.0000\n",
            "Epoch [875/1000], Step [4/8], d_loss: 11.6396, g_loss: -0.0000\n",
            "Epoch [875/1000], Step [5/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [875/1000], Step [6/8], d_loss: 985.8932, g_loss: -0.0000\n",
            "Epoch [875/1000], Step [7/8], d_loss: 26845.4492, g_loss: -0.0000\n",
            "Epoch [875/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [876/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [876/1000], Step [2/8], d_loss: 876.3068, g_loss: -0.0000\n",
            "Epoch [876/1000], Step [3/8], d_loss: 8.7695, g_loss: -0.0000\n",
            "Epoch [876/1000], Step [4/8], d_loss: 2731.5242, g_loss: -0.0000\n",
            "Epoch [876/1000], Step [5/8], d_loss: 494.8445, g_loss: -0.0000\n",
            "Epoch [876/1000], Step [6/8], d_loss: 339.2912, g_loss: -0.0000\n",
            "Epoch [876/1000], Step [7/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [876/1000], Step [8/8], d_loss: 7261.6343, g_loss: -0.0000\n",
            "Epoch [877/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [877/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [877/1000], Step [3/8], d_loss: 834.3485, g_loss: -0.0000\n",
            "Epoch [877/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [877/1000], Step [5/8], d_loss: 20.1963, g_loss: -0.0000\n",
            "Epoch [877/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [877/1000], Step [7/8], d_loss: 2901.0310, g_loss: -0.0000\n",
            "Epoch [877/1000], Step [8/8], d_loss: 4772.3647, g_loss: -0.0000\n",
            "Epoch [878/1000], Step [1/8], d_loss: 8.9651, g_loss: -0.0000\n",
            "Epoch [878/1000], Step [2/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [878/1000], Step [3/8], d_loss: 10.4242, g_loss: -0.0000\n",
            "Epoch [878/1000], Step [4/8], d_loss: 9336.2197, g_loss: -0.0000\n",
            "Epoch [878/1000], Step [5/8], d_loss: 542.6558, g_loss: -0.0000\n",
            "Epoch [878/1000], Step [6/8], d_loss: 8.4905, g_loss: -0.0000\n",
            "Epoch [878/1000], Step [7/8], d_loss: 13.0330, g_loss: -0.0000\n",
            "Epoch [878/1000], Step [8/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [879/1000], Step [1/8], d_loss: 16.6176, g_loss: -0.0000\n",
            "Epoch [879/1000], Step [2/8], d_loss: 8.9995, g_loss: -0.0000\n",
            "Epoch [879/1000], Step [3/8], d_loss: 8.7249, g_loss: -0.0000\n",
            "Epoch [879/1000], Step [4/8], d_loss: 8.9832, g_loss: -0.0000\n",
            "Epoch [879/1000], Step [5/8], d_loss: 8.9234, g_loss: -0.0000\n",
            "Epoch [879/1000], Step [6/8], d_loss: 953.2608, g_loss: -0.0311\n",
            "Epoch [879/1000], Step [7/8], d_loss: 14763.2979, g_loss: -0.0000\n",
            "Epoch [879/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [880/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [880/1000], Step [2/8], d_loss: 8.9727, g_loss: -0.0000\n",
            "Epoch [880/1000], Step [3/8], d_loss: 66.2910, g_loss: -0.0000\n",
            "Epoch [880/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [880/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [880/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [880/1000], Step [7/8], d_loss: 16.5041, g_loss: -0.0000\n",
            "Epoch [880/1000], Step [8/8], d_loss: 8.8336, g_loss: -0.0000\n",
            "Epoch [881/1000], Step [1/8], d_loss: 8075.6221, g_loss: -0.0000\n",
            "Epoch [881/1000], Step [2/8], d_loss: 8.6964, g_loss: -0.0000\n",
            "Epoch [881/1000], Step [3/8], d_loss: 8.6947, g_loss: -0.0000\n",
            "Epoch [881/1000], Step [4/8], d_loss: 14.4215, g_loss: -0.0000\n",
            "Epoch [881/1000], Step [5/8], d_loss: 3918.5469, g_loss: -0.0000\n",
            "Epoch [881/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [881/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [881/1000], Step [8/8], d_loss: 56.3903, g_loss: -0.0000\n",
            "Epoch [882/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [882/1000], Step [2/8], d_loss: 52.0214, g_loss: -0.0000\n",
            "Epoch [882/1000], Step [3/8], d_loss: 8.9843, g_loss: -0.0000\n",
            "Epoch [882/1000], Step [4/8], d_loss: 12498.3369, g_loss: -0.0000\n",
            "Epoch [882/1000], Step [5/8], d_loss: 5777.6611, g_loss: -0.0000\n",
            "Epoch [882/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [882/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [882/1000], Step [8/8], d_loss: 8.9655, g_loss: -0.0000\n",
            "Epoch [883/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [883/1000], Step [2/8], d_loss: 9.0005, g_loss: -0.0000\n",
            "Epoch [883/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [883/1000], Step [4/8], d_loss: 4764.6841, g_loss: -0.0000\n",
            "Epoch [883/1000], Step [5/8], d_loss: 8.9548, g_loss: -0.0000\n",
            "Epoch [883/1000], Step [6/8], d_loss: 8.8077, g_loss: -0.0000\n",
            "Epoch [883/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0036\n",
            "Epoch [883/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [884/1000], Step [1/8], d_loss: 9657.7988, g_loss: -0.0000\n",
            "Epoch [884/1000], Step [2/8], d_loss: 8.9991, g_loss: -0.0000\n",
            "Epoch [884/1000], Step [3/8], d_loss: 9627.2275, g_loss: -0.0000\n",
            "Epoch [884/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [884/1000], Step [5/8], d_loss: 8.8796, g_loss: -0.0000\n",
            "Epoch [884/1000], Step [6/8], d_loss: 10.5202, g_loss: -0.0000\n",
            "Epoch [884/1000], Step [7/8], d_loss: 4871.9111, g_loss: -0.0000\n",
            "Epoch [884/1000], Step [8/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [885/1000], Step [1/8], d_loss: 8.8330, g_loss: -0.0000\n",
            "Epoch [885/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [885/1000], Step [3/8], d_loss: 61.3726, g_loss: -0.0000\n",
            "Epoch [885/1000], Step [4/8], d_loss: 8.8513, g_loss: -0.0000\n",
            "Epoch [885/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [885/1000], Step [6/8], d_loss: 8.9837, g_loss: -0.0000\n",
            "Epoch [885/1000], Step [7/8], d_loss: 8.9488, g_loss: -0.0000\n",
            "Epoch [885/1000], Step [8/8], d_loss: 4494.8037, g_loss: -0.0000\n",
            "Epoch [886/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [886/1000], Step [2/8], d_loss: 142.9852, g_loss: -0.0000\n",
            "Epoch [886/1000], Step [3/8], d_loss: 8.7064, g_loss: -0.0000\n",
            "Epoch [886/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [886/1000], Step [5/8], d_loss: 9361.1133, g_loss: -0.0000\n",
            "Epoch [886/1000], Step [6/8], d_loss: 15.8747, g_loss: -0.0000\n",
            "Epoch [886/1000], Step [7/8], d_loss: 8.9883, g_loss: -0.0000\n",
            "Epoch [886/1000], Step [8/8], d_loss: 8.9971, g_loss: -0.0000\n",
            "Epoch [887/1000], Step [1/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [887/1000], Step [2/8], d_loss: 8.9121, g_loss: -0.0000\n",
            "Epoch [887/1000], Step [3/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [887/1000], Step [4/8], d_loss: 9325.4561, g_loss: -0.0000\n",
            "Epoch [887/1000], Step [5/8], d_loss: 8.9928, g_loss: -0.0000\n",
            "Epoch [887/1000], Step [6/8], d_loss: 8.7015, g_loss: -0.0000\n",
            "Epoch [887/1000], Step [7/8], d_loss: 8.8482, g_loss: -0.0000\n",
            "Epoch [887/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [888/1000], Step [1/8], d_loss: 283.5736, g_loss: -0.0000\n",
            "Epoch [888/1000], Step [2/8], d_loss: 5352.5273, g_loss: -0.0301\n",
            "Epoch [888/1000], Step [3/8], d_loss: 8848.4639, g_loss: -0.0000\n",
            "Epoch [888/1000], Step [4/8], d_loss: 10601.9561, g_loss: -0.0000\n",
            "Epoch [888/1000], Step [5/8], d_loss: 8.7127, g_loss: -0.0000\n",
            "Epoch [888/1000], Step [6/8], d_loss: 11.1190, g_loss: -0.0000\n",
            "Epoch [888/1000], Step [7/8], d_loss: 8.7723, g_loss: -0.0000\n",
            "Epoch [888/1000], Step [8/8], d_loss: 9.4249, g_loss: -0.0000\n",
            "Epoch [889/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [889/1000], Step [2/8], d_loss: 8.8135, g_loss: -0.0000\n",
            "Epoch [889/1000], Step [3/8], d_loss: 8.7122, g_loss: -0.0000\n",
            "Epoch [889/1000], Step [4/8], d_loss: 8.9980, g_loss: -0.0000\n",
            "Epoch [889/1000], Step [5/8], d_loss: 8.9819, g_loss: -0.0000\n",
            "Epoch [889/1000], Step [6/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [889/1000], Step [7/8], d_loss: 8.8793, g_loss: -0.0000\n",
            "Epoch [889/1000], Step [8/8], d_loss: 15.7680, g_loss: -0.0000\n",
            "Epoch [890/1000], Step [1/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [890/1000], Step [2/8], d_loss: 11.6924, g_loss: -0.0000\n",
            "Epoch [890/1000], Step [3/8], d_loss: 367.2832, g_loss: -0.0000\n",
            "Epoch [890/1000], Step [4/8], d_loss: 8.9110, g_loss: -0.0000\n",
            "Epoch [890/1000], Step [5/8], d_loss: 1306.7600, g_loss: -0.0000\n",
            "Epoch [890/1000], Step [6/8], d_loss: 8.9575, g_loss: -0.0000\n",
            "Epoch [890/1000], Step [7/8], d_loss: 17684.3203, g_loss: -0.0000\n",
            "Epoch [890/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [891/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [891/1000], Step [2/8], d_loss: 33172.2539, g_loss: -0.0000\n",
            "Epoch [891/1000], Step [3/8], d_loss: 8.9009, g_loss: -0.0000\n",
            "Epoch [891/1000], Step [4/8], d_loss: 2106.9697, g_loss: -0.0000\n",
            "Epoch [891/1000], Step [5/8], d_loss: 8.9438, g_loss: -0.0000\n",
            "Epoch [891/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [891/1000], Step [7/8], d_loss: 9.6547, g_loss: -0.0000\n",
            "Epoch [891/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [892/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [892/1000], Step [2/8], d_loss: 3921.5601, g_loss: -0.0000\n",
            "Epoch [892/1000], Step [3/8], d_loss: 8.8003, g_loss: -0.0000\n",
            "Epoch [892/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [892/1000], Step [5/8], d_loss: 79.0331, g_loss: -0.0000\n",
            "Epoch [892/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [892/1000], Step [7/8], d_loss: 8.8779, g_loss: -0.0000\n",
            "Epoch [892/1000], Step [8/8], d_loss: 8.9354, g_loss: -0.0000\n",
            "Epoch [893/1000], Step [1/8], d_loss: 9.0306, g_loss: -0.0000\n",
            "Epoch [893/1000], Step [2/8], d_loss: 96.3778, g_loss: -0.0000\n",
            "Epoch [893/1000], Step [3/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [893/1000], Step [4/8], d_loss: 8.6472, g_loss: -0.0000\n",
            "Epoch [893/1000], Step [5/8], d_loss: 6754.2026, g_loss: -0.0000\n",
            "Epoch [893/1000], Step [6/8], d_loss: 20872.4375, g_loss: -0.0000\n",
            "Epoch [893/1000], Step [7/8], d_loss: 11.1302, g_loss: -0.0000\n",
            "Epoch [893/1000], Step [8/8], d_loss: 8.9674, g_loss: -0.0000\n",
            "Epoch [894/1000], Step [1/8], d_loss: 13.8784, g_loss: -0.0000\n",
            "Epoch [894/1000], Step [2/8], d_loss: 193.2123, g_loss: -0.0000\n",
            "Epoch [894/1000], Step [3/8], d_loss: 8.7898, g_loss: -0.0000\n",
            "Epoch [894/1000], Step [4/8], d_loss: 587.1860, g_loss: -0.0000\n",
            "Epoch [894/1000], Step [5/8], d_loss: 8.7113, g_loss: -0.0000\n",
            "Epoch [894/1000], Step [6/8], d_loss: 16334.9258, g_loss: -0.0000\n",
            "Epoch [894/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [894/1000], Step [8/8], d_loss: 8.5746, g_loss: -0.0000\n",
            "Epoch [895/1000], Step [1/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [895/1000], Step [2/8], d_loss: 18697.0684, g_loss: -0.0000\n",
            "Epoch [895/1000], Step [3/8], d_loss: 1397.2961, g_loss: -0.0000\n",
            "Epoch [895/1000], Step [4/8], d_loss: 9.0076, g_loss: -0.0000\n",
            "Epoch [895/1000], Step [5/8], d_loss: 8.9270, g_loss: -0.0000\n",
            "Epoch [895/1000], Step [6/8], d_loss: 7108.2715, g_loss: -0.0000\n",
            "Epoch [895/1000], Step [7/8], d_loss: 8.9979, g_loss: -0.0000\n",
            "Epoch [895/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [896/1000], Step [1/8], d_loss: 8.8384, g_loss: -0.0000\n",
            "Epoch [896/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [896/1000], Step [3/8], d_loss: 8.9976, g_loss: -0.0007\n",
            "Epoch [896/1000], Step [4/8], d_loss: 8.9952, g_loss: -0.0000\n",
            "Epoch [896/1000], Step [5/8], d_loss: 8.9689, g_loss: -0.0312\n",
            "Epoch [896/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0457\n",
            "Epoch [896/1000], Step [7/8], d_loss: 3954.8269, g_loss: -0.0000\n",
            "Epoch [896/1000], Step [8/8], d_loss: 140.5909, g_loss: -0.0000\n",
            "Epoch [897/1000], Step [1/8], d_loss: 599.6884, g_loss: -0.0000\n",
            "Epoch [897/1000], Step [2/8], d_loss: 8.9131, g_loss: -0.0312\n",
            "Epoch [897/1000], Step [3/8], d_loss: 21429.6738, g_loss: -0.0000\n",
            "Epoch [897/1000], Step [4/8], d_loss: 177.1298, g_loss: -0.0000\n",
            "Epoch [897/1000], Step [5/8], d_loss: 8.9641, g_loss: -0.0000\n",
            "Epoch [897/1000], Step [6/8], d_loss: 11.6863, g_loss: -0.0006\n",
            "Epoch [897/1000], Step [7/8], d_loss: 8.9961, g_loss: -0.0000\n",
            "Epoch [897/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [898/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [898/1000], Step [2/8], d_loss: 16680.8984, g_loss: -0.0000\n",
            "Epoch [898/1000], Step [3/8], d_loss: 144.2853, g_loss: -0.0000\n",
            "Epoch [898/1000], Step [4/8], d_loss: 704.1169, g_loss: -0.0000\n",
            "Epoch [898/1000], Step [5/8], d_loss: 9.6962, g_loss: -0.0000\n",
            "Epoch [898/1000], Step [6/8], d_loss: 1105.4623, g_loss: -0.0000\n",
            "Epoch [898/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [898/1000], Step [8/8], d_loss: 9.0435, g_loss: -0.0000\n",
            "Epoch [899/1000], Step [1/8], d_loss: 1019.1273, g_loss: -0.0000\n",
            "Epoch [899/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0002\n",
            "Epoch [899/1000], Step [3/8], d_loss: 8.9847, g_loss: -0.0000\n",
            "Epoch [899/1000], Step [4/8], d_loss: 269.5305, g_loss: -0.0000\n",
            "Epoch [899/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [899/1000], Step [6/8], d_loss: 694.5023, g_loss: -0.0000\n",
            "Epoch [899/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [899/1000], Step [8/8], d_loss: 9.0435, g_loss: -0.0000\n",
            "Epoch [900/1000], Step [1/8], d_loss: 40.7448, g_loss: -0.0000\n",
            "Epoch [900/1000], Step [2/8], d_loss: 9.0025, g_loss: -0.0000\n",
            "Epoch [900/1000], Step [3/8], d_loss: 39.3751, g_loss: -0.0000\n",
            "Epoch [900/1000], Step [4/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [900/1000], Step [5/8], d_loss: 13884.2979, g_loss: -0.0000\n",
            "Epoch [900/1000], Step [6/8], d_loss: 8.9800, g_loss: -0.0000\n",
            "Epoch [900/1000], Step [7/8], d_loss: 184.2212, g_loss: -0.0000\n",
            "Epoch [900/1000], Step [8/8], d_loss: 5469.4390, g_loss: -0.0000\n",
            "Epoch [901/1000], Step [1/8], d_loss: 9.0297, g_loss: -0.0000\n",
            "Epoch [901/1000], Step [2/8], d_loss: 9.3796, g_loss: -0.0000\n",
            "Epoch [901/1000], Step [3/8], d_loss: 178.6302, g_loss: -0.0000\n",
            "Epoch [901/1000], Step [4/8], d_loss: 8.7207, g_loss: -0.0000\n",
            "Epoch [901/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [901/1000], Step [6/8], d_loss: 13.4330, g_loss: -0.0000\n",
            "Epoch [901/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [901/1000], Step [8/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [902/1000], Step [1/8], d_loss: 9.0004, g_loss: -0.0000\n",
            "Epoch [902/1000], Step [2/8], d_loss: 8.8148, g_loss: -0.0000\n",
            "Epoch [902/1000], Step [3/8], d_loss: 11.5758, g_loss: -0.0000\n",
            "Epoch [902/1000], Step [4/8], d_loss: 8.9845, g_loss: -0.0000\n",
            "Epoch [902/1000], Step [5/8], d_loss: 8.8072, g_loss: -0.0313\n",
            "Epoch [902/1000], Step [6/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [902/1000], Step [7/8], d_loss: 924.4833, g_loss: -0.0000\n",
            "Epoch [902/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [903/1000], Step [1/8], d_loss: 826.3776, g_loss: -0.0000\n",
            "Epoch [903/1000], Step [2/8], d_loss: 8.9932, g_loss: -0.0000\n",
            "Epoch [903/1000], Step [3/8], d_loss: 8.9995, g_loss: -0.0001\n",
            "Epoch [903/1000], Step [4/8], d_loss: 8.8939, g_loss: -0.0000\n",
            "Epoch [903/1000], Step [5/8], d_loss: 13692.0566, g_loss: -0.0000\n",
            "Epoch [903/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [903/1000], Step [7/8], d_loss: 9.0021, g_loss: -0.0000\n",
            "Epoch [903/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [904/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [904/1000], Step [2/8], d_loss: 8.7798, g_loss: -0.0000\n",
            "Epoch [904/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [904/1000], Step [4/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [904/1000], Step [5/8], d_loss: 5648.4092, g_loss: -0.0000\n",
            "Epoch [904/1000], Step [6/8], d_loss: 16917.3184, g_loss: -0.0000\n",
            "Epoch [904/1000], Step [7/8], d_loss: 8.9173, g_loss: -0.0000\n",
            "Epoch [904/1000], Step [8/8], d_loss: 8.9067, g_loss: -0.0000\n",
            "Epoch [905/1000], Step [1/8], d_loss: 8.8019, g_loss: -0.0000\n",
            "Epoch [905/1000], Step [2/8], d_loss: 8.6924, g_loss: -0.0000\n",
            "Epoch [905/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [905/1000], Step [4/8], d_loss: 6015.9658, g_loss: -0.0000\n",
            "Epoch [905/1000], Step [5/8], d_loss: 9.3928, g_loss: -0.0000\n",
            "Epoch [905/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [905/1000], Step [7/8], d_loss: 404.3139, g_loss: -0.0000\n",
            "Epoch [905/1000], Step [8/8], d_loss: 8.9815, g_loss: -0.0000\n",
            "Epoch [906/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [906/1000], Step [2/8], d_loss: 8.8864, g_loss: -0.0000\n",
            "Epoch [906/1000], Step [3/8], d_loss: 841.2073, g_loss: -0.0000\n",
            "Epoch [906/1000], Step [4/8], d_loss: 8.9333, g_loss: -0.0312\n",
            "Epoch [906/1000], Step [5/8], d_loss: 26.7145, g_loss: -0.0000\n",
            "Epoch [906/1000], Step [6/8], d_loss: 8.9625, g_loss: -0.0000\n",
            "Epoch [906/1000], Step [7/8], d_loss: 690.8342, g_loss: -0.0000\n",
            "Epoch [906/1000], Step [8/8], d_loss: 11075.5947, g_loss: -0.0000\n",
            "Epoch [907/1000], Step [1/8], d_loss: 2299.6743, g_loss: -0.0000\n",
            "Epoch [907/1000], Step [2/8], d_loss: 9.0311, g_loss: -0.0000\n",
            "Epoch [907/1000], Step [3/8], d_loss: 43.0734, g_loss: -0.0000\n",
            "Epoch [907/1000], Step [4/8], d_loss: 37680.8203, g_loss: -0.0000\n",
            "Epoch [907/1000], Step [5/8], d_loss: 524.5104, g_loss: -0.0000\n",
            "Epoch [907/1000], Step [6/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [907/1000], Step [7/8], d_loss: 37.6929, g_loss: -0.0000\n",
            "Epoch [907/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [908/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [908/1000], Step [2/8], d_loss: 23.2565, g_loss: -0.0000\n",
            "Epoch [908/1000], Step [3/8], d_loss: 8.7571, g_loss: -0.0000\n",
            "Epoch [908/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [908/1000], Step [5/8], d_loss: 9.0034, g_loss: -0.0000\n",
            "Epoch [908/1000], Step [6/8], d_loss: 33.5422, g_loss: -0.0000\n",
            "Epoch [908/1000], Step [7/8], d_loss: 9.0312, g_loss: -0.0312\n",
            "Epoch [908/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [909/1000], Step [1/8], d_loss: 2366.9329, g_loss: -0.0303\n",
            "Epoch [909/1000], Step [2/8], d_loss: 13.4955, g_loss: -0.0256\n",
            "Epoch [909/1000], Step [3/8], d_loss: 8.9664, g_loss: -0.0000\n",
            "Epoch [909/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0312\n",
            "Epoch [909/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [909/1000], Step [6/8], d_loss: 9.0313, g_loss: -0.0000\n",
            "Epoch [909/1000], Step [7/8], d_loss: 9.0300, g_loss: -0.0022\n",
            "Epoch [909/1000], Step [8/8], d_loss: 8.5993, g_loss: -0.0000\n",
            "Epoch [910/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0312\n",
            "Epoch [910/1000], Step [2/8], d_loss: 9.0303, g_loss: -0.0000\n",
            "Epoch [910/1000], Step [3/8], d_loss: 5948.7969, g_loss: -0.0000\n",
            "Epoch [910/1000], Step [4/8], d_loss: 9.3896, g_loss: -0.0000\n",
            "Epoch [910/1000], Step [5/8], d_loss: 9275.9668, g_loss: -0.0000\n",
            "Epoch [910/1000], Step [6/8], d_loss: 50.8007, g_loss: -0.0000\n",
            "Epoch [910/1000], Step [7/8], d_loss: 8286.3916, g_loss: -0.0000\n",
            "Epoch [910/1000], Step [8/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [911/1000], Step [1/8], d_loss: 8.9854, g_loss: -0.0312\n",
            "Epoch [911/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [911/1000], Step [3/8], d_loss: 8.9997, g_loss: -0.0305\n",
            "Epoch [911/1000], Step [4/8], d_loss: 8.9445, g_loss: -0.0000\n",
            "Epoch [911/1000], Step [5/8], d_loss: 8.6725, g_loss: -0.0000\n",
            "Epoch [911/1000], Step [6/8], d_loss: 10.5101, g_loss: -0.0000\n",
            "Epoch [911/1000], Step [7/8], d_loss: 7970.5708, g_loss: -0.0000\n",
            "Epoch [911/1000], Step [8/8], d_loss: 8.7800, g_loss: -0.0434\n",
            "Epoch [912/1000], Step [1/8], d_loss: 8.9529, g_loss: -0.0000\n",
            "Epoch [912/1000], Step [2/8], d_loss: 5661.3164, g_loss: -0.0000\n",
            "Epoch [912/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [912/1000], Step [4/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [912/1000], Step [5/8], d_loss: 8117.2915, g_loss: -0.0000\n",
            "Epoch [912/1000], Step [6/8], d_loss: 8.9982, g_loss: -0.0000\n",
            "Epoch [912/1000], Step [7/8], d_loss: 80.4846, g_loss: -0.0000\n",
            "Epoch [912/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0063\n",
            "Epoch [913/1000], Step [1/8], d_loss: 8.7905, g_loss: -0.0625\n",
            "Epoch [913/1000], Step [2/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [913/1000], Step [3/8], d_loss: 8998.3057, g_loss: -0.0000\n",
            "Epoch [913/1000], Step [4/8], d_loss: 5159.9023, g_loss: -0.0000\n",
            "Epoch [913/1000], Step [5/8], d_loss: 8.9899, g_loss: -0.0000\n",
            "Epoch [913/1000], Step [6/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [913/1000], Step [7/8], d_loss: 9.0625, g_loss: -0.0000\n",
            "Epoch [913/1000], Step [8/8], d_loss: 9.0328, g_loss: -0.0000\n",
            "Epoch [914/1000], Step [1/8], d_loss: 9.0071, g_loss: -0.0000\n",
            "Epoch [914/1000], Step [2/8], d_loss: 5158.0215, g_loss: -0.0000\n",
            "Epoch [914/1000], Step [3/8], d_loss: 9.0625, g_loss: -0.0000\n",
            "Epoch [914/1000], Step [4/8], d_loss: 9.0367, g_loss: -0.0000\n",
            "Epoch [914/1000], Step [5/8], d_loss: 9.0625, g_loss: -0.0000\n",
            "Epoch [914/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [914/1000], Step [7/8], d_loss: 8.7983, g_loss: -0.0000\n",
            "Epoch [914/1000], Step [8/8], d_loss: 8.9959, g_loss: -0.0000\n",
            "Epoch [915/1000], Step [1/8], d_loss: 8.8867, g_loss: -0.0000\n",
            "Epoch [915/1000], Step [2/8], d_loss: 8.9828, g_loss: -0.0000\n",
            "Epoch [915/1000], Step [3/8], d_loss: 9.0297, g_loss: -0.0000\n",
            "Epoch [915/1000], Step [4/8], d_loss: 8.8679, g_loss: -0.0000\n",
            "Epoch [915/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [915/1000], Step [6/8], d_loss: 5155.5908, g_loss: -0.0000\n",
            "Epoch [915/1000], Step [7/8], d_loss: 12897.8623, g_loss: -0.0000\n",
            "Epoch [915/1000], Step [8/8], d_loss: 9.0435, g_loss: -0.0000\n",
            "Epoch [916/1000], Step [1/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [916/1000], Step [2/8], d_loss: 9.0310, g_loss: -0.0000\n",
            "Epoch [916/1000], Step [3/8], d_loss: 2911.2905, g_loss: -0.0000\n",
            "Epoch [916/1000], Step [4/8], d_loss: 9.0815, g_loss: -0.0000\n",
            "Epoch [916/1000], Step [5/8], d_loss: 10.4856, g_loss: -0.0000\n",
            "Epoch [916/1000], Step [6/8], d_loss: 8.9943, g_loss: -0.0000\n",
            "Epoch [916/1000], Step [7/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [916/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [917/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [917/1000], Step [2/8], d_loss: 8.6972, g_loss: -0.0000\n",
            "Epoch [917/1000], Step [3/8], d_loss: 9.0938, g_loss: -0.0000\n",
            "Epoch [917/1000], Step [4/8], d_loss: 9.0938, g_loss: -0.0000\n",
            "Epoch [917/1000], Step [5/8], d_loss: 1264.6860, g_loss: -0.0000\n",
            "Epoch [917/1000], Step [6/8], d_loss: 59.7115, g_loss: -0.0000\n",
            "Epoch [917/1000], Step [7/8], d_loss: 9.0624, g_loss: -0.0000\n",
            "Epoch [917/1000], Step [8/8], d_loss: 8.6820, g_loss: -0.0000\n",
            "Epoch [918/1000], Step [1/8], d_loss: 9.0261, g_loss: -0.0000\n",
            "Epoch [918/1000], Step [2/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [918/1000], Step [3/8], d_loss: 43.4381, g_loss: -0.0000\n",
            "Epoch [918/1000], Step [4/8], d_loss: 245.0651, g_loss: -0.0000\n",
            "Epoch [918/1000], Step [5/8], d_loss: 9.0581, g_loss: -0.0000\n",
            "Epoch [918/1000], Step [6/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [918/1000], Step [7/8], d_loss: 8.9943, g_loss: -0.0000\n",
            "Epoch [918/1000], Step [8/8], d_loss: 8.7584, g_loss: -0.0431\n",
            "Epoch [919/1000], Step [1/8], d_loss: 9.0439, g_loss: -0.0081\n",
            "Epoch [919/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [919/1000], Step [3/8], d_loss: 9.0520, g_loss: -0.0000\n",
            "Epoch [919/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [919/1000], Step [5/8], d_loss: 8.7898, g_loss: -0.0000\n",
            "Epoch [919/1000], Step [6/8], d_loss: 8.8753, g_loss: -0.0003\n",
            "Epoch [919/1000], Step [7/8], d_loss: 4373.1284, g_loss: -0.0348\n",
            "Epoch [919/1000], Step [8/8], d_loss: 5304.0122, g_loss: -0.0000\n",
            "Epoch [920/1000], Step [1/8], d_loss: 94.4812, g_loss: -0.0000\n",
            "Epoch [920/1000], Step [2/8], d_loss: 38.4547, g_loss: -0.0000\n",
            "Epoch [920/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [920/1000], Step [4/8], d_loss: 9.0302, g_loss: -0.0000\n",
            "Epoch [920/1000], Step [5/8], d_loss: 1931.0208, g_loss: -0.0000\n",
            "Epoch [920/1000], Step [6/8], d_loss: 9.0625, g_loss: -0.0000\n",
            "Epoch [920/1000], Step [7/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [920/1000], Step [8/8], d_loss: 5468.3062, g_loss: -0.0000\n",
            "Epoch [921/1000], Step [1/8], d_loss: 8.9941, g_loss: -0.0000\n",
            "Epoch [921/1000], Step [2/8], d_loss: 14153.6045, g_loss: -0.0000\n",
            "Epoch [921/1000], Step [3/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [921/1000], Step [4/8], d_loss: 5788.1016, g_loss: -0.0000\n",
            "Epoch [921/1000], Step [5/8], d_loss: 39.7068, g_loss: -0.0301\n",
            "Epoch [921/1000], Step [6/8], d_loss: 9.1327, g_loss: -0.0000\n",
            "Epoch [921/1000], Step [7/8], d_loss: 125.2295, g_loss: -0.0000\n",
            "Epoch [921/1000], Step [8/8], d_loss: 9.0435, g_loss: -0.0000\n",
            "Epoch [922/1000], Step [1/8], d_loss: 8.9920, g_loss: -0.0041\n",
            "Epoch [922/1000], Step [2/8], d_loss: 8.9416, g_loss: -0.0313\n",
            "Epoch [922/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0311\n",
            "Epoch [922/1000], Step [4/8], d_loss: 8.6865, g_loss: -0.0084\n",
            "Epoch [922/1000], Step [5/8], d_loss: 9.0005, g_loss: -0.0008\n",
            "Epoch [922/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [922/1000], Step [7/8], d_loss: 8.8048, g_loss: -0.0000\n",
            "Epoch [922/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0435\n",
            "Epoch [923/1000], Step [1/8], d_loss: 8380.0312, g_loss: -0.0000\n",
            "Epoch [923/1000], Step [2/8], d_loss: 117.3186, g_loss: -0.0000\n",
            "Epoch [923/1000], Step [3/8], d_loss: 8.9143, g_loss: -0.0001\n",
            "Epoch [923/1000], Step [4/8], d_loss: 7733.2939, g_loss: -0.0002\n",
            "Epoch [923/1000], Step [5/8], d_loss: 9.0152, g_loss: -0.0000\n",
            "Epoch [923/1000], Step [6/8], d_loss: 113.0655, g_loss: -0.0118\n",
            "Epoch [923/1000], Step [7/8], d_loss: 30.9892, g_loss: -0.0624\n",
            "Epoch [923/1000], Step [8/8], d_loss: 32.1882, g_loss: -0.0000\n",
            "Epoch [924/1000], Step [1/8], d_loss: 1577.7417, g_loss: -0.0000\n",
            "Epoch [924/1000], Step [2/8], d_loss: 9.0011, g_loss: -0.0000\n",
            "Epoch [924/1000], Step [3/8], d_loss: 8.9885, g_loss: -0.0190\n",
            "Epoch [924/1000], Step [4/8], d_loss: 8.8111, g_loss: -0.0000\n",
            "Epoch [924/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [924/1000], Step [6/8], d_loss: 203.0282, g_loss: -0.0000\n",
            "Epoch [924/1000], Step [7/8], d_loss: 8.9928, g_loss: -0.0002\n",
            "Epoch [924/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [925/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [925/1000], Step [2/8], d_loss: 9.1240, g_loss: -0.0000\n",
            "Epoch [925/1000], Step [3/8], d_loss: 6598.0747, g_loss: -0.0000\n",
            "Epoch [925/1000], Step [4/8], d_loss: 3857.2759, g_loss: -0.0000\n",
            "Epoch [925/1000], Step [5/8], d_loss: 8318.8809, g_loss: -0.0000\n",
            "Epoch [925/1000], Step [6/8], d_loss: 9.0053, g_loss: -0.0312\n",
            "Epoch [925/1000], Step [7/8], d_loss: 12.7383, g_loss: -0.0307\n",
            "Epoch [925/1000], Step [8/8], d_loss: 7073.8096, g_loss: -0.0000\n",
            "Epoch [926/1000], Step [1/8], d_loss: 842.7119, g_loss: -0.0000\n",
            "Epoch [926/1000], Step [2/8], d_loss: 773.1644, g_loss: -0.0000\n",
            "Epoch [926/1000], Step [3/8], d_loss: 122.6200, g_loss: -0.0000\n",
            "Epoch [926/1000], Step [4/8], d_loss: 124.9752, g_loss: -0.0000\n",
            "Epoch [926/1000], Step [5/8], d_loss: 12.5960, g_loss: -0.0000\n",
            "Epoch [926/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0009\n",
            "Epoch [926/1000], Step [7/8], d_loss: 910.9180, g_loss: -0.0000\n",
            "Epoch [926/1000], Step [8/8], d_loss: 123.1988, g_loss: -0.0000\n",
            "Epoch [927/1000], Step [1/8], d_loss: 8.8751, g_loss: -0.0000\n",
            "Epoch [927/1000], Step [2/8], d_loss: 148.7381, g_loss: -0.0000\n",
            "Epoch [927/1000], Step [3/8], d_loss: 18.2252, g_loss: -0.0000\n",
            "Epoch [927/1000], Step [4/8], d_loss: 19406.5312, g_loss: -0.0000\n",
            "Epoch [927/1000], Step [5/8], d_loss: 8.8944, g_loss: -0.0000\n",
            "Epoch [927/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [927/1000], Step [7/8], d_loss: 8.8954, g_loss: -0.0000\n",
            "Epoch [927/1000], Step [8/8], d_loss: 10.4793, g_loss: -0.0000\n",
            "Epoch [928/1000], Step [1/8], d_loss: 8.9988, g_loss: -0.0000\n",
            "Epoch [928/1000], Step [2/8], d_loss: 5675.5601, g_loss: -0.0000\n",
            "Epoch [928/1000], Step [3/8], d_loss: 9.0598, g_loss: -0.0000\n",
            "Epoch [928/1000], Step [4/8], d_loss: 9.5907, g_loss: -0.0000\n",
            "Epoch [928/1000], Step [5/8], d_loss: 8.9573, g_loss: -0.0000\n",
            "Epoch [928/1000], Step [6/8], d_loss: 8.6820, g_loss: -0.0000\n",
            "Epoch [928/1000], Step [7/8], d_loss: 9.0075, g_loss: -0.0312\n",
            "Epoch [928/1000], Step [8/8], d_loss: 10.7027, g_loss: -0.0000\n",
            "Epoch [929/1000], Step [1/8], d_loss: 8.9276, g_loss: -0.0000\n",
            "Epoch [929/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [929/1000], Step [3/8], d_loss: 8.9951, g_loss: -0.0000\n",
            "Epoch [929/1000], Step [4/8], d_loss: 8.9607, g_loss: -0.0000\n",
            "Epoch [929/1000], Step [5/8], d_loss: 17324.8770, g_loss: -0.0000\n",
            "Epoch [929/1000], Step [6/8], d_loss: 40066.3594, g_loss: -0.0000\n",
            "Epoch [929/1000], Step [7/8], d_loss: 83.7900, g_loss: -0.0311\n",
            "Epoch [929/1000], Step [8/8], d_loss: 8.9990, g_loss: -0.0000\n",
            "Epoch [930/1000], Step [1/8], d_loss: 13168.4668, g_loss: -0.0000\n",
            "Epoch [930/1000], Step [2/8], d_loss: 7692.8042, g_loss: -0.0000\n",
            "Epoch [930/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0349\n",
            "Epoch [930/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [930/1000], Step [5/8], d_loss: 107.4146, g_loss: -0.0000\n",
            "Epoch [930/1000], Step [6/8], d_loss: 8.7210, g_loss: -0.0000\n",
            "Epoch [930/1000], Step [7/8], d_loss: 2007.9608, g_loss: -0.0000\n",
            "Epoch [930/1000], Step [8/8], d_loss: 8.9926, g_loss: -0.0000\n",
            "Epoch [931/1000], Step [1/8], d_loss: 9.0032, g_loss: -0.0000\n",
            "Epoch [931/1000], Step [2/8], d_loss: 32.9667, g_loss: -0.0000\n",
            "Epoch [931/1000], Step [3/8], d_loss: 9.0381, g_loss: -0.0000\n",
            "Epoch [931/1000], Step [4/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [931/1000], Step [5/8], d_loss: 12594.4492, g_loss: -0.0000\n",
            "Epoch [931/1000], Step [6/8], d_loss: 8.9988, g_loss: -0.0000\n",
            "Epoch [931/1000], Step [7/8], d_loss: 12218.7852, g_loss: -0.0000\n",
            "Epoch [931/1000], Step [8/8], d_loss: 8.9694, g_loss: -0.0000\n",
            "Epoch [932/1000], Step [1/8], d_loss: 905.2791, g_loss: -0.0000\n",
            "Epoch [932/1000], Step [2/8], d_loss: 5035.1260, g_loss: -0.0000\n",
            "Epoch [932/1000], Step [3/8], d_loss: 7848.3359, g_loss: -0.0000\n",
            "Epoch [932/1000], Step [4/8], d_loss: 9.0312, g_loss: -0.0180\n",
            "Epoch [932/1000], Step [5/8], d_loss: 8.9975, g_loss: -0.0000\n",
            "Epoch [932/1000], Step [6/8], d_loss: 2319.0774, g_loss: -0.0000\n",
            "Epoch [932/1000], Step [7/8], d_loss: 90.8417, g_loss: -0.0000\n",
            "Epoch [932/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [933/1000], Step [1/8], d_loss: 14.8148, g_loss: -0.0000\n",
            "Epoch [933/1000], Step [2/8], d_loss: 124.5780, g_loss: -0.0000\n",
            "Epoch [933/1000], Step [3/8], d_loss: 26.2755, g_loss: -0.0000\n",
            "Epoch [933/1000], Step [4/8], d_loss: 8.9857, g_loss: -0.0311\n",
            "Epoch [933/1000], Step [5/8], d_loss: 8.9958, g_loss: -0.0311\n",
            "Epoch [933/1000], Step [6/8], d_loss: 5661.8325, g_loss: -0.0000\n",
            "Epoch [933/1000], Step [7/8], d_loss: 1234.4807, g_loss: -0.0313\n",
            "Epoch [933/1000], Step [8/8], d_loss: 3470.0112, g_loss: -0.0001\n",
            "Epoch [934/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [934/1000], Step [2/8], d_loss: 8.9875, g_loss: -0.0000\n",
            "Epoch [934/1000], Step [3/8], d_loss: 6557.0527, g_loss: -0.0000\n",
            "Epoch [934/1000], Step [4/8], d_loss: 9.0506, g_loss: -0.0000\n",
            "Epoch [934/1000], Step [5/8], d_loss: 8.8644, g_loss: -0.0031\n",
            "Epoch [934/1000], Step [6/8], d_loss: 2199.2561, g_loss: -0.0000\n",
            "Epoch [934/1000], Step [7/8], d_loss: 11184.8848, g_loss: -0.0000\n",
            "Epoch [934/1000], Step [8/8], d_loss: 79.8079, g_loss: -0.0002\n",
            "Epoch [935/1000], Step [1/8], d_loss: 9.0627, g_loss: -0.0127\n",
            "Epoch [935/1000], Step [2/8], d_loss: 8.9991, g_loss: -0.0000\n",
            "Epoch [935/1000], Step [3/8], d_loss: 1589.0662, g_loss: -0.0267\n",
            "Epoch [935/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [935/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [935/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0126\n",
            "Epoch [935/1000], Step [7/8], d_loss: 9.0313, g_loss: -0.0000\n",
            "Epoch [935/1000], Step [8/8], d_loss: 8.9673, g_loss: -0.0000\n",
            "Epoch [936/1000], Step [1/8], d_loss: 8.7781, g_loss: -0.0000\n",
            "Epoch [936/1000], Step [2/8], d_loss: 9.0248, g_loss: -0.0000\n",
            "Epoch [936/1000], Step [3/8], d_loss: 8.8879, g_loss: -0.0000\n",
            "Epoch [936/1000], Step [4/8], d_loss: 9.1015, g_loss: -0.0000\n",
            "Epoch [936/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0002\n",
            "Epoch [936/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [936/1000], Step [7/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [936/1000], Step [8/8], d_loss: 224.5571, g_loss: -0.0000\n",
            "Epoch [937/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [937/1000], Step [2/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [937/1000], Step [3/8], d_loss: 5291.6143, g_loss: -0.0000\n",
            "Epoch [937/1000], Step [4/8], d_loss: 18.3141, g_loss: -0.0000\n",
            "Epoch [937/1000], Step [5/8], d_loss: 271.0019, g_loss: -0.0000\n",
            "Epoch [937/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [937/1000], Step [7/8], d_loss: 8.9999, g_loss: -0.0003\n",
            "Epoch [937/1000], Step [8/8], d_loss: 397.2807, g_loss: -0.0000\n",
            "Epoch [938/1000], Step [1/8], d_loss: 9.0312, g_loss: -0.0293\n",
            "Epoch [938/1000], Step [2/8], d_loss: 8.9513, g_loss: -0.0000\n",
            "Epoch [938/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0311\n",
            "Epoch [938/1000], Step [4/8], d_loss: 8.9979, g_loss: -0.0000\n",
            "Epoch [938/1000], Step [5/8], d_loss: 8.9991, g_loss: -0.0153\n",
            "Epoch [938/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [938/1000], Step [7/8], d_loss: 1705.9958, g_loss: -0.0000\n",
            "Epoch [938/1000], Step [8/8], d_loss: 9.0111, g_loss: -0.0000\n",
            "Epoch [939/1000], Step [1/8], d_loss: 8.8379, g_loss: -0.0000\n",
            "Epoch [939/1000], Step [2/8], d_loss: 8.9986, g_loss: -0.0312\n",
            "Epoch [939/1000], Step [3/8], d_loss: 8.5809, g_loss: -0.0000\n",
            "Epoch [939/1000], Step [4/8], d_loss: 56.3009, g_loss: -0.0000\n",
            "Epoch [939/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [939/1000], Step [6/8], d_loss: 8.9611, g_loss: -0.0001\n",
            "Epoch [939/1000], Step [7/8], d_loss: 9.0310, g_loss: -0.0000\n",
            "Epoch [939/1000], Step [8/8], d_loss: 9.0868, g_loss: -0.0000\n",
            "Epoch [940/1000], Step [1/8], d_loss: 8.9837, g_loss: -0.0000\n",
            "Epoch [940/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [940/1000], Step [3/8], d_loss: 8.7698, g_loss: -0.0000\n",
            "Epoch [940/1000], Step [4/8], d_loss: 9.0952, g_loss: -0.0000\n",
            "Epoch [940/1000], Step [5/8], d_loss: 12451.0811, g_loss: -0.0000\n",
            "Epoch [940/1000], Step [6/8], d_loss: 184.1151, g_loss: -0.0000\n",
            "Epoch [940/1000], Step [7/8], d_loss: 195.1792, g_loss: -0.0000\n",
            "Epoch [940/1000], Step [8/8], d_loss: 22806.9316, g_loss: -0.0000\n",
            "Epoch [941/1000], Step [1/8], d_loss: 9.0312, g_loss: -0.0061\n",
            "Epoch [941/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [941/1000], Step [3/8], d_loss: 23.1609, g_loss: -0.0000\n",
            "Epoch [941/1000], Step [4/8], d_loss: 11.3267, g_loss: -0.0000\n",
            "Epoch [941/1000], Step [5/8], d_loss: 18.0627, g_loss: -0.0000\n",
            "Epoch [941/1000], Step [6/8], d_loss: 9.0615, g_loss: -0.0000\n",
            "Epoch [941/1000], Step [7/8], d_loss: 8.8331, g_loss: -0.0000\n",
            "Epoch [941/1000], Step [8/8], d_loss: 4549.9409, g_loss: -0.0000\n",
            "Epoch [942/1000], Step [1/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [942/1000], Step [2/8], d_loss: 8.9421, g_loss: -0.0000\n",
            "Epoch [942/1000], Step [3/8], d_loss: 14.3238, g_loss: -0.0000\n",
            "Epoch [942/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [942/1000], Step [5/8], d_loss: 27387.3906, g_loss: -0.0000\n",
            "Epoch [942/1000], Step [6/8], d_loss: 1874.5812, g_loss: -0.0000\n",
            "Epoch [942/1000], Step [7/8], d_loss: 8.9838, g_loss: -0.0000\n",
            "Epoch [942/1000], Step [8/8], d_loss: 3258.9268, g_loss: -0.0000\n",
            "Epoch [943/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0008\n",
            "Epoch [943/1000], Step [2/8], d_loss: 8.8870, g_loss: -0.0000\n",
            "Epoch [943/1000], Step [3/8], d_loss: 8.5876, g_loss: -0.0000\n",
            "Epoch [943/1000], Step [4/8], d_loss: 8.9995, g_loss: -0.0000\n",
            "Epoch [943/1000], Step [5/8], d_loss: 8.9645, g_loss: -0.0000\n",
            "Epoch [943/1000], Step [6/8], d_loss: 3313.0144, g_loss: -0.0000\n",
            "Epoch [943/1000], Step [7/8], d_loss: 13.6765, g_loss: -0.0003\n",
            "Epoch [943/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [944/1000], Step [1/8], d_loss: 9.0125, g_loss: -0.0000\n",
            "Epoch [944/1000], Step [2/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [944/1000], Step [3/8], d_loss: 2150.7407, g_loss: -0.0127\n",
            "Epoch [944/1000], Step [4/8], d_loss: 8.9933, g_loss: -0.0002\n",
            "Epoch [944/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [944/1000], Step [6/8], d_loss: 9.0625, g_loss: -0.0000\n",
            "Epoch [944/1000], Step [7/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [944/1000], Step [8/8], d_loss: 8.9879, g_loss: -0.0000\n",
            "Epoch [945/1000], Step [1/8], d_loss: 9.0327, g_loss: -0.0000\n",
            "Epoch [945/1000], Step [2/8], d_loss: 750.6013, g_loss: -0.0006\n",
            "Epoch [945/1000], Step [3/8], d_loss: 1393.0302, g_loss: -0.0000\n",
            "Epoch [945/1000], Step [4/8], d_loss: 8.7976, g_loss: -0.0000\n",
            "Epoch [945/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [945/1000], Step [6/8], d_loss: 1415.8279, g_loss: -0.0000\n",
            "Epoch [945/1000], Step [7/8], d_loss: 8.8123, g_loss: -0.0000\n",
            "Epoch [945/1000], Step [8/8], d_loss: 9083.9209, g_loss: -0.0000\n",
            "Epoch [946/1000], Step [1/8], d_loss: 8.6539, g_loss: -0.0000\n",
            "Epoch [946/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [946/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [946/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [946/1000], Step [5/8], d_loss: 8.6862, g_loss: -0.0000\n",
            "Epoch [946/1000], Step [6/8], d_loss: 8.9999, g_loss: -0.0312\n",
            "Epoch [946/1000], Step [7/8], d_loss: 8.7476, g_loss: -0.0312\n",
            "Epoch [946/1000], Step [8/8], d_loss: 9.0103, g_loss: -0.0000\n",
            "Epoch [947/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [947/1000], Step [2/8], d_loss: 4879.5415, g_loss: -0.0000\n",
            "Epoch [947/1000], Step [3/8], d_loss: 10.0158, g_loss: -0.0000\n",
            "Epoch [947/1000], Step [4/8], d_loss: 2333.9006, g_loss: -0.0000\n",
            "Epoch [947/1000], Step [5/8], d_loss: 9.0603, g_loss: -0.0000\n",
            "Epoch [947/1000], Step [6/8], d_loss: 6133.9067, g_loss: -0.0000\n",
            "Epoch [947/1000], Step [7/8], d_loss: 7644.5264, g_loss: -0.0000\n",
            "Epoch [947/1000], Step [8/8], d_loss: 9.0441, g_loss: -0.0000\n",
            "Epoch [948/1000], Step [1/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [948/1000], Step [2/8], d_loss: 8.9966, g_loss: -0.0000\n",
            "Epoch [948/1000], Step [3/8], d_loss: 2032.9911, g_loss: -0.0181\n",
            "Epoch [948/1000], Step [4/8], d_loss: 39.3474, g_loss: -0.0007\n",
            "Epoch [948/1000], Step [5/8], d_loss: 9.0001, g_loss: -0.0312\n",
            "Epoch [948/1000], Step [6/8], d_loss: 8.9990, g_loss: -0.0000\n",
            "Epoch [948/1000], Step [7/8], d_loss: 8.8381, g_loss: -0.0155\n",
            "Epoch [948/1000], Step [8/8], d_loss: 9.0222, g_loss: -0.0000\n",
            "Epoch [949/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [949/1000], Step [2/8], d_loss: 398.7794, g_loss: -0.0000\n",
            "Epoch [949/1000], Step [3/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [949/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [949/1000], Step [5/8], d_loss: 8.9858, g_loss: -0.0000\n",
            "Epoch [949/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [949/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [949/1000], Step [8/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [950/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [950/1000], Step [2/8], d_loss: 1103.8992, g_loss: -0.0000\n",
            "Epoch [950/1000], Step [3/8], d_loss: 15520.6123, g_loss: -0.0000\n",
            "Epoch [950/1000], Step [4/8], d_loss: 8.9744, g_loss: -0.0000\n",
            "Epoch [950/1000], Step [5/8], d_loss: 8.8306, g_loss: -0.0000\n",
            "Epoch [950/1000], Step [6/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [950/1000], Step [7/8], d_loss: 9.0144, g_loss: -0.0000\n",
            "Epoch [950/1000], Step [8/8], d_loss: 5434.7500, g_loss: -0.0000\n",
            "Epoch [951/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [951/1000], Step [2/8], d_loss: 8.9884, g_loss: -0.0000\n",
            "Epoch [951/1000], Step [3/8], d_loss: 12103.8623, g_loss: -0.0000\n",
            "Epoch [951/1000], Step [4/8], d_loss: 1279.1543, g_loss: -0.0000\n",
            "Epoch [951/1000], Step [5/8], d_loss: 179.8299, g_loss: -0.0000\n",
            "Epoch [951/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [951/1000], Step [7/8], d_loss: 8.7662, g_loss: -0.0000\n",
            "Epoch [951/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [952/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [952/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [952/1000], Step [3/8], d_loss: 2005.1035, g_loss: -0.0000\n",
            "Epoch [952/1000], Step [4/8], d_loss: 9.0312, g_loss: -0.0313\n",
            "Epoch [952/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [952/1000], Step [6/8], d_loss: 8.9768, g_loss: -0.0000\n",
            "Epoch [952/1000], Step [7/8], d_loss: 8.7869, g_loss: -0.0000\n",
            "Epoch [952/1000], Step [8/8], d_loss: 2688.8403, g_loss: -0.0000\n",
            "Epoch [953/1000], Step [1/8], d_loss: 8.4829, g_loss: -0.0000\n",
            "Epoch [953/1000], Step [2/8], d_loss: 1101.1028, g_loss: -0.0000\n",
            "Epoch [953/1000], Step [3/8], d_loss: 8.8634, g_loss: -0.0312\n",
            "Epoch [953/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [953/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [953/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [953/1000], Step [7/8], d_loss: 8.9994, g_loss: -0.0004\n",
            "Epoch [953/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [954/1000], Step [1/8], d_loss: 9.0015, g_loss: -0.0000\n",
            "Epoch [954/1000], Step [2/8], d_loss: 8.6532, g_loss: -0.0313\n",
            "Epoch [954/1000], Step [3/8], d_loss: 8.8183, g_loss: -0.0000\n",
            "Epoch [954/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [954/1000], Step [5/8], d_loss: 8.9774, g_loss: -0.0000\n",
            "Epoch [954/1000], Step [6/8], d_loss: 8.9751, g_loss: -0.0000\n",
            "Epoch [954/1000], Step [7/8], d_loss: 9.0312, g_loss: -0.0312\n",
            "Epoch [954/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0435\n",
            "Epoch [955/1000], Step [1/8], d_loss: 8.8694, g_loss: -0.0000\n",
            "Epoch [955/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [955/1000], Step [3/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [955/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0311\n",
            "Epoch [955/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0311\n",
            "Epoch [955/1000], Step [6/8], d_loss: 1972.7766, g_loss: -0.0000\n",
            "Epoch [955/1000], Step [7/8], d_loss: 8.9951, g_loss: -0.0000\n",
            "Epoch [955/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [956/1000], Step [1/8], d_loss: 39.4593, g_loss: -0.0312\n",
            "Epoch [956/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [956/1000], Step [3/8], d_loss: 8.9990, g_loss: -0.0000\n",
            "Epoch [956/1000], Step [4/8], d_loss: 21.6009, g_loss: -0.0000\n",
            "Epoch [956/1000], Step [5/8], d_loss: 30444.9648, g_loss: -0.0000\n",
            "Epoch [956/1000], Step [6/8], d_loss: 10555.1611, g_loss: -0.0000\n",
            "Epoch [956/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [956/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [957/1000], Step [1/8], d_loss: 8.8969, g_loss: -0.0000\n",
            "Epoch [957/1000], Step [2/8], d_loss: 8.9519, g_loss: -0.0312\n",
            "Epoch [957/1000], Step [3/8], d_loss: 8.8199, g_loss: -0.0000\n",
            "Epoch [957/1000], Step [4/8], d_loss: 13370.4688, g_loss: -0.0000\n",
            "Epoch [957/1000], Step [5/8], d_loss: 8.9921, g_loss: -0.0000\n",
            "Epoch [957/1000], Step [6/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [957/1000], Step [7/8], d_loss: 8.6860, g_loss: -0.0000\n",
            "Epoch [957/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [958/1000], Step [1/8], d_loss: 355.7817, g_loss: -0.0097\n",
            "Epoch [958/1000], Step [2/8], d_loss: 8.9968, g_loss: -0.0000\n",
            "Epoch [958/1000], Step [3/8], d_loss: 26.6195, g_loss: -0.0000\n",
            "Epoch [958/1000], Step [4/8], d_loss: 8.5429, g_loss: -0.0000\n",
            "Epoch [958/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [958/1000], Step [6/8], d_loss: 1727.1071, g_loss: -0.0000\n",
            "Epoch [958/1000], Step [7/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [958/1000], Step [8/8], d_loss: 8.5873, g_loss: -0.0000\n",
            "Epoch [959/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0307\n",
            "Epoch [959/1000], Step [2/8], d_loss: 8.9044, g_loss: -0.0000\n",
            "Epoch [959/1000], Step [3/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [959/1000], Step [4/8], d_loss: 64.7268, g_loss: -0.0000\n",
            "Epoch [959/1000], Step [5/8], d_loss: 8.9251, g_loss: -0.0051\n",
            "Epoch [959/1000], Step [6/8], d_loss: 8.6986, g_loss: -0.0000\n",
            "Epoch [959/1000], Step [7/8], d_loss: 9.0970, g_loss: -0.0007\n",
            "Epoch [959/1000], Step [8/8], d_loss: 228.2120, g_loss: -0.0000\n",
            "Epoch [960/1000], Step [1/8], d_loss: 8.9274, g_loss: -0.0000\n",
            "Epoch [960/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [960/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0001\n",
            "Epoch [960/1000], Step [4/8], d_loss: 8.9995, g_loss: -0.0000\n",
            "Epoch [960/1000], Step [5/8], d_loss: 9.7829, g_loss: -0.0000\n",
            "Epoch [960/1000], Step [6/8], d_loss: 9.8416, g_loss: -0.0000\n",
            "Epoch [960/1000], Step [7/8], d_loss: 8.9514, g_loss: -0.0000\n",
            "Epoch [960/1000], Step [8/8], d_loss: 8.6193, g_loss: -0.0000\n",
            "Epoch [961/1000], Step [1/8], d_loss: 9.0053, g_loss: -0.0004\n",
            "Epoch [961/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [961/1000], Step [3/8], d_loss: 212.1933, g_loss: -0.0001\n",
            "Epoch [961/1000], Step [4/8], d_loss: 1398.2336, g_loss: -0.0000\n",
            "Epoch [961/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [961/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [961/1000], Step [7/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [961/1000], Step [8/8], d_loss: 146.9850, g_loss: -0.0000\n",
            "Epoch [962/1000], Step [1/8], d_loss: 9.0007, g_loss: -0.0001\n",
            "Epoch [962/1000], Step [2/8], d_loss: 8.5819, g_loss: -0.0000\n",
            "Epoch [962/1000], Step [3/8], d_loss: 249.4168, g_loss: -0.0000\n",
            "Epoch [962/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [962/1000], Step [5/8], d_loss: 9.0370, g_loss: -0.0000\n",
            "Epoch [962/1000], Step [6/8], d_loss: 1316.7649, g_loss: -0.0000\n",
            "Epoch [962/1000], Step [7/8], d_loss: 3640.6516, g_loss: -0.0000\n",
            "Epoch [962/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0030\n",
            "Epoch [963/1000], Step [1/8], d_loss: 9.0218, g_loss: -0.0018\n",
            "Epoch [963/1000], Step [2/8], d_loss: 31.6354, g_loss: -0.0000\n",
            "Epoch [963/1000], Step [3/8], d_loss: 2198.5508, g_loss: -0.0000\n",
            "Epoch [963/1000], Step [4/8], d_loss: 9.0582, g_loss: -0.0000\n",
            "Epoch [963/1000], Step [5/8], d_loss: 8239.6826, g_loss: -0.0000\n",
            "Epoch [963/1000], Step [6/8], d_loss: 9.0227, g_loss: -0.0101\n",
            "Epoch [963/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [963/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0435\n",
            "Epoch [964/1000], Step [1/8], d_loss: 8.9908, g_loss: -0.0000\n",
            "Epoch [964/1000], Step [2/8], d_loss: 514.9507, g_loss: -0.0000\n",
            "Epoch [964/1000], Step [3/8], d_loss: 50.8624, g_loss: -0.0027\n",
            "Epoch [964/1000], Step [4/8], d_loss: 8.9988, g_loss: -0.0000\n",
            "Epoch [964/1000], Step [5/8], d_loss: 8.9617, g_loss: -0.0000\n",
            "Epoch [964/1000], Step [6/8], d_loss: 21094.5645, g_loss: -0.0000\n",
            "Epoch [964/1000], Step [7/8], d_loss: 8.9933, g_loss: -0.0000\n",
            "Epoch [964/1000], Step [8/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [965/1000], Step [1/8], d_loss: 8.9950, g_loss: -0.0000\n",
            "Epoch [965/1000], Step [2/8], d_loss: 3407.0789, g_loss: -0.0000\n",
            "Epoch [965/1000], Step [3/8], d_loss: 104.1395, g_loss: -0.0512\n",
            "Epoch [965/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0273\n",
            "Epoch [965/1000], Step [5/8], d_loss: 7282.1782, g_loss: -0.0000\n",
            "Epoch [965/1000], Step [6/8], d_loss: 8.9994, g_loss: -0.0312\n",
            "Epoch [965/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [965/1000], Step [8/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [966/1000], Step [1/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [966/1000], Step [2/8], d_loss: 8.8481, g_loss: -0.0000\n",
            "Epoch [966/1000], Step [3/8], d_loss: 10.2533, g_loss: -0.0000\n",
            "Epoch [966/1000], Step [4/8], d_loss: 8.9968, g_loss: -0.0000\n",
            "Epoch [966/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [966/1000], Step [6/8], d_loss: 13716.8828, g_loss: -0.0000\n",
            "Epoch [966/1000], Step [7/8], d_loss: 8.9998, g_loss: -0.0000\n",
            "Epoch [966/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [967/1000], Step [1/8], d_loss: 8.9722, g_loss: -0.0000\n",
            "Epoch [967/1000], Step [2/8], d_loss: 24553.7168, g_loss: -0.0000\n",
            "Epoch [967/1000], Step [3/8], d_loss: 8.9173, g_loss: -0.0000\n",
            "Epoch [967/1000], Step [4/8], d_loss: 9.0301, g_loss: -0.0000\n",
            "Epoch [967/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [967/1000], Step [6/8], d_loss: 8.8688, g_loss: -0.0000\n",
            "Epoch [967/1000], Step [7/8], d_loss: 8.9984, g_loss: -0.0000\n",
            "Epoch [967/1000], Step [8/8], d_loss: 6670.0742, g_loss: -0.0000\n",
            "Epoch [968/1000], Step [1/8], d_loss: 10433.8398, g_loss: -0.0000\n",
            "Epoch [968/1000], Step [2/8], d_loss: 1202.9572, g_loss: -0.0000\n",
            "Epoch [968/1000], Step [3/8], d_loss: 2880.2612, g_loss: -0.0000\n",
            "Epoch [968/1000], Step [4/8], d_loss: 542.4399, g_loss: -0.0000\n",
            "Epoch [968/1000], Step [5/8], d_loss: 8.9972, g_loss: -0.0000\n",
            "Epoch [968/1000], Step [6/8], d_loss: 12.7668, g_loss: -0.0000\n",
            "Epoch [968/1000], Step [7/8], d_loss: 107.1253, g_loss: -0.0000\n",
            "Epoch [968/1000], Step [8/8], d_loss: 15.4865, g_loss: -0.0000\n",
            "Epoch [969/1000], Step [1/8], d_loss: 2711.5869, g_loss: -0.0000\n",
            "Epoch [969/1000], Step [2/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [969/1000], Step [3/8], d_loss: 8.6796, g_loss: -0.0000\n",
            "Epoch [969/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [969/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [969/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [969/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [969/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [970/1000], Step [1/8], d_loss: 8.6565, g_loss: -0.0000\n",
            "Epoch [970/1000], Step [2/8], d_loss: 8.9368, g_loss: -0.0000\n",
            "Epoch [970/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [970/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [970/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [970/1000], Step [6/8], d_loss: 11.4425, g_loss: -0.0000\n",
            "Epoch [970/1000], Step [7/8], d_loss: 8.6697, g_loss: -0.0000\n",
            "Epoch [970/1000], Step [8/8], d_loss: 8.8711, g_loss: -0.0000\n",
            "Epoch [971/1000], Step [1/8], d_loss: 8.9306, g_loss: -0.0000\n",
            "Epoch [971/1000], Step [2/8], d_loss: 12.7155, g_loss: -0.0000\n",
            "Epoch [971/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [971/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [971/1000], Step [5/8], d_loss: 8.9983, g_loss: -0.0000\n",
            "Epoch [971/1000], Step [6/8], d_loss: 8.9983, g_loss: -0.0312\n",
            "Epoch [971/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [971/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [972/1000], Step [1/8], d_loss: 9.3814, g_loss: -0.0000\n",
            "Epoch [972/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [972/1000], Step [3/8], d_loss: 355.7414, g_loss: -0.0000\n",
            "Epoch [972/1000], Step [4/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [972/1000], Step [5/8], d_loss: 8.9928, g_loss: -0.0000\n",
            "Epoch [972/1000], Step [6/8], d_loss: 8.9466, g_loss: -0.0000\n",
            "Epoch [972/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [972/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [973/1000], Step [1/8], d_loss: 18.2489, g_loss: -0.0000\n",
            "Epoch [973/1000], Step [2/8], d_loss: 2041.0031, g_loss: -0.0000\n",
            "Epoch [973/1000], Step [3/8], d_loss: 85.2531, g_loss: -0.0000\n",
            "Epoch [973/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [973/1000], Step [5/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [973/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [973/1000], Step [7/8], d_loss: 28.7335, g_loss: -0.0000\n",
            "Epoch [973/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [974/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [974/1000], Step [2/8], d_loss: 8.9659, g_loss: -0.0000\n",
            "Epoch [974/1000], Step [3/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [974/1000], Step [4/8], d_loss: 23.9042, g_loss: -0.0000\n",
            "Epoch [974/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [974/1000], Step [6/8], d_loss: 9.0311, g_loss: -0.0000\n",
            "Epoch [974/1000], Step [7/8], d_loss: 138.0894, g_loss: -0.0000\n",
            "Epoch [974/1000], Step [8/8], d_loss: 5965.4365, g_loss: -0.0000\n",
            "Epoch [975/1000], Step [1/8], d_loss: 544.2131, g_loss: -0.0000\n",
            "Epoch [975/1000], Step [2/8], d_loss: 8.9524, g_loss: -0.0000\n",
            "Epoch [975/1000], Step [3/8], d_loss: 119.0241, g_loss: -0.0000\n",
            "Epoch [975/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [975/1000], Step [5/8], d_loss: 8.9300, g_loss: -0.0000\n",
            "Epoch [975/1000], Step [6/8], d_loss: 8.9103, g_loss: -0.0000\n",
            "Epoch [975/1000], Step [7/8], d_loss: 8.9993, g_loss: -0.0000\n",
            "Epoch [975/1000], Step [8/8], d_loss: 1465.3059, g_loss: -0.0000\n",
            "Epoch [976/1000], Step [1/8], d_loss: 36.5620, g_loss: -0.0000\n",
            "Epoch [976/1000], Step [2/8], d_loss: 26.2830, g_loss: -0.0000\n",
            "Epoch [976/1000], Step [3/8], d_loss: 8.9949, g_loss: -0.0312\n",
            "Epoch [976/1000], Step [4/8], d_loss: 8.9982, g_loss: -0.0000\n",
            "Epoch [976/1000], Step [5/8], d_loss: 8.9877, g_loss: -0.0000\n",
            "Epoch [976/1000], Step [6/8], d_loss: 8.6904, g_loss: -0.0000\n",
            "Epoch [976/1000], Step [7/8], d_loss: 15.3725, g_loss: -0.0000\n",
            "Epoch [976/1000], Step [8/8], d_loss: 17259.3926, g_loss: -0.0000\n",
            "Epoch [977/1000], Step [1/8], d_loss: 2149.1572, g_loss: -0.0000\n",
            "Epoch [977/1000], Step [2/8], d_loss: 2303.5283, g_loss: -0.0000\n",
            "Epoch [977/1000], Step [3/8], d_loss: 8.8621, g_loss: -0.0000\n",
            "Epoch [977/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [977/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [977/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [977/1000], Step [7/8], d_loss: 8.9801, g_loss: -0.0000\n",
            "Epoch [977/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0394\n",
            "Epoch [978/1000], Step [1/8], d_loss: 1035.0833, g_loss: -0.0000\n",
            "Epoch [978/1000], Step [2/8], d_loss: 9.0311, g_loss: -0.0000\n",
            "Epoch [978/1000], Step [3/8], d_loss: 12677.5361, g_loss: -0.0000\n",
            "Epoch [978/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0285\n",
            "Epoch [978/1000], Step [5/8], d_loss: 88.9736, g_loss: -0.0000\n",
            "Epoch [978/1000], Step [6/8], d_loss: 8.9996, g_loss: -0.0000\n",
            "Epoch [978/1000], Step [7/8], d_loss: 6178.5996, g_loss: -0.0000\n",
            "Epoch [978/1000], Step [8/8], d_loss: 38.1623, g_loss: -0.0000\n",
            "Epoch [979/1000], Step [1/8], d_loss: 8.8998, g_loss: -0.0000\n",
            "Epoch [979/1000], Step [2/8], d_loss: 8.6939, g_loss: -0.0000\n",
            "Epoch [979/1000], Step [3/8], d_loss: 26.4826, g_loss: -0.0000\n",
            "Epoch [979/1000], Step [4/8], d_loss: 8.9985, g_loss: -0.0000\n",
            "Epoch [979/1000], Step [5/8], d_loss: 12396.9805, g_loss: -0.0312\n",
            "Epoch [979/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [979/1000], Step [7/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [979/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [980/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [980/1000], Step [2/8], d_loss: 3733.8198, g_loss: -0.0000\n",
            "Epoch [980/1000], Step [3/8], d_loss: 101.4174, g_loss: -0.0000\n",
            "Epoch [980/1000], Step [4/8], d_loss: 8.9999, g_loss: -0.0089\n",
            "Epoch [980/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [980/1000], Step [6/8], d_loss: 1293.0541, g_loss: -0.0000\n",
            "Epoch [980/1000], Step [7/8], d_loss: 3928.0762, g_loss: -0.0000\n",
            "Epoch [980/1000], Step [8/8], d_loss: 4797.9277, g_loss: -0.0000\n",
            "Epoch [981/1000], Step [1/8], d_loss: 40364.4062, g_loss: -0.0000\n",
            "Epoch [981/1000], Step [2/8], d_loss: 2976.0605, g_loss: -0.0000\n",
            "Epoch [981/1000], Step [3/8], d_loss: 6027.6660, g_loss: -0.0000\n",
            "Epoch [981/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [981/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0001\n",
            "Epoch [981/1000], Step [6/8], d_loss: 9.0312, g_loss: -0.0294\n",
            "Epoch [981/1000], Step [7/8], d_loss: 8.9897, g_loss: -0.0000\n",
            "Epoch [981/1000], Step [8/8], d_loss: 10.5011, g_loss: -0.0000\n",
            "Epoch [982/1000], Step [1/8], d_loss: 9.0351, g_loss: -0.0000\n",
            "Epoch [982/1000], Step [2/8], d_loss: 9.0624, g_loss: -0.0000\n",
            "Epoch [982/1000], Step [3/8], d_loss: 8.7980, g_loss: -0.0000\n",
            "Epoch [982/1000], Step [4/8], d_loss: 8.9854, g_loss: -0.0000\n",
            "Epoch [982/1000], Step [5/8], d_loss: 8.9986, g_loss: -0.0000\n",
            "Epoch [982/1000], Step [6/8], d_loss: 8.9836, g_loss: -0.0000\n",
            "Epoch [982/1000], Step [7/8], d_loss: 1627.7920, g_loss: -0.0000\n",
            "Epoch [982/1000], Step [8/8], d_loss: 250.7560, g_loss: -0.0435\n",
            "Epoch [983/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [983/1000], Step [2/8], d_loss: 8.7187, g_loss: -0.0000\n",
            "Epoch [983/1000], Step [3/8], d_loss: 8.8680, g_loss: -0.0000\n",
            "Epoch [983/1000], Step [4/8], d_loss: 24.2518, g_loss: -0.0000\n",
            "Epoch [983/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [983/1000], Step [6/8], d_loss: 9.0145, g_loss: -0.0000\n",
            "Epoch [983/1000], Step [7/8], d_loss: 1572.8812, g_loss: -0.0000\n",
            "Epoch [983/1000], Step [8/8], d_loss: 5087.8677, g_loss: -0.0000\n",
            "Epoch [984/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [984/1000], Step [2/8], d_loss: 32115.0508, g_loss: -0.0000\n",
            "Epoch [984/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [984/1000], Step [4/8], d_loss: 6469.1133, g_loss: -0.0003\n",
            "Epoch [984/1000], Step [5/8], d_loss: 71.6384, g_loss: -0.0000\n",
            "Epoch [984/1000], Step [6/8], d_loss: 8.8260, g_loss: -0.0000\n",
            "Epoch [984/1000], Step [7/8], d_loss: 13064.4668, g_loss: -0.0000\n",
            "Epoch [984/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0207\n",
            "Epoch [985/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [985/1000], Step [2/8], d_loss: 8.9997, g_loss: -0.0000\n",
            "Epoch [985/1000], Step [3/8], d_loss: 8.9969, g_loss: -0.0000\n",
            "Epoch [985/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [985/1000], Step [5/8], d_loss: 9.0310, g_loss: -0.0000\n",
            "Epoch [985/1000], Step [6/8], d_loss: 8.9976, g_loss: -0.0295\n",
            "Epoch [985/1000], Step [7/8], d_loss: 25.6512, g_loss: -0.0000\n",
            "Epoch [985/1000], Step [8/8], d_loss: 8.6586, g_loss: -0.0000\n",
            "Epoch [986/1000], Step [1/8], d_loss: 53.0339, g_loss: -0.0000\n",
            "Epoch [986/1000], Step [2/8], d_loss: 8.7184, g_loss: -0.0000\n",
            "Epoch [986/1000], Step [3/8], d_loss: 8.9833, g_loss: -0.0000\n",
            "Epoch [986/1000], Step [4/8], d_loss: 163.4837, g_loss: -0.0000\n",
            "Epoch [986/1000], Step [5/8], d_loss: 8.9992, g_loss: -0.0000\n",
            "Epoch [986/1000], Step [6/8], d_loss: 8.6264, g_loss: -0.0000\n",
            "Epoch [986/1000], Step [7/8], d_loss: 581.2198, g_loss: -0.0312\n",
            "Epoch [986/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [987/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [987/1000], Step [2/8], d_loss: 8.6883, g_loss: -0.0000\n",
            "Epoch [987/1000], Step [3/8], d_loss: 574.8220, g_loss: -0.0312\n",
            "Epoch [987/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [987/1000], Step [5/8], d_loss: 8.9995, g_loss: -0.0291\n",
            "Epoch [987/1000], Step [6/8], d_loss: 8.9478, g_loss: -0.0000\n",
            "Epoch [987/1000], Step [7/8], d_loss: 8.9727, g_loss: -0.0000\n",
            "Epoch [987/1000], Step [8/8], d_loss: 9.0005, g_loss: -0.0000\n",
            "Epoch [988/1000], Step [1/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [988/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [988/1000], Step [3/8], d_loss: 420.3885, g_loss: -0.0000\n",
            "Epoch [988/1000], Step [4/8], d_loss: 8.9995, g_loss: -0.0000\n",
            "Epoch [988/1000], Step [5/8], d_loss: 9.0304, g_loss: -0.0000\n",
            "Epoch [988/1000], Step [6/8], d_loss: 8.6336, g_loss: -0.0000\n",
            "Epoch [988/1000], Step [7/8], d_loss: 8.9994, g_loss: -0.0000\n",
            "Epoch [988/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [989/1000], Step [1/8], d_loss: 9.0197, g_loss: -0.0000\n",
            "Epoch [989/1000], Step [2/8], d_loss: 10.9511, g_loss: -0.0000\n",
            "Epoch [989/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0312\n",
            "Epoch [989/1000], Step [4/8], d_loss: 8.9903, g_loss: -0.0000\n",
            "Epoch [989/1000], Step [5/8], d_loss: 5182.6333, g_loss: -0.0042\n",
            "Epoch [989/1000], Step [6/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [989/1000], Step [7/8], d_loss: 8.8055, g_loss: -0.0000\n",
            "Epoch [989/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0003\n",
            "Epoch [990/1000], Step [1/8], d_loss: 8933.7773, g_loss: -0.0000\n",
            "Epoch [990/1000], Step [2/8], d_loss: 8.9922, g_loss: -0.0000\n",
            "Epoch [990/1000], Step [3/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [990/1000], Step [4/8], d_loss: 8.7326, g_loss: -0.0000\n",
            "Epoch [990/1000], Step [5/8], d_loss: 12869.9775, g_loss: -0.0000\n",
            "Epoch [990/1000], Step [6/8], d_loss: 19412.8691, g_loss: -0.0000\n",
            "Epoch [990/1000], Step [7/8], d_loss: 9.9764, g_loss: -0.0000\n",
            "Epoch [990/1000], Step [8/8], d_loss: 9.0405, g_loss: -0.0000\n",
            "Epoch [991/1000], Step [1/8], d_loss: 14.7874, g_loss: -0.0001\n",
            "Epoch [991/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [991/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [991/1000], Step [4/8], d_loss: 8.9937, g_loss: -0.0000\n",
            "Epoch [991/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [991/1000], Step [6/8], d_loss: 16151.0859, g_loss: -0.0000\n",
            "Epoch [991/1000], Step [7/8], d_loss: 9.0311, g_loss: -0.0000\n",
            "Epoch [991/1000], Step [8/8], d_loss: 8.7667, g_loss: -0.0000\n",
            "Epoch [992/1000], Step [1/8], d_loss: 8.9129, g_loss: -0.0001\n",
            "Epoch [992/1000], Step [2/8], d_loss: 9.0937, g_loss: -0.0000\n",
            "Epoch [992/1000], Step [3/8], d_loss: 4142.5396, g_loss: -0.0000\n",
            "Epoch [992/1000], Step [4/8], d_loss: 8.9404, g_loss: -0.0000\n",
            "Epoch [992/1000], Step [5/8], d_loss: 17074.9824, g_loss: -0.0027\n",
            "Epoch [992/1000], Step [6/8], d_loss: 8.8771, g_loss: -0.0000\n",
            "Epoch [992/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [992/1000], Step [8/8], d_loss: 8.5825, g_loss: -0.0000\n",
            "Epoch [993/1000], Step [1/8], d_loss: 8.9996, g_loss: -0.0001\n",
            "Epoch [993/1000], Step [2/8], d_loss: 8.9993, g_loss: -0.0000\n",
            "Epoch [993/1000], Step [3/8], d_loss: 2255.3008, g_loss: -0.0000\n",
            "Epoch [993/1000], Step [4/8], d_loss: 8.8300, g_loss: -0.0000\n",
            "Epoch [993/1000], Step [5/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [993/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [993/1000], Step [7/8], d_loss: 8.9967, g_loss: -0.0000\n",
            "Epoch [993/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [994/1000], Step [1/8], d_loss: 9.0319, g_loss: -0.0002\n",
            "Epoch [994/1000], Step [2/8], d_loss: 8.9995, g_loss: -0.0000\n",
            "Epoch [994/1000], Step [3/8], d_loss: 9.0010, g_loss: -0.0000\n",
            "Epoch [994/1000], Step [4/8], d_loss: 2183.4819, g_loss: -0.0000\n",
            "Epoch [994/1000], Step [5/8], d_loss: 281.1757, g_loss: -0.0005\n",
            "Epoch [994/1000], Step [6/8], d_loss: 8.8428, g_loss: -0.0000\n",
            "Epoch [994/1000], Step [7/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [994/1000], Step [8/8], d_loss: 8.7523, g_loss: -0.0000\n",
            "Epoch [995/1000], Step [1/8], d_loss: 615.0050, g_loss: -0.0000\n",
            "Epoch [995/1000], Step [2/8], d_loss: 9.0000, g_loss: -0.0741\n",
            "Epoch [995/1000], Step [3/8], d_loss: 9.0314, g_loss: -0.0000\n",
            "Epoch [995/1000], Step [4/8], d_loss: 8.9982, g_loss: -0.0000\n",
            "Epoch [995/1000], Step [5/8], d_loss: 9.0296, g_loss: -0.0000\n",
            "Epoch [995/1000], Step [6/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [995/1000], Step [7/8], d_loss: 8.9260, g_loss: -0.0000\n",
            "Epoch [995/1000], Step [8/8], d_loss: 8.9505, g_loss: -0.0000\n",
            "Epoch [996/1000], Step [1/8], d_loss: 15.1482, g_loss: -0.0000\n",
            "Epoch [996/1000], Step [2/8], d_loss: 8.7075, g_loss: -0.0000\n",
            "Epoch [996/1000], Step [3/8], d_loss: 9.0001, g_loss: -0.0000\n",
            "Epoch [996/1000], Step [4/8], d_loss: 33.7166, g_loss: -0.0000\n",
            "Epoch [996/1000], Step [5/8], d_loss: 2316.4834, g_loss: -0.0000\n",
            "Epoch [996/1000], Step [6/8], d_loss: 1915.4576, g_loss: -0.0000\n",
            "Epoch [996/1000], Step [7/8], d_loss: 8.9999, g_loss: -0.0000\n",
            "Epoch [996/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [997/1000], Step [1/8], d_loss: 8.9720, g_loss: -0.0000\n",
            "Epoch [997/1000], Step [2/8], d_loss: 4015.9021, g_loss: -0.0000\n",
            "Epoch [997/1000], Step [3/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [997/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [997/1000], Step [5/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [997/1000], Step [6/8], d_loss: 8.7000, g_loss: -0.0254\n",
            "Epoch [997/1000], Step [7/8], d_loss: 1324.5699, g_loss: -0.0000\n",
            "Epoch [997/1000], Step [8/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [998/1000], Step [1/8], d_loss: 8.9374, g_loss: -0.0000\n",
            "Epoch [998/1000], Step [2/8], d_loss: 446.7115, g_loss: -0.0304\n",
            "Epoch [998/1000], Step [3/8], d_loss: 8.9175, g_loss: -0.0000\n",
            "Epoch [998/1000], Step [4/8], d_loss: 9.0000, g_loss: -0.0000\n",
            "Epoch [998/1000], Step [5/8], d_loss: 8.9979, g_loss: -0.0312\n",
            "Epoch [998/1000], Step [6/8], d_loss: 9.0312, g_loss: -0.0000\n",
            "Epoch [998/1000], Step [7/8], d_loss: 8.9018, g_loss: -0.0312\n",
            "Epoch [998/1000], Step [8/8], d_loss: 803.5245, g_loss: -0.0000\n",
            "Epoch [999/1000], Step [1/8], d_loss: 8.7222, g_loss: -0.0000\n",
            "Epoch [999/1000], Step [2/8], d_loss: 17746.2051, g_loss: -0.0000\n",
            "Epoch [999/1000], Step [3/8], d_loss: 52630.4453, g_loss: -0.0000\n",
            "Epoch [999/1000], Step [4/8], d_loss: 8.9601, g_loss: -0.0000\n",
            "Epoch [999/1000], Step [5/8], d_loss: 8.8826, g_loss: -0.0000\n",
            "Epoch [999/1000], Step [6/8], d_loss: 11551.9248, g_loss: -0.0000\n",
            "Epoch [999/1000], Step [7/8], d_loss: 4194.5288, g_loss: -0.0000\n",
            "Epoch [999/1000], Step [8/8], d_loss: 200.5764, g_loss: -0.0000\n",
            "CPU times: user 3min 31s, sys: 4.59 s, total: 3min 35s\n",
            "Wall time: 3min 51s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = fit(epochs, lr, opt_d, opt_g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "-9M_sE8xsT-r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "outputId": "b2582669-00c4-4fb8-ab58-7bdbf1fba512"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa139437d30>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x864 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "losses_g, losses_d = history[0], history[1]\n",
        "\n",
        "fig, axes = plt.subplots(1,1, figsize=(30, 12))\n",
        "ax1 = plt.subplot(1,1,1)\n",
        "\n",
        "plt.plot(range(1,1001), losses_g, label = 'Generator')\n",
        "plt.plot(range(1, 1001), losses_d, label = 'Discriminator')\n",
        "#plt.plot(range(1,601), losses_g, label = 'Generator')\n",
        "#plt.plot(range(1, 601), losses_d, label = 'Discriminator')\n",
        "\n",
        "ax1.tick_params(labelsize = 30)\n",
        "ax1.set_xlabel('Number of Iterations', fontsize = 40)\n",
        "ax1.set_ylabel('Loss (Binary Cross Entropy)', fontsize = 40)\n",
        "plt.title('Gen vs Dis loss across training', fontsize = 50)\n",
        "plt.legend(fontsize = 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5OYiR_asT-r"
      },
      "source": [
        "# Testing Generated Samples from Trained Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "KwphoXX3sT-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6a98d3-117c-4bb5-edc6-83d75249bde6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df.columns: Index(['AGE', 'SMOKING', 'YELLOW_FINGERS', 'ANXIETY', 'PEER_PRESSURE',\n",
            "       'CHRONIC DISEASE', 'FATIGUE ', 'ALLERGY ', 'WHEEZING',\n",
            "       'ALCOHOL CONSUMING', 'COUGHING', 'SHORTNESS OF BREATH',\n",
            "       'SWALLOWING DIFFICULTY', 'CHEST PAIN', 'LUNG_CANCER', 'GENDER_F',\n",
            "       'GENDER_M'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#df.label.value_counts()\n",
        "print(\"df.columns:\", df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Y3HfXxX1sT-s"
      },
      "outputs": [],
      "source": [
        "def generate_samples(number_of_samples_to_generate, class_val):\n",
        "    if class_val == 0:\n",
        "        label = torch.zeros(number_of_samples_to_generate, dtype=torch.int).to(device)  #generate for class 0\n",
        "    elif class_val == 1:\n",
        "        label = torch.ones(number_of_samples_to_generate, dtype=torch.int).to(device)  #generate for class 1\n",
        "        \n",
        "        \n",
        "    latent_space_samples = torch.randn(number_of_samples_to_generate, n_features).to(device)\n",
        "    generated_samples = generator(latent_space_samples, label)\n",
        "    print('generated_samples: ', generated_samples.shape)\n",
        "    print('label: ', label.shape)\n",
        "    generated_samples = torch.concat([generated_samples, label.reshape(number_of_samples_to_generate, 1)], \\\n",
        "                                     dim = 1)\n",
        "    generated_samples = generated_samples.cpu().detach().numpy()\n",
        "    #check this line\n",
        "    print(df.columns)\n",
        "    df_generated = pd.DataFrame(generated_samples, columns = df.columns)  #assign columns\n",
        "    print(\"df_generated_shape\", df_generated.shape)\n",
        "    #df_generated = pd.DataFrame(generated_samples)  # don't assign columns, leon\n",
        "    return df_generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "xB4lqSvEsT-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a336639b-3428-4ed8-df69-698f7a4909b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated_samples:  torch.Size([2000, 16])\n",
            "label:  torch.Size([2000])\n",
            "Index(['AGE', 'SMOKING', 'YELLOW_FINGERS', 'ANXIETY', 'PEER_PRESSURE',\n",
            "       'CHRONIC DISEASE', 'FATIGUE ', 'ALLERGY ', 'WHEEZING',\n",
            "       'ALCOHOL CONSUMING', 'COUGHING', 'SHORTNESS OF BREATH',\n",
            "       'SWALLOWING DIFFICULTY', 'CHEST PAIN', 'LUNG_CANCER', 'GENDER_F',\n",
            "       'GENDER_M'],\n",
            "      dtype='object')\n",
            "df_generated_shape (2000, 17)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 17 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   AGE                    2000 non-null   float32\n",
            " 1   SMOKING                2000 non-null   float32\n",
            " 2   YELLOW_FINGERS         2000 non-null   float32\n",
            " 3   ANXIETY                2000 non-null   float32\n",
            " 4   PEER_PRESSURE          2000 non-null   float32\n",
            " 5   CHRONIC DISEASE        2000 non-null   float32\n",
            " 6   FATIGUE                2000 non-null   float32\n",
            " 7   ALLERGY                2000 non-null   float32\n",
            " 8   WHEEZING               2000 non-null   float32\n",
            " 9   ALCOHOL CONSUMING      2000 non-null   float32\n",
            " 10  COUGHING               2000 non-null   float32\n",
            " 11  SHORTNESS OF BREATH    2000 non-null   float32\n",
            " 12  SWALLOWING DIFFICULTY  2000 non-null   float32\n",
            " 13  CHEST PAIN             2000 non-null   float32\n",
            " 14  LUNG_CANCER            2000 non-null   int64  \n",
            " 15  GENDER_F               2000 non-null   float32\n",
            " 16  GENDER_M               2000 non-null   float32\n",
            "dtypes: float32(16), int64(1)\n",
            "memory usage: 140.8 KB\n",
            "        AGE   SMOKING  YELLOW_FINGERS   ANXIETY  PEER_PRESSURE  \\\n",
            "0  0.550335  0.670873        0.808438  0.799868       0.753164   \n",
            "1  0.902668  1.455807        1.474811  1.452528       1.280835   \n",
            "2  0.498846  0.988597        0.995657  0.890670       1.015493   \n",
            "3  0.643355  1.238636        1.099555  0.898425       1.042288   \n",
            "4  0.542587  0.913156        0.924258  0.994772       0.939045   \n",
            "\n",
            "   CHRONIC DISEASE  FATIGUE   ALLERGY   WHEEZING  ALCOHOL CONSUMING  COUGHING  \\\n",
            "0        -0.096660  0.694046 -0.041102  0.277945          -0.024718  0.739143   \n",
            "1         0.027100  1.300380  0.059074  1.094257           0.026160  1.356233   \n",
            "2        -0.167876  0.945457 -0.006865  0.388247          -0.001609  0.799287   \n",
            "3        -0.561701  0.896742 -0.045771  0.105554          -0.140212  0.837708   \n",
            "4        -0.141701  0.835020  0.006992  0.591669          -0.006282  0.821567   \n",
            "\n",
            "   SHORTNESS OF BREATH  SWALLOWING DIFFICULTY  CHEST PAIN  LUNG_CANCER  \\\n",
            "0             0.629571               0.818236    0.027486            0   \n",
            "1             1.545288               1.539920   -0.070140            0   \n",
            "2             1.125973               1.289848   -0.089122            0   \n",
            "3             0.932725               1.111320   -0.087033            0   \n",
            "4             0.901398               1.200366   -0.025373            0   \n",
            "\n",
            "   GENDER_F  GENDER_M  \n",
            "0 -0.061226       0.0  \n",
            "1  0.014721       0.0  \n",
            "2 -0.083508       0.0  \n",
            "3 -0.160165       0.0  \n",
            "4 -0.024032       0.0  \n",
            "generated_samples:  torch.Size([1800, 16])\n",
            "label:  torch.Size([1800])\n",
            "Index(['AGE', 'SMOKING', 'YELLOW_FINGERS', 'ANXIETY', 'PEER_PRESSURE',\n",
            "       'CHRONIC DISEASE', 'FATIGUE ', 'ALLERGY ', 'WHEEZING',\n",
            "       'ALCOHOL CONSUMING', 'COUGHING', 'SHORTNESS OF BREATH',\n",
            "       'SWALLOWING DIFFICULTY', 'CHEST PAIN', 'LUNG_CANCER', 'GENDER_F',\n",
            "       'GENDER_M'],\n",
            "      dtype='object')\n",
            "df_generated_shape (1800, 17)\n",
            "        AGE   SMOKING  YELLOW_FINGERS   ANXIETY  PEER_PRESSURE  \\\n",
            "0  0.594963  1.207333        1.134938  0.975690       1.098248   \n",
            "1  1.025067  1.907469        1.950449  1.816450       1.620914   \n",
            "2  0.929081  1.645792        1.585080  1.434555       1.450405   \n",
            "3  0.613889  1.304365        1.315727  1.222877       1.259426   \n",
            "4  0.971839  1.646744        1.707939  1.472319       1.459765   \n",
            "\n",
            "   CHRONIC DISEASE  FATIGUE   ALLERGY   WHEEZING  ALCOHOL CONSUMING  COUGHING  \\\n",
            "0        -0.229453  1.162396 -0.096684  1.121039          -0.012052  0.990746   \n",
            "1        -0.342165  1.754746  0.144056  1.619182          -0.084835  2.140768   \n",
            "2        -0.273300  1.431439  0.084568  0.627362          -0.083123  1.551248   \n",
            "3        -0.583363  1.196463 -0.145315  0.200490          -0.085810  1.062269   \n",
            "4        -0.243477  1.518492  0.078493  1.101282          -0.004569  1.726218   \n",
            "\n",
            "   SHORTNESS OF BREATH  SWALLOWING DIFFICULTY  CHEST PAIN  LUNG_CANCER  \\\n",
            "0             1.212577               1.108048   -0.102851            1   \n",
            "1             2.088160               2.175212   -0.166137            1   \n",
            "2             1.552703               1.573423   -0.106372            1   \n",
            "3             1.233579               1.411955   -0.121470            1   \n",
            "4             1.769112               1.683251   -0.141682            1   \n",
            "\n",
            "   GENDER_F  GENDER_M  \n",
            "0 -0.040363       1.0  \n",
            "1 -0.031154       1.0  \n",
            "2 -0.045863       1.0  \n",
            "3 -0.118848       1.0  \n",
            "4 -0.032668       1.0  \n"
          ]
        }
      ],
      "source": [
        "#df_generated_0 = generate_samples(549, 0)\n",
        "df_generated_0 = generate_samples(2000, 0)  #5000\n",
        "\n",
        "df_generated_0[\"LUNG_CANCER\"] = 0\n",
        "df_generated_0.info()\n",
        "df_generated_0.head()\n",
        "print(df_generated_0.head())\n",
        "#df_generated_1 = generate_samples(342, 1)\n",
        "df_generated_1 = generate_samples(1800, 1)  #4800\n",
        "df_generated_1[\"LUNG_CANCER\"] = 1\n",
        "print(df_generated_1.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coXHZd4Zusks"
      },
      "source": [
        "Concatenate dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "KfXAEx0zuk1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c813e6-6a02-4f31-de84-3f4054918362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X:         AGE   SMOKING  YELLOW_FINGERS   ANXIETY  PEER_PRESSURE  \\\n",
            "0  0.421635  0.729027        0.760568  0.611937       0.847133   \n",
            "1  0.965685  1.910970        2.231100  1.999675       1.836305   \n",
            "2  0.626559  1.210906        1.072996  1.141008       1.088026   \n",
            "3  0.618999  1.269639        1.202499  1.001550       1.185884   \n",
            "4  0.819490  1.503342        1.458259  1.345540       1.316121   \n",
            "\n",
            "   CHRONIC DISEASE  FATIGUE   ALLERGY   WHEEZING  ALCOHOL CONSUMING  COUGHING  \\\n",
            "0        -0.154936  0.682792 -0.041514  0.003310           0.019465  0.429938   \n",
            "1        -0.729558  1.984937 -0.036096  0.830436           0.029971  2.460595   \n",
            "2        -0.232935  1.078048  0.009205  0.695621          -0.085179  0.859832   \n",
            "3        -0.603129  1.043351 -0.091086  0.011035          -0.136707  0.986151   \n",
            "4        -0.310992  1.322787 -0.081474  0.817744          -0.026066  1.303655   \n",
            "\n",
            "   SHORTNESS OF BREATH  SWALLOWING DIFFICULTY  CHEST PAIN  GENDER_F  GENDER_M  \n",
            "0             0.878389               0.907826   -0.074210 -0.038741       0.0  \n",
            "1             2.004640               2.295565   -0.151820 -0.243352       1.0  \n",
            "2             1.312818               1.270698   -0.132662 -0.012395       0.0  \n",
            "3             0.991386               1.216120   -0.057248 -0.133388       1.0  \n",
            "4             1.540928               1.582546   -0.151415 -0.053135       1.0  \n",
            "Y： 0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    1\n",
            "Name: LUNG_CANCER, dtype: int64\n",
            "X_train_gan shape: (3800, 16)\n",
            "y_train_gan shape: (3800, 1)\n",
            "X 0     4047\n",
            "1     4047\n",
            "2     4047\n",
            "3     4047\n",
            "4     4047\n",
            "5     4047\n",
            "6     4047\n",
            "7     4047\n",
            "8     4047\n",
            "9     4047\n",
            "10    4047\n",
            "11    4047\n",
            "12    4047\n",
            "13    4047\n",
            "14    4047\n",
            "15    4047\n",
            "dtype: int64\n",
            "y: 0    4047\n",
            "dtype: int64\n",
            "X (4047, 16)\n",
            "y: (4047, 1)\n",
            "         0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
            "0  0.863636  1.0  1.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0  1.0  0.0   \n",
            "1  0.848485  0.0  1.0  0.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0   \n",
            "2  0.530303  1.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0   \n",
            "3  0.515152  1.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "4  0.575758  0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  1.0   \n",
            "\n",
            "    14   15  \n",
            "0  1.0  0.0  \n",
            "1  0.0  1.0  \n",
            "2  0.0  1.0  \n",
            "3  1.0  0.0  \n",
            "4  1.0  0.0  \n",
            "   0\n",
            "0  1\n",
            "1  1\n",
            "2  1\n",
            "3  0\n",
            "4  0\n"
          ]
        }
      ],
      "source": [
        "df_gan = pd.concat([df_generated_1, df_generated_0], ignore_index=True, sort=False)  #leon\n",
        "df_gan = df_gan.sample(frac=1).reset_index(drop=True)  #用于从DataFrame中随机选择行和列。\n",
        "\n",
        "y_train_gan = df_gan['LUNG_CANCER']\n",
        "X_train_gan = df_gan.drop('LUNG_CANCER',axis='columns')\n",
        "#print(X_train_2.iloc[0:5])pe\n",
        "#y_train_gan = df_gan['LUNG_CANCER'].values\n",
        "#y_train_gan = df_gan['LUNG_CANCER']\n",
        "print(\"X:\", X_train_gan.head())\n",
        "print(\"Y：\", y_train_gan.head())\n",
        "\n",
        "\n",
        "\n",
        "#y_train_2_d = df_gan['LUNG_CANCER']\n",
        "\n",
        "#transform to narray lost column name\n",
        "X_train_gan = X_train_gan.values\n",
        "y_train_gan = y_train_gan.values\n",
        "#transforms to dataframe again\n",
        "X_train_gan = pd.DataFrame(X_train_gan)\n",
        "y_train_gan = pd.DataFrame(y_train_gan)\n",
        "\n",
        "print(f\"X_train_gan shape: {X_train_gan.shape}\")\n",
        "print(f\"y_train_gan shape: {y_train_gan.shape}\")\n",
        "\n",
        "# transform and lost column name for concatenation\n",
        "origin_df_x = pd.DataFrame(X_train.values)\n",
        "origin_df_y = pd.DataFrame(y_train.values)\n",
        "\n",
        "\n",
        "#X_train_2_e =  X_train_2.values\n",
        "\n",
        "#origin_df - pd.merge(origin_df_x,origin_df_y)\n",
        "#origin_df.info()\n",
        "#origin_df.head()\n",
        "\n",
        "#X_train_2_d = pd.DataFrame(X_train_2_e)\n",
        "\n",
        "X_train_fin = pd.concat([origin_df_x, X_train_gan], axis=0, ignore_index=True)       \n",
        "y_train_fin = pd.concat([origin_df_y, y_train_gan], axis=0, ignore_index=True)\n",
        "print('X', X_train_fin.count())\n",
        "print('y:',y_train_fin.count())\n",
        "print('X', X_train_fin.shape)\n",
        "print('y:',y_train_fin.shape)\n",
        "\n",
        "\n",
        "#print(\"y count(）\", y_train_fin.value_counts())\n",
        "print(X_train_fin.head())\n",
        "print(y_train_fin.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "SUQew4p3upTP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "dceafc7c-0888-4bd1-a560-cc0234a81368"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport xgboost as xgb2\\nxgb2 = xgb2.XGBClassifier()\\ny_train_fin = y_train_fin.values.ravel()\\n\\nxgb2.fit(X_train_fin,y_train_fin)\\n\\ny_pred = xgb2.predict(X_test)\\n\\nprint(classification_report(y_test, y_pred))\\nprint(classification_report_imbalanced(y_test, y_pred))\\nplot_confusion_matrix(xgb2, X_test, y_test)\\nplt.show()  \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "\"\"\"\n",
        "import xgboost as xgb2\n",
        "xgb2 = xgb2.XGBClassifier()\n",
        "y_train_fin = y_train_fin.values.ravel()\n",
        "\n",
        "xgb2.fit(X_train_fin,y_train_fin)\n",
        "\n",
        "y_pred = xgb2.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(classification_report_imbalanced(y_test, y_pred))\n",
        "plot_confusion_matrix(xgb2, X_test, y_test)\n",
        "plt.show()  \n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameter = {\n",
        "    'max_depth':range(3,10,2), \n",
        "    'min_child_weight':range(1,5,2)\n",
        "    }\n",
        "\n",
        "p_grid_search = GridSearchCV(estimator = xgb.XGBClassifier(eval_metric='mlogloss'), param_grid = parameter, \n",
        "                             scoring='accuracy', n_jobs=-1, cv=2)\n",
        "\n",
        "p_grid_search.fit(X_train_fin,y_train_fin)\n",
        "\n",
        "\n",
        "GridSearchCV(cv=2,\n",
        "             estimator=xgb.XGBClassifier(base_score=None, booster=None,   #leon  add xgb before xgbclassifier\n",
        "                                     callbacks=None, colsample_bylevel=None,\n",
        "                                     colsample_bynode=None,\n",
        "                                     colsample_bytree=None,\n",
        "                                     early_stopping_rounds=None,\n",
        "                                     enable_categorical=False,\n",
        "                                     eval_metric='mlogloss', gamma=None,\n",
        "                                     gpu_id=None, grow_policy=None,\n",
        "                                     importance_type=None,\n",
        "                                     interaction_constraints=None,\n",
        "                                     learning_rate=None, max_bin=None,\n",
        "                                     max_cat_to_onehot=None,\n",
        "                                     max_delta_step=None, max_depth=None,\n",
        "                                     max_leaves=None, min_child_weight=None,\n",
        "                                     missing=None, monotone_constraints=None,\n",
        "                                     n_estimators=100, n_jobs=None,\n",
        "                                     num_parallel_tree=None, predictor=None,\n",
        "                                     random_state=None, reg_alpha=None,\n",
        "                                     reg_lambda=None),\n",
        "             n_jobs=-1,\n",
        "             param_grid={'max_depth': range(3, 10, 2),\n",
        "                         'min_child_weight': range(1, 5, 2)},\n",
        "             scoring='accuracy')\n",
        "\n",
        "p_grid_search.best_params_, p_grid_search.best_score_"
      ],
      "metadata": {
        "id": "5ZlDzzwUjTfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d4a429-582e-41b4-9c78-91f028782eab"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'max_depth': 3, 'min_child_weight': 1}, 0.9728260869565217)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "refined_xgb_model = xgb.XGBClassifier(eval_metric='logloss', max_depth=list(p_grid_search.best_params_.values())[0]-1, \n",
        "                                      min_child_weight=list(p_grid_search.best_params_.values())[-1]+4)\n",
        "refined_xgb_model.fit(X_train_fin,y_train_fin)"
      ],
      "metadata": {
        "id": "B9mlOX8AjUt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a04d930-39d5-47dd-b12a-01eacf30a2a5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
              "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric='logloss', gamma=0, gpu_id=-1,\n",
              "              grow_policy='depthwise', importance_type=None,\n",
              "              interaction_constraints='', learning_rate=0.300000012,\n",
              "              max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=2,\n",
              "              max_leaves=0, min_child_weight=5, missing=nan,\n",
              "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
              "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, ...)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from imblearn.metrics import classification_report_imbalanced\n",
        "ref_xgb_pred_y2 = refined_xgb_model.predict(X_test)\n",
        "def plot_confusion_matrix(y_test, y_pred, color):\n",
        "    \n",
        "    plt.rcParams['figure.figsize'] = (16, 9)\n",
        "   \n",
        "    data = {'y_Actual': y_test, 'y_Predicted': y_pred}\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "    conf_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], \n",
        "                              rownames=['Actual'], \n",
        "                              colnames=['Predicted'])\n",
        "    \n",
        "    sns.heatmap(conf_matrix, annot=True, fmt = \"d\", cmap=color)\n",
        "    plt.show()\n",
        "    \n",
        "plot_confusion_matrix(np.array(y_test), ref_xgb_pred_y2, 'crest')\n",
        "print(classification_report(y_test, ref_xgb_pred_y2))\n",
        "print(classification_report_imbalanced(y_test, ref_xgb_pred_y2))  #, digits=4"
      ],
      "metadata": {
        "id": "W0StC7yTjWny",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828
        },
        "outputId": "9233fa1a-1d98-4e28-f557-11a407ddac3d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50         6\n",
            "           1       0.95      0.95      0.95        56\n",
            "\n",
            "    accuracy                           0.90        62\n",
            "   macro avg       0.72      0.72      0.72        62\n",
            "weighted avg       0.90      0.90      0.90        62\n",
            "\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.50      0.50      0.95      0.50      0.69      0.45         6\n",
            "          1       0.95      0.95      0.50      0.95      0.69      0.49        56\n",
            "\n",
            "avg / total       0.90      0.90      0.54      0.90      0.69      0.49        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=300, n_jobs=-1)\n",
        "rf.fit(X_train_fin,y_train_fin)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "plot_confusion_matrix(rf, X_test, y_test)\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "w-LGoBTABV0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "60dc0720-6cca-4347-bf9e-891fd896adb3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.ensemble import RandomForestClassifier\\nrf = RandomForestClassifier(n_estimators=300, n_jobs=-1)\\nrf.fit(X_train_fin,y_train_fin)\\ny_pred = rf.predict(X_test)\\n\\nprint(classification_report(y_test, y_pred))\\nplot_confusion_matrix(rf, X_test, y_test)\\nplt.show()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_2 = lgb.LGBMClassifier()\n",
        "\n",
        "#y_train_3 = y_train_3.values\n",
        "#y_train_3 = y_train_3.ravel()\n",
        "lgb_2.fit(X_train_fin,y_train_fin)\n",
        "\n",
        "y_pred = lgb_2.predict(X_test)\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(classification_report_imbalanced(y_test, y_pred))\n",
        "\"\"\"\n",
        "plot_confusion_matrix(lgb_2, X_test, y_test)\n",
        "plt.show()\n",
        "\"\"\"\n",
        "print(lgb_2.classes_)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=lgb_2.classes_)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lgb_2.classes_)\n",
        "disp.plot()\n",
        "_ = disp.ax_.set_title(\"LGBM Classifier\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iT2Kmwxjax5E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        },
        "outputId": "6aedde61-0977-451d-aea0-23477b6877bf"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.33      0.44         6\n",
            "           1       0.93      0.98      0.96        56\n",
            "\n",
            "    accuracy                           0.92        62\n",
            "   macro avg       0.80      0.66      0.70        62\n",
            "weighted avg       0.91      0.92      0.91        62\n",
            "\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.67      0.33      0.98      0.44      0.57      0.31         6\n",
            "          1       0.93      0.98      0.33      0.96      0.57      0.35        56\n",
            "\n",
            "avg / total       0.91      0.92      0.40      0.91      0.57      0.34        62\n",
            "\n",
            "[0 1]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report,\\\n",
        "                            plot_confusion_matrix, confusion_matrix\n",
        "xgb_3=xgb.XGBClassifier()\n",
        "\n",
        "xgb_3.fit(X_train_fin,y_train_fin)\n",
        "\n",
        "y_pred = xgb_3.predict(X_test)\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#change y value to 0..2\n",
        "#le2 = LabelEncoder()\n",
        "#y_test = le2.fit_transform(y_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(classification_report_imbalanced(y_test, y_pred))\n",
        "plot_confusion_matrix(xgb_3, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c3DKOv_LJNcN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        },
        "outputId": "4774d941-cf9b-472a-f144-8eece3519788"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50         6\n",
            "           1       0.95      0.95      0.95        56\n",
            "\n",
            "    accuracy                           0.90        62\n",
            "   macro avg       0.72      0.72      0.72        62\n",
            "weighted avg       0.90      0.90      0.90        62\n",
            "\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.50      0.50      0.95      0.50      0.69      0.45         6\n",
            "          1       0.95      0.95      0.50      0.95      0.69      0.49        56\n",
            "\n",
            "avg / total       0.90      0.90      0.54      0.90      0.69      0.49        62\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAIWCAYAAAAI8Mr7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdIElEQVR4nO3de9TtdV0n8PfnHG6KXEIQyRukDg7jjEaImTMuLqNhtUZtmaXWsBpaVlo6NS7H+iPLNc2ypjRntIzUgcq8jTdIAxN1kMmUi1oCXk54QzHkYoIIcs7zmT+eDZ6Q85znnPP89t58z+u11l7s/dt7/36fh8Ve68P7971UdwcAgOW0adEFAACwY5o1AIAlplkDAFhimjUAgCWmWQMAWGKaNQCAJbbPogvY3n61fx+QAxddBgBwF7fmm/l231aLrmO9fvjkA/v6G7ZNeo1L/+6287v7tEkvkiVr1g7IgXlsnbroMgCAu/hIX7DoEnbJ9Tdsy0fPf/Ck19h81GcPn/QCM0vVrAEAbIROspKVRZexIYxZAwBYYpI1AGBAnW0tWQMAYGKSNQBgOKtj1nrRZWwIyRoAwBKTrAEAQzIbFACAyUnWAIDhdDrb2pg1AAAmJlkDAIY0ymxQzRoAMJxOsm2QZs1tUACAJSZZAwCGNMptUMkaAMASk6wBAMPpxNIdAABMT7IGAAxpjM2mJGsAAEtNsgYADKfT1lkDAGB6kjUAYDydbBsjWJOsAQAsM8kaADCczjizQTVrAAATqarPJ7kpybYkW7v7hKo6LMmbkxyd5PNJntHdN+7oHG6DAgADqmyb+LELTu7uR3f3CbPXL05yQXc/PMkFs9c7pFkDAJivpyQ5e/b87CRPXevDboMCAMPpJCvTzwY9vKou2e71md195t2U8t6q6iR/PHv/yO6+Zvb+V5McudZFNGsAALvnuu1ube7Iv+3uL1fV/ZL8dVV9avs3u7tnjdwOadYAgCHt4riySXT3l2f/vLaq3pHkxCT/WFVHdfc1VXVUkmvXOocxawAAE6iqA6vqoDueJ3lSkk8mOSfJ6bOPnZ7kXWudR7IGAAynsxTJ2pFJ3lFVyWrP9RfdfV5VXZzkLVV1RpIvJHnGWifRrAEAQ1rpxTZr3X1VkkfdzfHrk5y63vO4DQoAsMQkawDAcJbkNuiGkKwBACwxyRoAMJxOZdsgmdQYfwUAwKAkawDAkBY9G3SjSNYAAJaYZA0AGI7ZoAAAzIVkDQAYUGVbj5FJjfFXAAAMSrIGAAynk6wMkkmN8VcAAAxKsgYADMlsUAAAJidZAwCG0202KAAAcyBZAwCGtGLMGgAAU5OsAQDDWd0bdIxMSrMGAAzIBAMAAOZAsgYADMd2UwAAzIVkDQAY0ra2dAcAABOTrAEAw+nUMEt3jPFXAAAMSrIGAAxpxTprAABMTbIGAAxnpO2mxvgrAAAGJVkDAIbTKeusAQAwPckaADAke4MCADA5yRoAMJzuZJt11gAAmJpkDQAYUGUlZoMCADAxyRoAMJyOMWsAAMyBZA0AGNIoe4Nq1gCA4XQqK7abAgBgapI1AGBIo9wGHeOvAAAYlGQNABhOJ1mxdAcAAFOTrAEAA6pss90UAABTk6wBAMMxZg0AgLmQrAEAQzJmDQCAyUnWAIDhdJcxawAATE+yBgAMaZtkDQCAqUnWAIDhdJIVs0EBAJiaZA0AGFAZswYAwPQkawDAcFb3Bh1jzJpmDQAY0rZBbiCO8VcAAAxKsgYADKdTw9wGlawBACwxyRoAMKSVQTKpMf4KAIBBSdYAgOF0J9uMWQMAYGqSNQBgSGaDAgAwOckaADCc1XXWxsikxvgrAAAGJVkDAIa0LcasAQAwMckaADCcjtmgAADMgWQNABiQ2aAAAMyBZA0AGNLKILNBNWvMxb77r+T3374l++7X2bxP50PvPjR/9nv3X3RZwG7ym4b5mbRZq6rTkrwyyeYkr+3ul015PZbX7bdVXvQTD82tt2zO5n06L3/nllz8/oPyqcsOXHRpwG7wm2bZdSfbBpkNOlmzVlWbk7w6yROTXJ3k4qo6p7uvmOqaLLPKrbdsTpLss29n876d7gWXBOwBv2mW3ygTDKZM1k5MsqW7r0qSqnpTkqck0aztpTZt6rzq/M/ke4/+ds4967759Mf8Hzjck/lNw3xM2XI+IMmXtnt99ezYP1NVz6mqS6rqkttz24TlsGgrK5XnPvHYPPsHjsuxj74lDzn2W4suCdgDftMss9WN3Kd9zMvC88HuPrO7T+juE/bN/osuhzn45jc25xN/c5885uSbFl0KsAH8pmHHqmpzVX2sqv5y9vqYqvpIVW2pqjdX1X47O8eUzdqXkzxou9cPnB1jL3TIYVtz4MHbkiT7HbCS459wc7605YAFVwXsLr9p7glWUpM+1ukFSa7c7vXvJHlFdz8syY1JztjZCaYcs3ZxkodX1TFZbdJ+KsmzJrweS+ywI2/PC1/5xWzalGzalFx47iH5yPsOXnRZwG7ym4adq6oHJvnRJL+d5FerqpKcku/0Q2cn+c0kf7TWeSZr1rp7a1X9UpLzs7p0x+u7+/Kprsdy+9yV98rznnTsossANojfNMtuSTZy/4MkL0py0Oz1fZN8vbu3zl7f7Xj+u5p0nbXufk+S90x5DQCABTm8qi7Z7vWZ3X1mklTVjyW5trsvraqT9uQidjAAAIY0h3XWruvuE3bw3uOT/Ieq+pEkByQ5OKsbBRxaVfvM0rV1jedf+GxQAIDRdPevdfcDu/vorI7bf393PzvJB5I8ffax05O8a2fn0qwBAOOZeI21PRgP91+zOtlgS1bHsL1uZ19wGxQAYELd/cEkH5w9vyqruzytm2YNABhOJ7uyFtpScxsUAGCJSdYAgCEtwTprG0KyBgCwxCRrAMBwlmQHgw0hWQMAWGKSNQBgSJI1AAAmJ1kDAIbT2aNdBpaKZg0AGJJFcQEAmJxkDQAYT5tgAADAHEjWAIDhWBQXAIC5kKwBAEOSrAEAMDnJGgAwnJEWxZWsAQAsMckaADCklqwBADA1yRoAMCR7gwIAMDnJGgAwnLY3KAAA8yBZAwCGZDYoAACTk6wBAAOygwEAAHMgWQMAhmTMGgAAk5OsAQDD6YyzzppmDQAYT68ujDsCt0EBAJaYZA0AGJKN3AEAmJxkDQAYTsfSHQAAzIFkDQAYkO2mAACYA8kaADAk66wBADA5yRoAMCSzQQEAmJxkDQAYTrdkDQCAOZCsAQBDss4aAACTk6wBAEOyzhoAAJOTrAEAQzIbFACAyUnWAIDhdGqYZE2zBgAMaZD5BW6DAgAsM8kaADAe200BADAPkjUAYEyDDFqTrAEALDHJGgAwJGPWAACYnGQNABiSjdwBAJicZA0AGE7HmDUAAOZAsgYAjKeTSNYAAJiaZA0AGJLZoAAATE6yBgCMSbIGAMDUJGsAwIDKOmsAAExPsgYAjGmQMWuaNQBgPG27KQAA5kCyBgCMaZDboJI1AIAlJlkDAAZlzBoAABOTrAEAYzJmDQCAqUnWAIAxSdYAAJiaZA0AGE8nsYMBAABTk6wBAENqY9YAAJiaZA0AGJNkDQCAHamqA6rqo1X1iaq6vKp+a3b8mKr6SFVtqao3V9V+a51nh8laVf2vrNGTdvfzd7t6AICpLX426G1JTunum6tq3yQXVdVfJfnVJK/o7jdV1WuSnJHkj3Z0krVug16yoeUCAOxFuruT3Dx7ue/s0UlOSfKs2fGzk/xmdqdZ6+6zt39dVffu7lt2v2QAgPmpJRizVlWbk1ya5GFJXp3kH5J8vbu3zj5ydZIHrHWOnY5Zq6rHVdUVST41e/2oqvrDPSkcAGAAh1fVJds9nnPXD3T3tu5+dJIHJjkxySN29SLrmQ36B0l+OMk5s4t+oqqesKsXAgCYm848ZoNe190nrOeD3f31qvpAksclObSq9pmlaw9M8uW1vruu2aDd/aW7HNq2nu8BACxGrU4wmPKxswqqjqiqQ2fP75XkiUmuTPKBJE+ffez0JO9a6zzrSda+VFU/lKRnMxleMLsQAAA7dlSSs2fj1jYleUt3/+VseNmbquq/JflYktetdZL1NGu/kOSVWR389pUk5yd53p5UDgAwuQVPMOjuv0vy/Xdz/Kqsjl9bl502a919XZJn71J1AABsiPXMBv2+qjq3qr5WVddW1buq6vvmURwAwG7riR9zsp4JBn+R5C1Zve/6vUnemuSNUxYFAMCq9TRr9+7uP+vurbPHnyc5YOrCAAD2yCDJ2lp7gx42e/pXVfXiJG/Kamk/meQ9c6gNAGCvt9YEg0uz2pzdsZDIz2/3Xif5tamKAgDYI51l2Mh9Q6y1N+gx8ywEAIDvtp511lJVj0xyXLYbq9bdfzpVUQAAe2oZNnLfCDtt1qrqJUlOymqz9p4kT05yURLNGgDAxNYzG/TpSU5N8tXu/tkkj0pyyKRVAQDsqUFmg66nWftWd68k2VpVBye5NsmDpi0LAIBkfWPWLpntGP8nWZ0henOSD09aFQAASda3N+hzZ09fU1XnJTl4tjEpAAATW2tR3OPXeq+7L5umJACAPbc3zAb9/TXe6ySnbHAtwGDO/8rHF10CsEFO/OFbFl3CXmutRXFPnmchAAAbapAdDNYzGxQAgAVZ1w4GAAD3KHNeC21KkjUAgCW202atVv10Vf3G7PWDq+rE6UsDANgDe9EOBn+Y5HFJnjl7fVOSV09WEQDABqie9jEv6xmz9tjuPr6qPpYk3X1jVe03cV0AAGR9zdrtVbU5s8Cvqo5IsjJpVQAAe2ovmmDwP5O8I8n9quq3k1yU5L9PWhUAAEnWtzfoG6rq0iSnJqkkT+3uKyevDABgTwySrO20WauqBye5Jcm52x/r7i9OWRgAAOsbs/burPamleSAJMck+XSSfzVhXQAAu23eMzantJ7boP96+9dVdXyS505WEQAAd9rl7aa6+7KqeuwUxQAAbJhBNnJfz5i1X93u5aYkxyf5ymQVAQBwp/Ukawdt93xrVsewvW2acgAANsjeMGZtthjuQd39wjnVAwDAdnbYrFXVPt29taoeP8+CAAA2wt4wG/SjWR2f9vGqOifJW5N88443u/vtE9cGALDXW8+YtQOSXJ/klHxnvbVOolkDAJbXXpCs3W82E/ST+U6TdodB/nwAgOW2VrO2Ocl98s+btDto1gCA5bWX7GBwTXe/dG6VAADwXdZq1sZY9hcA2DsNkqxtWuO9U+dWBQAAd2uHyVp33zDPQgAANtQgydoub+QOAHBPMMoEg7VugwIAsGCaNQCAJaZZAwBYYsasAQBjMmYNAICpSdYAgPEMtN2UZA0AYIlJ1gCAMUnWAACYmmQNABiTZA0AgKlJ1gCA4VTMBgUAYA4kawDAmCRrAABMTbIGAIzHDgYAAMyDZA0AGJNkDQCAqUnWAIAxDZKsadYAgCGZYAAAwOQkawDAmCRrAABMTbIGAIynI1kDAGB6kjUAYEhmgwIAMDnJGgAwJskaAABTk6wBAEMyZg0AgMlJ1gCAMUnWAACYmmQNABiPHQwAAJgHyRoAMJyaPUYgWQMAWGKSNQBgTMasAQAwNckaADCkUXYw0KwBAGMapFlzGxQAYIlJ1gCAMUnWAACYmmQNABhPjzPBQLIGALDENGsAwJh64sdOVNWDquoDVXVFVV1eVS+YHT+sqv66qj47++f3rHUezRoAwDS2Jvkv3X1ckh9M8ryqOi7Ji5Nc0N0PT3LB7PUOadYAgCFVT/vYme6+prsvmz2/KcmVSR6Q5ClJzp597OwkT13rPCYYAADsnsOr6pLtXp/Z3Wfe3Qer6ugk35/kI0mO7O5rZm99NcmRa11EswYAjGn62aDXdfcJO/tQVd0nyduS/Ofu/kZV3fled3fV2jmd26AAABOpqn2z2qi9obvfPjv8j1V11Oz9o5Jcu9Y5NGsAwJAWPWatViO01yW5srtfvt1b5yQ5ffb89CTvWus8boMCAEzj8Ul+JsnfV9XHZ8d+PcnLkrylqs5I8oUkz1jrJJo1AGA861wLbdISui9KUjt4+9T1nsdtUACAJSZZAwDGZG9QAACmJlkDAIZTWd+MzXsCyRoAwBKTrAEAYxokWdOsAQBDqh6jW3MbFABgiUnWAIDxLMGiuBtFsgYAsMQkawDAkCzdAQDA5CRrAMCYJGsAAExNsgYADMmYNQAAJidZAwDGJFkDAGBqkjUAYDxtzBoAAHMgWQMAxiRZAwBgapI1AGA4FWPWAACYA8kaADCmHiNak6wBACwxyRoAMCRj1gAAmJxkDQAYT2eYddY0awDAkGpl0RVsDLdBAQCWmGQNABjTILdBJWsAAEtMsgYADGmUpTs0a8zFvvuv5PffviX77tfZvE/nQ+8+NH/2e/dfdFnALvqPJx6Xe91nWzZtSjbv03nVeZ/J2b97/3z4/ENSlRx6+O154R98Mfe9/9ZFlwrDmKxZq6rXJ/mxJNd29yOnug73DLffVnnRTzw0t96yOZv36bz8nVty8fsPyqcuO3DRpQG76HffuiWH3Hfbna+f/ovX5vQXfTVJ8s7XHp4/f8X984LfuXpR5cGqju2m1uGsJKdNeH7uUSq33rI5SbLPvp3N+/YovyHY6x140HfWR7j1W5tStcBiYECTJWvdfWFVHT3V+bnn2bSp86rzP5PvPfrbOfes++bTH5OqwT1OdX79mQ9NKvnRn7k+P/LT1ydJ/vfL7p/3vfWwHHjwtvzu/9my4CJh1Shj1hY+G7SqnlNVl1TVJbfntkWXw4RWVirPfeKxefYPHJdjH31LHnLstxZdErCLXv7OLXn1ez+T337DVTnnrMPz93+7+j9dP/vir+YNl16RU378xpzz+iMWXCWMZeHNWnef2d0ndPcJ+2b/RZfDHHzzG5vzib+5Tx5z8k2LLgXYRYcfdXuS5NDDt+bxp/1TPvWxe/+z90952o256D2HLKI0+G498WNOFt6ssXc45LCtOfDg1QHJ+x2wkuOfcHO+tOWABVcF7Ipbb9mUW27edOfzS//vQTn6Ebfmy1ftd+dnPnz+IXnQw9wlgY1k6Q7m4rAjb88LX/nFbNqUbNqUXHjuIfnI+w5edFnALrjxa/vkt844JkmybWty8tO+nsecfFNe+nNH5+p/2D+bNiX3e8C383wzQVkClXHGrE25dMcbk5yU5PCqujrJS7r7dVNdj+X2uSvvlec96dhFlwHsgaMe8u285n2f/q7jv/Haz8+/GNiLTDkb9JlTnRsAYE3d1lkDAGB6xqwBAEMaZcyaZA0AYIlJ1gCAMUnWAACYmmQNABjSKGPWNGsAwHg6ycoY3ZrboAAAS0yyBgCMaYxgTbIGALDMJGsAwJBGmWAgWQMAWGKSNQBgTDZyBwBgapI1AGBIxqwBADA5yRoAMJ6OddYAAJieZA0AGE4lKbNBAQCYmmQNABjTyqIL2BiSNQCAJSZZAwCGZMwaAACTk6wBAOOxzhoAAPMgWQMABtTJIGPWNGsAwJBs5A4AwOQkawDAmAa5DSpZAwBYYpI1AGA8nZTtpgAAmJpkDQAYkzFrAABMTbIGAIxpjGBNsgYAsMwkawDAkMqYNQAApiZZAwDGJFkDAGBqkjUAYDydxA4GAABMTbIGAAyn0maDAgAwPc0aADCm7mkfO1FVr6+qa6vqk9sdO6yq/rqqPjv75/fs7DyaNQCAaZyV5LS7HHtxkgu6++FJLpi9XpNmDQAY04KTte6+MMkNdzn8lCRnz56fneSpOzuPCQYAwHjms3TH4VV1yXavz+zuM3fynSO7+5rZ868mOXJnF9GsAQDsnuu6+4Td/XJ3d1XtNKLTrAEAQ1rSpTv+saqO6u5rquqoJNfu7AvGrAEAzM85SU6fPT89ybt29gXJGgAwpgUna1X1xiQnZXVs29VJXpLkZUneUlVnJPlCkmfs7DyaNQCACXT3M3fw1qm7ch7NGgAwoPUtr3FPYMwaAMASk6wBAOPpSNYAAJieZA0AGNP0OxjMhWQNAGCJSdYAgCEt6Q4Gu0yyBgCwxCRrAMCYJGsAAExNsgYAjKeTrEjWAACYmGQNABiQvUEBAJgDyRoAMCbJGgAAU5OsAQBjGiRZ06wBAOOxdAcAAPMgWQMABtRJryy6iA0hWQMAWGKSNQBgTINMMJCsAQAsMckaADAes0EBAJgHyRoAMCZj1gAAmJpkDQAYk2QNAICpSdYAgAG1ZA0AgOlJ1gCA8XSSFXuDAgAwMckaADAmY9YAAJiaZA0AGJNkDQCAqUnWAIABdbIyRrKmWQMAxtNJt6U7AACYmGQNABjTILdBJWsAAEtMsgYAjMnSHQAATE2yBgCMp9tG7gAATE+yBgCMyZg1AACmJlkDAIbUxqwBADA1yRoAMKA2Zg0AgOlJ1gCA8XTsDQoAwPQkawDAmNpsUAAAJiZZAwCG00namDUAAKYmWQMAxtM9zJg1zRoAMCS3QQEAmJxkDQAY0yC3QSVrAABLrHqJNjmtqq8l+cKi62Byhye5btFFABvGb3rv8JDuPmLRRaxXVZ2X1f82p3Rdd5828TWWq1lj71BVl3T3CYuuA9gYftMwLbdBAQCWmGYNAGCJadZYhDMXXQCwofymYULGrAEALDHJGgDAEtOsMTdVdVpVfbqqtlTVixddD7D7qur1VXVtVX1y0bXA6DRrzEVVbU7y6iRPTnJckmdW1XGLrQrYA2clmXx9KUCzxvycmGRLd1/V3d9O8qYkT1lwTcBu6u4Lk9yw6Dpgb6BZY14ekORL272+enYMAFiDZg0AYIlp1piXLyd50HavHzg7BgCsQbPGvFyc5OFVdUxV7Zfkp5Kcs+CaAGDpadaYi+7emuSXkpyf5Mokb+nuyxdbFbC7quqNST6c5Niqurqqzlh0TTAqOxgAACwxyRoAwBLTrAEALDHNGgDAEtOsAQAsMc0aAMAS06zBIKpqW1V9vKo+WVVvrap778G5zqqqp8+ev7aqjlvjsydV1Q/txjU+X1WHr/f4XT5z8y5e6zer6oW7WiPAMtCswTi+1d2P7u5HJvl2kl/Y/s2q2md3TtrdP9fdV6zxkZOS7HKzBsD6aNZgTB9K8rBZ6vWhqjonyRVVtbmq/kdVXVxVf1dVP58ktepVVfXpqnpfkvvdcaKq+mBVnTB7flpVXVZVn6iqC6rq6Kw2hb8yS/X+XVUdUVVvm13j4qp6/Oy7962q91bV5VX12iS1sz+iqt5ZVZfOvvOcu7z3itnxC6rqiNmxh1bVebPvfKiqHrER/zIBFmm3/k8bWF6zBO3JSc6bHTo+ySO7+3OzhuefuvsxVbV/kv9XVe9N8v1Jjk1yXJIjk1yR5PV3Oe8RSf4kyRNm5zqsu2+oqtckubm7f2/2ub9I8oruvqiqHpzVXSv+ZZKXJLmou19aVT+aZD0r3v+n2TXuleTiqnpbd1+f5MAkl3T3r1TVb8zO/UtJzkzyC9392ap6bJI/THLKbvxrBFgamjUYx72q6uOz5x9K8rqs3p78aHd/bnb8SUn+zR3j0ZIckuThSZ6Q5I3dvS3JV6rq/Xdz/h9McuEd5+ruG3ZQx79PclzVncHZwVV1n9k1fnz23XdX1Y3r+JueX1VPmz1/0KzW65OsJHnz7PifJ3n77Bo/lOSt2117/3VcA2CpadZgHN/q7kdvf2DWtHxz+0NJfrm7z7/L535kA+vYlOQHu/vWu6ll3arqpKw2fo/r7luq6oNJDtjBx3t23a/f9d8BwD2dMWuwdzk/yS9W1b5JUlX/oqoOTHJhkp+cjWk7KsnJd/Pdv03yhKo6Zvbdw2bHb0py0Hafe2+SX77jRVXd0TxdmORZs2NPTvI9O6n1kCQ3zhq1R2Q12bvDpiR3pIPPyurt1W8k+VxV/cTsGlVVj9rJNQCWnmYN9i6vzep4tMuq6pNJ/jirCfs7knx29t6fJvnwXb/Y3V9L8pys3nL8RL5zG/LcJE+7Y4JBkucnOWE2geGKfGdW6m9ltdm7PKu3Q7+4k1rPS7JPVV2Z5GVZbRbv8M0kJ87+hlOSvHR2/NlJzpjVd3mSp6zj3wnAUqvuXnQNAADsgGQNAGCJadYAAJaYZg0AYIlp1gAAlphmDQBgiWnWAACWmGYNAGCJadYAAJbY/wcn5aB1kpS5cgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf_Ww9agfiRl"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M93pZapPsT-t"
      },
      "source": [
        "# Checking distributions of synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "eDs9PlHYsT-t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ee10fe0f-1bf7-44fb-fea2-62e25a00bf63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport warnings\\nwarnings.filterwarnings(\"ignore\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "\"\"\"\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "6xuObvXYsT-t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2442289e-a17c-4986-b5d7-3758f4b5d71c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndf0 = df[df.LUNG_CANCER == 0]\\n#df1 = df[df.label == 1]\\ndf1 = df[df.LUNG_CANCER == 1]\\n\\nmc = MinMaxScaler(feature_range=(0, 1))\\nstandard_scaler0 = mc.fit(df0)\\ndf0 = standard_scaler0.transform(df0)\\n#x_scaled = pd.DataFrame(df0)\\n\\nstandard_scaler1 = mc.fit(df1)\\ndf1 = standard_scaler1.transform(df1)\\n\\nprint(df0[0:5])\\nprint(df1[0:5])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "df0 = df[df.LUNG_CANCER == 0]\n",
        "#df1 = df[df.label == 1]\n",
        "df1 = df[df.LUNG_CANCER == 1]\n",
        "\n",
        "mc = MinMaxScaler(feature_range=(0, 1))\n",
        "standard_scaler0 = mc.fit(df0)\n",
        "df0 = standard_scaler0.transform(df0)\n",
        "#x_scaled = pd.DataFrame(df0)\n",
        "\n",
        "standard_scaler1 = mc.fit(df1)\n",
        "df1 = standard_scaler1.transform(df1)\n",
        "\n",
        "print(df0[0:5])\n",
        "print(df1[0:5])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGKrVeyusT-u"
      },
      "source": [
        "<b> For class 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "oGuJ4y7-sT-u",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "54b29e7c-d640-43dd-ff71-6dcc97def91b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nprint('FOR CLASS 0')\\nfig, axes = plt.subplots(16, 1, figsize=(10, 50))  # must change plot number\\n\\nfor n, col in enumerate(df.columns.to_list()[:-1]):\\n    ax1 = plt.subplot(16,1, n+1)  # must change plot number\\n    sns.distplot(x = df_generated_0[col], color = 'red', label = 'Generated')\\n    sns.distplot(x = df0[col], color = 'blue', label = 'real')\\n    plt.legend(fontsize = 12)  # 30\\n    plt.xlabel(col, fontsize = 12)  #30 \\n    plt.title(col, fontsize = 12)   #30\\n    plt.ylabel(' ')\\nplt.subplots_adjust(wspace=0.5,hspace=0.5)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "\"\"\"\n",
        "print('FOR CLASS 0')\n",
        "fig, axes = plt.subplots(16, 1, figsize=(10, 50))  # must change plot number\n",
        "\n",
        "for n, col in enumerate(df.columns.to_list()[:-1]):\n",
        "    ax1 = plt.subplot(16,1, n+1)  # must change plot number\n",
        "    sns.distplot(x = df_generated_0[col], color = 'red', label = 'Generated')\n",
        "    sns.distplot(x = df0[col], color = 'blue', label = 'real')\n",
        "    plt.legend(fontsize = 12)  # 30\n",
        "    plt.xlabel(col, fontsize = 12)  #30 \n",
        "    plt.title(col, fontsize = 12)   #30\n",
        "    plt.ylabel(' ')\n",
        "plt.subplots_adjust(wspace=0.5,hspace=0.5)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EugWQdLOsT-u"
      },
      "source": [
        "<b> For class 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "HBlaEEiosT-u",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "011ea871-c738-41ff-8e47-267dd518c196"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nprint('FOR CLASS 1')\\nfig, axes = plt.subplots(16, 1, figsize=(10, 50)) #must change font size \\n\\nfor n, col in enumerate(df.columns.to_list()[:-1]):\\n    ax1 = plt.subplot(16,1, n+1)\\n    sns.distplot(x = df_generated_1[col], color = 'red', label = 'Generated')\\n    sns.distplot(x = df1[col], color = 'blue', label = 'real')\\n    plt.legend(fontsize = 12) # #30\\n    plt.xlabel(col, fontsize = 12)\\n    plt.title(col, fontsize = 12)\\n    plt.ylabel(' ')\\nplt.subplots_adjust(wspace=0.5,hspace=0.5)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "\"\"\"\n",
        "print('FOR CLASS 1')\n",
        "fig, axes = plt.subplots(16, 1, figsize=(10, 50)) #must change font size \n",
        "\n",
        "for n, col in enumerate(df.columns.to_list()[:-1]):\n",
        "    ax1 = plt.subplot(16,1, n+1)\n",
        "    sns.distplot(x = df_generated_1[col], color = 'red', label = 'Generated')\n",
        "    sns.distplot(x = df1[col], color = 'blue', label = 'real')\n",
        "    plt.legend(fontsize = 12) # #30\n",
        "    plt.xlabel(col, fontsize = 12)\n",
        "    plt.title(col, fontsize = 12)\n",
        "    plt.ylabel(' ')\n",
        "plt.subplots_adjust(wspace=0.5,hspace=0.5)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG8v3WH8cjEx"
      },
      "source": [
        "Asssessment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH3a5Ds-chpD"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "M93pZapPsT-t"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}